{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "E3blYPMzdrPA",
        "jtfXsBeWdkzQ",
        "RzSJA1Fa0ZLD",
        "4XBPDWNA0SK-",
        "ro4TXaI2sUx8",
        "LVWcMbSPU3A0",
        "qtzr6EtWU9cr",
        "pYr8JhupcuMF",
        "MO5pUXkPc0pN",
        "vUEtbpP5Uxcg",
        "1u5G1rJAwPjE",
        "ToG_GdIPEfsC",
        "BSTmBtNGuXZy",
        "hR9TjcKn8vcl",
        "PJ9FCJy5vUoU",
        "CpazRs8rVvLS",
        "Dp0mF1tgWFIl",
        "NETM_zpze1IP",
        "sjNmEso5CN1R",
        "IqfQZXdDpAS9",
        "DgDRBmb1_mGr",
        "RhJ_KxCz_pYE",
        "HCsaSE8dGekH"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmperoR1127/ml_project/blob/master/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_TbqKhLg9Yf",
        "colab_type": "code",
        "outputId": "fc3fd50f-078c-4bde-c28b-9c8003271f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-vXWv-ZEx9K",
        "colab_type": "text"
      },
      "source": [
        "In recent years, an increasing number of internationals expect to get a working permission in US for various reasons. Quite a few of them, unfortunately, are denied. We feel it is important for candidates to predict the result prior submitting their applications, so we use machine learning algorithms to tackle this problem.\n",
        "\n",
        "Another focus of this study is, with a comprehensive comparison and analysis, discussing the strength and limitations of different types of machine learning algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLSkIfDHdYjk",
        "colab_type": "text"
      },
      "source": [
        "# Env setup\n",
        "We need to import some packages to setup the working environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3blYPMzdrPA",
        "colab_type": "text"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6GJppz9hBv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Project root directory\n",
        "PROJECT_ROOT_DIR = \"/content/drive/My Drive/\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"Images\", fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtfXsBeWdkzQ",
        "colab_type": "text"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOO7V1uePIVN",
        "colab_type": "code",
        "outputId": "4e56b6ff-c2fb-45b4-cb52-8bc124f3a729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#load the dataset\n",
        "path = PROJECT_ROOT_DIR + \"Data/H-1B_Disclosure_RAW_Data.csv\"\n",
        "df = pd.read_csv(path, encoding='utf-8')\n",
        "processed_data = df.copy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlcBrHwtFSq0",
        "colab_type": "text"
      },
      "source": [
        "The demonstration of supervised learning has 3 parts: feature engineering, training the models and experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlltPJJUAauj",
        "colab_type": "text"
      },
      "source": [
        "#Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ri_l1feFbhL",
        "colab_type": "text"
      },
      "source": [
        "We apply several feature engineering steps to the dataset, feature transformation; \n",
        "feature selection methods; \n",
        "since the dataset is highly skewed, we also tackle the class imbalance by resampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSJA1Fa0ZLD",
        "colab_type": "text"
      },
      "source": [
        "###Drop correlated columns and create new columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVgedKr4jm9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data = processed_data.drop([\"CASE_NUMBER\", \"VISA_CLASS\", \n",
        "                                        \"EMPLOYER_NAME\", \"EMPLOYER_STATE\",\"EMPLOYER_POSTAL_CODE\", \n",
        "                                        \"EMPLOYER_CITY\", \"EMPLOYER_BUSINESS_DBA\", \n",
        "                                        \"EMPLOYER_COUNTRY\", \"EMPLOYER_PROVINCE\", \"EMPLOYER_ADDRESS\", \n",
        "                                        \"EMPLOYER_PHONE\", \"EMPLOYER_PHONE_EXT\", \n",
        "                                        \"AGENT_ATTORNEY_NAME\", \"AGENT_ATTORNEY_CITY\", \"AGENT_ATTORNEY_STATE\",\n",
        "                                        \"JOB_TITLE\", \"SOC_NAME\",\n",
        "                                        \"PW_SOURCE\", \"PW_SOURCE_YEAR\", \"PW_SOURCE_OTHER\", \"WAGE_RATE_OF_PAY_FROM\",\n",
        "                                        \"WAGE_RATE_OF_PAY_TO\", \"WAGE_UNIT_OF_PAY\",\n",
        "                                        \"WORKSITE_CITY\", \"WORKSITE_COUNTY\", \"WORKSITE_POSTAL_CODE\", \n",
        "                                        \"ORIGINAL_CERT_DATE\", \"PUBLIC_DISCLOSURE_LOCATION\"], axis=1)\n",
        "#format EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['CASE_SUBMITTED'] = pd.to_datetime(processed_data['CASE_SUBMITTED'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['DECISION_DATE'] = pd.to_datetime(processed_data['DECISION_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_START_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_START_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_END_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_END_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "#drop NaT rows because we can't \"guess\" the specific date\n",
        "processed_data = processed_data[processed_data.CASE_SUBMITTED != 'NaT']\n",
        "processed_data = processed_data[processed_data.DECISION_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_START_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_END_DATE != 'NaT']\n",
        "#add one column as EMP_PERIOD, and drop EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMPLOYMENT_END_DATE'] - processed_data['EMPLOYMENT_START_DATE']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD']/np.timedelta64(1,'Y')\n",
        "#train_set = train_set[train_set.EMP_PERIOD != '-']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD'].astype(float)\n",
        "#add one column as PROCESS_TIME, indicating processing time of visa application\n",
        "processed_data['PROCESS_TIME'] = processed_data['DECISION_DATE'] - processed_data['CASE_SUBMITTED']\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].map(lambda x: str(x)[:1])\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].astype(float)\n",
        "processed_data = processed_data.drop([\"EMPLOYMENT_START_DATE\", \"EMPLOYMENT_END_DATE\"], axis=1)\n",
        "processed_data = processed_data.drop([\"CASE_SUBMITTED\", \"DECISION_DATE\"], axis=1)\n",
        "\n",
        "#concatenate the first 2 digit of column SOC_CODE and NAIC_CODE\n",
        "processed_data['SOC_CODE'] = processed_data['SOC_CODE'].map(lambda x: str(x)[:2])\n",
        "processed_data['NAICS_CODE'] = processed_data['NAICS_CODE'].map(lambda x: str(x)[:2])\n",
        "#remove impurity in the column\n",
        "processed_data = processed_data[processed_data.PW_UNIT_OF_PAY != 'N']\n",
        "processed_data = processed_data[processed_data.PREVAILING_WAGE != 'N']\n",
        "#according to google, there are 2080 working hours per year\n",
        "pw_unit_column = {\"Year\":1, \"Hour\":2080, \"Month\":12, \"Week\":52, \"Bi-Weekly\":26}\n",
        "processed_data['PW_UNIT_OF_PAY'] = processed_data['PW_UNIT_OF_PAY'].replace(pw_unit_column)\n",
        "#remove ',' in the column value\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('str')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data.PREVAILING_WAGE.str.replace(',','')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('float')\n",
        "#add one column as ANNUAL_SALARY\n",
        "processed_data['ANNUAL_SALARY'] = processed_data['PREVAILING_WAGE'] * processed_data['PW_UNIT_OF_PAY']\n",
        "processed_data = processed_data.drop([\"PREVAILING_WAGE\", \"PW_UNIT_OF_PAY\"], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XBPDWNA0SK-",
        "colab_type": "text"
      },
      "source": [
        "### Deal with noise, missing values, numerical and categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRGugNHkGECf",
        "colab_type": "code",
        "outputId": "8c2f9858-c99c-4d08-c526-2c265dce027d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "original_set = processed_data.drop([\"CASE_STATUS\"], axis=1)\n",
        "original_labels = processed_data[[\"CASE_STATUS\"]].copy()\n",
        "original_set_num = original_set.drop([\"AGENT_REPRESENTING_EMPLOYER\", \"SOC_CODE\", \"NAICS_CODE\",\n",
        "                                \"FULL_TIME_POSITION\", \"PW_WAGE_LEVEL\", \"H1B_DEPENDENT\", \"WILLFUL_VIOLATOR\",\n",
        "                                \"SUPPORT_H1B\", \"LABOR_CON_AGREE\", \"WORKSITE_STATE\"], axis=1)\n",
        "original_set_cat = original_set.drop([\"TOTAL_WORKERS\",\"NEW_EMPLOYMENT\",\"CONTINUED_EMPLOYMENT\",\n",
        "                                \"CHANGE_PREVIOUS_EMPLOYMENT\", \"NEW_CONCURRENT_EMP\", \"CHANGE_EMPLOYER\",\n",
        "                                \"AMENDED_PETITION\", \"EMP_PERIOD\", \"PROCESS_TIME\",\n",
        "                                \"ANNUAL_SALARY\"], axis=1)\n",
        "#build the pipeline\n",
        "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),('cat', OneHotEncoder()),])\n",
        "full_pipeline = ColumnTransformer([(\"num\", num_pipeline, list(original_set_num)),(\"cat\", cat_pipeline, list(original_set_cat)),])\n",
        "\n",
        "#prepare the data\n",
        "original_set = full_pipeline.fit_transform(original_set)\n",
        "\n",
        "#prepare the target\n",
        "encoder = LabelEncoder()\n",
        "original_labels = encoder.fit_transform(original_labels)\n",
        "\n",
        "#get columns after encoding\n",
        "def get_feature_names(columnTransformer):\n",
        "    output_features = []\n",
        "    for name, pipe, features in columnTransformer.transformers_:\n",
        "        if name!='remainder':\n",
        "            for i in pipe:\n",
        "                trans_features = []\n",
        "                if hasattr(i,'categories_'):\n",
        "                    trans_features.extend(i.get_feature_names(features))\n",
        "                else:\n",
        "                    trans_features = features\n",
        "            output_features.extend(trans_features)\n",
        "    return output_features\n",
        "column_names = get_feature_names(full_pipeline)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFnoIJULI1Cs",
        "colab_type": "code",
        "outputId": "fe6ab1eb-58fe-46eb-ac0e-2a8b1050e340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "original_set.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20327, 122)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VGv6kw1j2f2",
        "colab_type": "text"
      },
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C1f6ZDHx9qG",
        "colab_type": "text"
      },
      "source": [
        "Three feature selection methods: Boruta, L1-based and tree-based."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwyk8nCc1zn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get feature names after feature selection\n",
        "def get_feature_names(X, col = column_names):\n",
        "  try:\n",
        "    mask = X.get_support() #list of booleans\n",
        "  except AttributeError:\n",
        "    mask = X.support_  #Boruta has different attributes from scikit-learn API\n",
        "  new_features = [] # The list of your K best features\n",
        "  for bool, feature in zip(mask, col):\n",
        "    if bool:\n",
        "      new_features.append(feature)\n",
        "  return new_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff-ed4Sp2LDQ",
        "colab_type": "text"
      },
      "source": [
        "Boruta feature selection method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yNuS8Id7ygE",
        "colab_type": "code",
        "outputId": "7d3591af-5f54-44fb-8fab-9cf059d84864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "!pip install Boruta"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Boruta\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/11/583f4eac99d802c79af9217e1eff56027742a69e6c866b295cce6a5a8fc2/Boruta-0.3-py3-none-any.whl (56kB)\n",
            "\r\u001b[K     |█████▉                          | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 20kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 30kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from Boruta) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from Boruta) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from Boruta) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17.1->Boruta) (0.14.0)\n",
            "Installing collected packages: Boruta\n",
            "Successfully installed Boruta-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKN5c2-53z8",
        "colab_type": "code",
        "outputId": "f9f445c5-3673-41e7-9931-90986bceced9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "#Boruta feature selection\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "feat_selector = BorutaPy(rf, n_estimators='auto', random_state=1)\n",
        "feat_selector.fit(original_set.toarray(), original_labels)\n",
        "boruta_set = feat_selector.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(boruta_set.shape[1])\n",
        "      + \" features after applying Boruta feature selection technique\")\n",
        "print(get_feature_names(feat_selector))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset with 122 features is reduced to 5 features after applying Boruta feature selection technique\n",
            "['PROCESS_TIME', 'ANNUAL_SALARY', 'SOC_CODE_15', 'H1B_DEPENDENT_N', 'H1B_DEPENDENT_Y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2sagoqX2T20",
        "colab_type": "text"
      },
      "source": [
        "L1-based and tree-based feature selection method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVoI2E6c6Tvg",
        "colab_type": "code",
        "outputId": "11783f26-4b9a-4c8c-cc98-4b6d87cc96b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "#L1-based feature selection\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter = 2000).fit(original_set, original_labels)\n",
        "l_model = SelectFromModel(lsvc, prefit=True)\n",
        "l1_set = l_model.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(l1_set.shape[1])\n",
        "      + \" features after applying L1-based feature selection technique\")\n",
        "print(get_feature_names(l_model))\n",
        "\n",
        "#tree-based feature selection\n",
        "clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = clf.fit(original_set, original_labels)\n",
        "tb_model = SelectFromModel(clf, prefit=True)\n",
        "tr_set = tb_model.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(tr_set.shape[1])\n",
        "      + \" features after applying tree-based feature selection technique\")\n",
        "print(get_feature_names(tb_model))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset with 122 features is reduced to 9 features after applying L1-based feature selection technique\n",
            "['PROCESS_TIME', 'ANNUAL_SALARY', 'AGENT_REPRESENTING_EMPLOYER_Y', 'SOC_CODE_15', 'NAICS_CODE_54', 'FULL_TIME_POSITION_Y', 'H1B_DEPENDENT_Y', 'WILLFUL_VIOLATOR_N', 'SUPPORT_H1B_Y']\n",
            "Dataset with 122 features is reduced to 16 features after applying tree-based feature selection technique\n",
            "['TOTAL_WORKERS', 'NEW_EMPLOYMENT', 'CONTINUED_EMPLOYMENT', 'CHANGE_PREVIOUS_EMPLOYMENT', 'CHANGE_EMPLOYER', 'AMENDED_PETITION', 'EMP_PERIOD', 'PROCESS_TIME', 'ANNUAL_SALARY', 'AGENT_REPRESENTING_EMPLOYER_N', 'AGENT_REPRESENTING_EMPLOYER_Y', 'PW_WAGE_LEVEL_Level I', 'PW_WAGE_LEVEL_Level II', 'PW_WAGE_LEVEL_Level III', 'WORKSITE_STATE_CA', 'WORKSITE_STATE_NY']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4TXaI2sUx8",
        "colab_type": "text"
      },
      "source": [
        "### Deal with class imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiKtzlk_yG9U",
        "colab_type": "text"
      },
      "source": [
        "Three resampling techniques: oversampling, undersampling and balanced sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byix8507s90s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "from collections import Counter\n",
        "#load the datasets\n",
        "original_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_set.gz')\n",
        "boruta_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'boruta_set.gz')\n",
        "l1_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'l1_set.gz')\n",
        "tr_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'tr_set.gz')\n",
        "#load the labels\n",
        "original_labels = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_labels.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrTUV3A8tMC4",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with oversampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmCKFngMtGM5",
        "colab_type": "code",
        "outputId": "0004899e-a2ba-4bf6-d447-17ddfc155489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#rebalance the dataset using oversampling (random oversampling)\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "ros_boruta_set, ros_boruta_labels = ros.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_boruta \" + str(sorted(Counter(ros_boruta_labels).items())))\n",
        "\n",
        "ros_l1_set, ros_l1_labels = ros.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_l1 \" + str(sorted(Counter(ros_l1_labels).items())))\n",
        "\n",
        "ros_tr_set, ros_tr_labels = ros.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_tr \" + str(sorted(Counter(ros_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of oversampling with train_set_boruta [(0, 20058), (1, 20058)]\n",
            "Class distribution of oversampling with train_set_l1 [(0, 20058), (1, 20058)]\n",
            "Class distribution of oversampling with train_set_tr [(0, 20058), (1, 20058)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Coxm_WJwpQh",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with under-sampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ypJeXqwuUY",
        "colab_type": "code",
        "outputId": "9603b8be-0b4e-4ebe-acc8-282f2e5543dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
        "#rebalance the dataset using undersampling (nearest neightbours)\n",
        "renn = RepeatedEditedNearestNeighbours()\n",
        "renn_boruta_set, renn_boruta_labels = renn.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of undersampling with boruta_set \" + str(sorted(Counter(renn_boruta_labels).items())))\n",
        "\n",
        "renn_l1_set, renn_l1_labels = renn.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of undersampling with l1_set \" + str(sorted(Counter(renn_l1_labels).items())))\n",
        "\n",
        "renn_tr_set, renn_tr_labels = renn.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of undersampling with tr_set \" + str(sorted(Counter(renn_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of undersampling with boruta_set [(0, 19484), (1, 269)]\n",
            "Class distribution of undersampling with l1_set [(0, 19548), (1, 269)]\n",
            "Class distribution of undersampling with tr_set [(0, 19606), (1, 269)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x551OsAqwa1L",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with balanced sampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B59FGJ7zQNff",
        "colab_type": "code",
        "outputId": "214ccc54-07f2-4b2c-f346-8ab0ed44769d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "#rebalance the dataset using balanced sampling (SMOTEENN)\n",
        "smote_enn = SMOTEENN(random_state=0)\n",
        "smote_boruta_set, smote_boruta_labels = smote_enn.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with boruta_set \" + str(sorted(Counter(smote_boruta_labels).items())))\n",
        "\n",
        "smote_l1_set, smote_l1_labels = smote_enn.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with l1_set \" + str(sorted(Counter(smote_l1_labels).items())))\n",
        "\n",
        "smote_tr_set, smote_tr_labels = smote_enn.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with tr_set \" + str(sorted(Counter(smote_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of balanced sampling with boruta_set [(0, 16097), (1, 15546)]\n",
            "Class distribution of balanced sampling with l1_set [(0, 16067), (1, 16140)]\n",
            "Class distribution of balanced sampling with tr_set [(0, 19055), (1, 19077)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVWcMbSPU3A0",
        "colab_type": "text"
      },
      "source": [
        "### Split train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heKfDhlRvGy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the dataset into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#1. split original_set and original_labels\n",
        "original_set_train, original_set_test, original_labels_train, original_labels_test = train_test_split(original_set,original_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#2. split ros_boruta_set and ros_boruta_labels\n",
        "ros_boruta_set_train, ros_boruta_set_test, ros_boruta_labels_train, ros_boruta_labels_test = train_test_split(ros_boruta_set,ros_boruta_labels, test_size=0.2, random_state=42)\n",
        "#3. split ros_l1_set and ros_l1_labels\n",
        "ros_l1_set_train, ros_l1_set_test, ros_l1_labels_train, ros_l1_labels_test = train_test_split(ros_l1_set,ros_l1_labels, test_size=0.2, random_state=42)\n",
        "#4. split ros_tr_set and ros_tr_labels\n",
        "ros_tr_set_train, ros_tr_set_test, ros_tr_labels_train, ros_tr_labels_test = train_test_split(ros_tr_set,ros_tr_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#5. split renn_boruta_set and renn_boruta_labels\n",
        "renn_boruta_set_train, renn_boruta_set_test, renn_boruta_labels_train, renn_boruta_labels_test = train_test_split(renn_boruta_set,renn_boruta_labels, test_size=0.2, random_state=42)\n",
        "#6. split renn_l1_set and renn_l1_labels\n",
        "renn_l1_set_train, renn_l1_set_test, renn_l1_labels_train, renn_l1_labels_test = train_test_split(renn_l1_set,renn_l1_labels, test_size=0.2, random_state=42)\n",
        "#7. split renn_tr_set and renn_tr_labels\n",
        "renn_tr_set_train, renn_tr_set_test, renn_tr_labels_train, renn_tr_labels_test = train_test_split(renn_tr_set,renn_tr_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#8. split smote_boruta_set and smote_boruta_labels\n",
        "smote_boruta_set_train, smote_boruta_set_test, smote_boruta_labels_train, smote_boruta_labels_test = train_test_split(smote_boruta_set,smote_boruta_labels, test_size=0.2, random_state=42)\n",
        "#9. split smote_l1_set and smote_l1_labels\n",
        "smote_l1_set_train, smote_l1_set_test, smote_l1_labels_train, smote_l1_labels_test = train_test_split(smote_l1_set,smote_l1_labels, test_size=0.2, random_state=42)\n",
        "#10. split smote_tr_set and smote_tr_labels\n",
        "smote_tr_set_train, smote_tr_set_test, smote_tr_labels_train, smote_tr_labels_test = train_test_split(smote_tr_set,smote_tr_labels, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtzr6EtWU9cr",
        "colab_type": "text"
      },
      "source": [
        "### Dump the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srUNJLqWvLfH",
        "colab_type": "code",
        "outputId": "552ade0e-021e-4b32-a614-865f174fcc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#store original dataset\n",
        "joblib.dump(original_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'original_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'original_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'original_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'original_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_boruta dataset\n",
        "joblib.dump(ros_boruta_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_l1 dataset\n",
        "joblib.dump(ros_l1_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_tr dataset\n",
        "joblib.dump(ros_tr_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_tr_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_boruta dataset\n",
        "joblib.dump(renn_boruta_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_l1 dataset\n",
        "joblib.dump(renn_l1_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_tr dataset\n",
        "joblib.dump(renn_tr_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_tr_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_boruta dataset\n",
        "joblib.dump(smote_boruta_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_l1 dataset\n",
        "joblib.dump(smote_l1_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_tr dataset\n",
        "joblib.dump(smote_tr_set_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_set_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_labels_train, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_labels_test, PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_tr_labels_test' + '.gz', compress=('gzip', 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/ml_project_dataset/smote_tr_labels_test.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYr8JhupcuMF",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPnf7O-QyaH-",
        "colab_type": "text"
      },
      "source": [
        "The origial dataset and nine new datasets generated by the feature selection and resampling methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd091sevQ7DH",
        "colab_type": "text"
      },
      "source": [
        "Dataset | Total instance | cls | Description\n",
        "--- | --- | --- | ---\n",
        "Original (OR) | 20327 | 0.0134 | No resampled and feature selection\n",
        "Ros_Boruta (RB) | 40116 | 1 | ROS resampled and Boruta selection\n",
        "Ros_L1 (RL) | 40116 | 1 | ROS resampled and L1-based selection\n",
        "Ros_Tr (RT) | 40116 | 1 | ROS resampled and Tree-based selection\n",
        "Renn_Boruta (EB) | 19753 | 0.0138 | RENN resampled and Boruta selection\n",
        "Renn_L1 (EL) | 19817 | 0.0138 | RENN resampled and L1-based selection\n",
        "Renn_Tr (ET) | 19875 | 0.0137 | RENN resampled and Tree-based selection\n",
        "Smote_Boruta (SB) | 31643 | 0.966 | SMOTE-ENN resampled and Boruta selection\n",
        "Smote_L1 (SL) | 32207 | 1.0045 | SMOTE-ENN resampled and L1-based selection\n",
        "Smote_Tr (ST) | 38132 | 1.0012 | SMOTE-ENN resampled and Tree-based selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JafooTz4zkTT",
        "colab_type": "text"
      },
      "source": [
        "# Train the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO5pUXkPc0pN",
        "colab_type": "text"
      },
      "source": [
        "### Model description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBsQ53J0W65U",
        "colab_type": "text"
      },
      "source": [
        "Model | Description\n",
        "--- | ---\n",
        "DecisionTreeClassifier (DT) | Decision Tree algorithm implemented by scikit-learn\n",
        "LinearSVC (LE) | Support vector machine algorithm implemented by scikit-learn\n",
        "KNeighborsClassifier (KNN) | K-Nearest Neighbors algorithm implemented by scikit-learn\n",
        "GaussianNB (GNB) | Naive Bayes algorithm implemented by scikit-learn\n",
        "SkopeRules (SR) | Skope-rules algorithm implemented by scikit-learn-contrib\n",
        "RandomForestClassifier (RF) | Random Forest algorithm implemented by scikit-learn\n",
        "AdaBoostClassifier (AD) | Boosting algorithm implemented by scikit-learn\n",
        "VotingClassifier (VT) | Hybrid algorithm implemented by scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdkgffIPnUpD",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkpwq-kencIu",
        "colab_type": "text"
      },
      "source": [
        "For this binary classification problem, we care more about the minority class, the ones that are denied.\n",
        "However, in this case, recall should be of more emphasis than precision, as we want the false negative to be as small as possible, we choose F2 score as evaluation criterion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUEtbpP5Uxcg",
        "colab_type": "text"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gur5v8QEtPAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "#load the 10 datasets\n",
        "#1. original dataset\n",
        "original_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'original_set_train' + '.gz')\n",
        "original_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'original_set_test' + '.gz')\n",
        "original_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'original_labels_train' + '.gz')\n",
        "original_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'original_labels_test' + '.gz')\n",
        "\n",
        "#2. ros_boruta dataset\n",
        "ros_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_boruta_set_train' + '.gz')\n",
        "ros_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_boruta_set_test' + '.gz')\n",
        "ros_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_boruta_labels_train' + '.gz')\n",
        "ros_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_boruta_labels_test' + '.gz')\n",
        "\n",
        "#3. ros_l1 dataset\n",
        "ros_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_l1_set_train' + '.gz')\n",
        "ros_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_l1_set_test' + '.gz')\n",
        "ros_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_l1_labels_train' + '.gz')\n",
        "ros_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_l1_labels_test' + '.gz')\n",
        "\n",
        "#4. ros_tr dataset\n",
        "ros_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_tr_set_train' + '.gz')\n",
        "ros_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_tr_set_test' + '.gz')\n",
        "ros_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_tr_labels_train' + '.gz')\n",
        "ros_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'ros_tr_labels_test' + '.gz')\n",
        "\n",
        "#5. renn_boruta dataset\n",
        "renn_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_boruta_set_train' + '.gz')\n",
        "renn_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_boruta_set_test' + '.gz')\n",
        "renn_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_boruta_labels_train' + '.gz')\n",
        "renn_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_boruta_labels_test' + '.gz')\n",
        "\n",
        "#6. renn_l1 dataset\n",
        "renn_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_l1_set_train' + '.gz')\n",
        "renn_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_l1_set_test' + '.gz')\n",
        "renn_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_l1_labels_train' + '.gz')\n",
        "renn_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_l1_labels_test' + '.gz')\n",
        "\n",
        "#7. renn_tr dataset\n",
        "renn_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_tr_set_train' + '.gz')\n",
        "renn_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_tr_set_test' + '.gz')\n",
        "renn_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_tr_labels_train' + '.gz')\n",
        "renn_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'renn_tr_labels_test' + '.gz')\n",
        "\n",
        "#8. smote_boruta dataset\n",
        "smote_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_boruta_set_train' + '.gz')\n",
        "smote_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_boruta_set_test' + '.gz')\n",
        "smote_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_boruta_labels_train' + '.gz')\n",
        "smote_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_boruta_labels_test' + '.gz')\n",
        "\n",
        "#9. smote_l1 dataset\n",
        "smote_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_l1_set_train' + '.gz')\n",
        "smote_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_l1_set_test' + '.gz')\n",
        "smote_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_l1_labels_train' + '.gz')\n",
        "smote_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_l1_labels_test' + '.gz')\n",
        "\n",
        "#10. smote_tr dataset\n",
        "smote_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_tr_set_train' + '.gz')\n",
        "smote_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_tr_set_test' + '.gz')\n",
        "smote_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_tr_labels_train' + '.gz')\n",
        "smote_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'ml_project_dataset/' + 'smote_tr_labels_test' + '.gz')\n",
        "\n",
        "#define the dateset list\n",
        "train_set_list = [original_set_train,ros_boruta_set_train,ros_l1_set_train,ros_tr_set_train, \\\n",
        "                 renn_boruta_set_train,renn_l1_set_train,renn_tr_set_train,smote_boruta_set_train,\\\n",
        "                 smote_l1_set_train,smote_tr_set_train]\n",
        "train_labels_list = [original_labels_train,ros_boruta_labels_train,ros_l1_labels_train, \\\n",
        "                    ros_tr_labels_train,renn_boruta_labels_train,renn_l1_labels_train \\\n",
        "                    ,renn_tr_labels_train,smote_boruta_labels_train,smote_l1_labels_train,smote_tr_labels_train]\n",
        "test_set_list = [original_set_test,ros_boruta_set_test,ros_l1_set_test,ros_tr_set_test,renn_boruta_set_test, \\\n",
        "                renn_l1_set_test,renn_tr_set_test,smote_boruta_set_test,smote_l1_set_test,smote_tr_set_test]\n",
        "test_labels_list = [original_labels_test,ros_boruta_labels_test,ros_l1_labels_test,ros_tr_labels_test, \\\n",
        "                  renn_boruta_labels_test,renn_l1_labels_test,renn_tr_labels_test,smote_boruta_labels_test, \\\n",
        "                  smote_l1_labels_test,smote_tr_labels_test]\n",
        "dataset_name_list = [\"original\",\"ros_boruta\",\"ros_l1\",\"ros_tr\",\"renn_boruta\", \\\n",
        "                     \"renn_l1\",\"renn_tr\",\"smote_boruta\",\"smote_l1\",\"smote_tr\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u5G1rJAwPjE",
        "colab_type": "text"
      },
      "source": [
        "### Tree models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nPcrLv7pvUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,roc_auc_score, log_loss,roc_curve\n",
        "import time\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "dt_clf = DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VtsToVfJIfx",
        "colab_type": "code",
        "outputId": "d164ea98-fea4-44ad-f1cf-9a0ccdf8e5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  #train the model against 10 dataset\n",
        "  train_start_time = time.time()\n",
        "  cross_val_score(dt_clf, train_set_list[i], train_labels_list[i], scoring = ftwo_scorer, cv=10)\n",
        "  train_end_time = time.time()\n",
        "  train_duration = train_end_time - train_start_time\n",
        "  test_start_time = time.time()\n",
        "  prediction = cross_val_predict(dt_clf, test_set_list[i], test_labels_list[i], cv=10)\n",
        "  test_end_time = time.time()\n",
        "  test_duration = test_end_time - test_start_time\n",
        "\n",
        "  f2_score = fbeta_score(test_labels_list[i], prediction, average='macro', beta=2)\n",
        "  cfm = confusion_matrix(test_labels_list[i], prediction)\n",
        "  accuracy = accuracy_score(test_labels_list[i], prediction)\n",
        "  precision = precision_score(test_labels_list[i], prediction)\n",
        "  recall = recall_score(test_labels_list[i], prediction)\n",
        "  roc_auc = roc_auc_score(test_labels_list[i], prediction)\n",
        "  log_score = log_loss(test_labels_list[i], prediction)\n",
        "\n",
        "  print(\"The f2 score of model trained against \" + dataset_name_list[i] + \" is \" + str(f2_score))\n",
        "  print(\"The confusion matrix of model trained against \" + dataset_name_list[i] + \" is \" + str(cfm))\n",
        "  print(\"The accuracy of model trained against \" + dataset_name_list[i] + \" is \" + str(accuracy))\n",
        "  print(\"The precision score of model trained against \" + dataset_name_list[i] + \" is \" + str(precision))\n",
        "  print(\"The recall score of model trained against \" + dataset_name_list[i] + \" is \" + str(recall))\n",
        "  print(\"The auc score of model trained against \" + dataset_name_list[i] + \" is \" + str(roc_auc))\n",
        "  print(\"The log loss of model trained against \" + dataset_name_list[i] + \" is \" + str(log_score))\n",
        "  print(\"Time duration of model trained against \" + dataset_name_list[i] + \" is \" + str(train_duration))\n",
        "  print(\"Time duration of model test against \" + dataset_name_list[i] + \" is \" + str(test_duration))\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against original is 0.7744920706039837\n",
            "The confusion matrix of model trained against original is [[3991   28]\n",
            " [  20   27]]\n",
            "The accuracy of model trained against original is 0.9881947860304968\n",
            "The precision score of model trained against original is 0.4909090909090909\n",
            "The recall score of model trained against original is 0.574468085106383\n",
            "The auc score of model trained against original is 0.7837505889577697\n",
            "The log loss of model trained against original is 0.4077431519143537\n",
            "Time duration of model trained against original is 1.7347784042358398\n",
            "Time duration of model test against original is 0.24266695976257324\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_boruta is 0.9760543636401822\n",
            "The confusion matrix of model trained against ros_boruta is [[3875  150]\n",
            " [  42 3957]]\n",
            "The accuracy of model trained against ros_boruta is 0.9760717846460618\n",
            "The precision score of model trained against ros_boruta is 0.9634769905040176\n",
            "The recall score of model trained against ros_boruta is 0.9894973743435859\n",
            "The auc score of model trained against ros_boruta is 0.9761151467991223\n",
            "The log loss of model trained against ros_boruta is 0.8264662272479296\n",
            "Time duration of model trained against ros_boruta is 1.188103199005127\n",
            "Time duration of model test against ros_boruta is 0.2618672847747803\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_l1 is 0.9812758377007555\n",
            "The confusion matrix of model trained against ros_l1 is [[3886  139]\n",
            " [  11 3988]]\n",
            "The accuracy of model trained against ros_l1 is 0.9813060817547358\n",
            "The precision score of model trained against ros_l1 is 0.9663193603101526\n",
            "The recall score of model trained against ros_l1 is 0.997249312328082\n",
            "The auc score of model trained against ros_l1 is 0.9813575754186994\n",
            "The log loss of model trained against ros_l1 is 0.6456789136689189\n",
            "Time duration of model trained against ros_l1 is 1.889922857284546\n",
            "Time duration of model test against ros_l1 is 0.4019780158996582\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_tr is 0.9838922912787686\n",
            "The confusion matrix of model trained against ros_tr is [[3896  129]\n",
            " [   0 3999]]\n",
            "The accuracy of model trained against ros_tr is 0.9839232303090728\n",
            "The precision score of model trained against ros_tr is 0.96875\n",
            "The recall score of model trained against ros_tr is 1.0\n",
            "The auc score of model trained against ros_tr is 0.9839751552795031\n",
            "The log loss of model trained against ros_tr is 0.5552848084511441\n",
            "Time duration of model trained against ros_tr is 3.6328020095825195\n",
            "Time duration of model test against ros_tr is 0.7305943965911865\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_boruta is 0.8441970686534626\n",
            "The confusion matrix of model trained against renn_boruta is [[3879   13]\n",
            " [  19   40]]\n",
            "The accuracy of model trained against renn_boruta is 0.9919007846114908\n",
            "The precision score of model trained against renn_boruta is 0.7547169811320755\n",
            "The recall score of model trained against renn_boruta is 0.6779661016949152\n",
            "The auc score of model trained against renn_boruta is 0.8373129583500271\n",
            "The log loss of model trained against renn_boruta is 0.27973962019836446\n",
            "Time duration of model trained against renn_boruta is 0.41494178771972656\n",
            "Time duration of model test against renn_boruta is 0.07647514343261719\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_l1 is 0.7934829970635597\n",
            "The confusion matrix of model trained against renn_l1 is [[3888   22]\n",
            " [  22   32]]\n",
            "The accuracy of model trained against renn_l1 is 0.9889001009081736\n",
            "The precision score of model trained against renn_l1 is 0.5925925925925926\n",
            "The recall score of model trained against renn_l1 is 0.5925925925925926\n",
            "The auc score of model trained against renn_l1 is 0.7934829970635596\n",
            "The log loss of model trained against renn_l1 is 0.383381370464061\n",
            "Time duration of model trained against renn_l1 is 0.5764424800872803\n",
            "Time duration of model test against renn_l1 is 0.10558176040649414\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_tr is 0.8311671763506625\n",
            "The confusion matrix of model trained against renn_tr is [[3907   17]\n",
            " [  17   34]]\n",
            "The accuracy of model trained against renn_tr is 0.9914465408805031\n",
            "The precision score of model trained against renn_tr is 0.6666666666666666\n",
            "The recall score of model trained against renn_tr is 0.6666666666666666\n",
            "The auc score of model trained against renn_tr is 0.8311671763506625\n",
            "The log loss of model trained against renn_tr is 0.29542943159327806\n",
            "Time duration of model trained against renn_tr is 0.9108729362487793\n",
            "Time duration of model test against renn_tr is 0.12611961364746094\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_boruta is 0.9865624106786144\n",
            "The confusion matrix of model trained against smote_boruta is [[3269   45]\n",
            " [  40 2975]]\n",
            "The accuracy of model trained against smote_boruta is 0.9865697582556486\n",
            "The precision score of model trained against smote_boruta is 0.9850993377483444\n",
            "The recall score of model trained against smote_boruta is 0.9867330016583747\n",
            "The auc score of model trained against smote_boruta is 0.9865771224344982\n",
            "The log loss of model trained against smote_boruta is 0.4638698017778121\n",
            "Time duration of model trained against smote_boruta is 0.7429771423339844\n",
            "Time duration of model test against smote_boruta is 0.15259838104248047\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_l1 is 0.9785603725101897\n",
            "The confusion matrix of model trained against smote_l1 is [[3182   56]\n",
            " [  82 3122]]\n",
            "The accuracy of model trained against smote_l1 is 0.9785780813411984\n",
            "The precision score of model trained against smote_l1 is 0.9823788546255506\n",
            "The recall score of model trained against smote_l1 is 0.9744069912609239\n",
            "The auc score of model trained against smote_l1 is 0.9785561824741926\n",
            "The log loss of model trained against smote_l1 is 0.739893809368794\n",
            "Time duration of model trained against smote_l1 is 1.2665019035339355\n",
            "Time duration of model test against smote_l1 is 0.2529177665710449\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_tr is 0.9816463643146193\n",
            "The confusion matrix of model trained against smote_tr is [[3752   75]\n",
            " [  65 3735]]\n",
            "The accuracy of model trained against smote_tr is 0.9816441589091386\n",
            "The precision score of model trained against smote_tr is 0.9803149606299213\n",
            "The recall score of model trained against smote_tr is 0.9828947368421053\n",
            "The auc score of model trained against smote_tr is 0.9816485704069423\n",
            "The log loss of model trained against smote_tr is 0.6339961538081509\n",
            "Time duration of model trained against smote_tr is 2.4523651599884033\n",
            "Time duration of model test against smote_tr is 0.5748379230499268\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToG_GdIPEfsC",
        "colab_type": "text"
      },
      "source": [
        "### Linear models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n4TSUe_Et2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,roc_auc_score, log_loss,roc_curve\n",
        "import time\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "le_clf = LinearSVC(random_state=0, tol=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylBXCz-eSVPN",
        "colab_type": "code",
        "outputId": "ad879c7b-46a3-4ee4-e4ae-5516da85aa41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  #train the model against 10 dataset\n",
        "  train_start_time = time.time()\n",
        "  cross_val_score(le_clf, train_set_list[i], train_labels_list[i], scoring = ftwo_scorer, cv=10)\n",
        "  train_end_time = time.time()\n",
        "  train_duration = train_end_time - train_start_time\n",
        "  test_start_time = time.time()\n",
        "  prediction = cross_val_predict(le_clf, test_set_list[i], test_labels_list[i], cv=10)\n",
        "  test_end_time = time.time()\n",
        "  test_duration = test_end_time - test_start_time\n",
        "\n",
        "  f2_score = fbeta_score(test_labels_list[i], prediction, average='macro', beta=2)\n",
        "  cfm = confusion_matrix(test_labels_list[i], prediction)\n",
        "  accuracy = accuracy_score(test_labels_list[i], prediction)\n",
        "  precision = precision_score(test_labels_list[i], prediction)\n",
        "  recall = recall_score(test_labels_list[i], prediction)\n",
        "  roc_auc = roc_auc_score(test_labels_list[i], prediction)\n",
        "  log_score = log_loss(test_labels_list[i], prediction)\n",
        "\n",
        "  print(\"The f2 score of model trained against \" + dataset_name_list[i] + \" is \" + str(f2_score))\n",
        "  print(\"The confusion matrix of model trained against \" + dataset_name_list[i] + \" is \" + str(cfm))\n",
        "  print(\"The accuracy of model trained against \" + dataset_name_list[i] + \" is \" + str(accuracy))\n",
        "  print(\"The precision score of model trained against \" + dataset_name_list[i] + \" is \" + str(precision))\n",
        "  print(\"The recall score of model trained against \" + dataset_name_list[i] + \" is \" + str(recall))\n",
        "  print(\"The auc score of model trained against \" + dataset_name_list[i] + \" is \" + str(roc_auc))\n",
        "  print(\"The log loss of model trained against \" + dataset_name_list[i] + \" is \" + str(log_score))\n",
        "  print(\"Time duration of model trained against \" + dataset_name_list[i] + \" is \" + str(train_duration))\n",
        "  print(\"Time duration of model test against \" + dataset_name_list[i] + \" is \" + str(test_duration))\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against original is 0.6581709251324499\n",
            "The confusion matrix of model trained against original is [[4016    3]\n",
            " [  34   13]]\n",
            "The accuracy of model trained against original is 0.9909001475651746\n",
            "The precision score of model trained against original is 0.8125\n",
            "The recall score of model trained against original is 0.2765957446808511\n",
            "The auc score of model trained against original is 0.6379246451694875\n",
            "The log loss of model trained against original is 0.3142983584367904\n",
            "Time duration of model trained against original is 3.579641103744507\n",
            "Time duration of model test against original is 0.38751935958862305\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against ros_boruta is 0.852887885442009\n",
            "The confusion matrix of model trained against ros_boruta is [[3581  444]\n",
            " [ 733 3266]]\n",
            "The accuracy of model trained against ros_boruta is 0.8533150548354935\n",
            "The precision score of model trained against ros_boruta is 0.8803234501347709\n",
            "The recall score of model trained against ros_boruta is 0.816704176044011\n",
            "The auc score of model trained against ros_boruta is 0.8531968085188999\n",
            "The log loss of model trained against ros_boruta is 5.066362766459234\n",
            "Time duration of model trained against ros_boruta is 15.70293378829956\n",
            "Time duration of model test against ros_boruta is 2.430683135986328\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against ros_l1 is 0.8272712983803792\n",
            "The confusion matrix of model trained against ros_l1 is [[3309  716]\n",
            " [ 670 3329]]\n",
            "The accuracy of model trained against ros_l1 is 0.8272681954137587\n",
            "The precision score of model trained against ros_l1 is 0.822991347342398\n",
            "The recall score of model trained against ros_l1 is 0.8324581145286322\n",
            "The auc score of model trained against ros_l1 is 0.8272849578854341\n",
            "The log loss of model trained against ros_l1 is 5.966016524813837\n",
            "Time duration of model trained against ros_l1 is 21.943746328353882\n",
            "Time duration of model test against ros_l1 is 3.569053888320923\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against ros_tr is 0.8090063433867388\n",
            "The confusion matrix of model trained against ros_tr is [[3349  676]\n",
            " [ 855 3144]]\n",
            "The accuracy of model trained against ros_tr is 0.80919740777667\n",
            "The precision score of model trained against ros_tr is 0.8230366492146597\n",
            "The recall score of model trained against ros_tr is 0.7861965491372843\n",
            "The auc score of model trained against ros_tr is 0.809123119289139\n",
            "The log loss of model trained against ros_tr is 6.590155432262097\n",
            "Time duration of model trained against ros_tr is 41.125633001327515\n",
            "Time duration of model test against ros_tr is 4.597985029220581\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_boruta is 0.7033056967231599\n",
            "The confusion matrix of model trained against renn_boruta is [[3892    0]\n",
            " [  38   21]]\n",
            "The accuracy of model trained against renn_boruta is 0.9903821817261452\n",
            "The precision score of model trained against renn_boruta is 1.0\n",
            "The recall score of model trained against renn_boruta is 0.3559322033898305\n",
            "The auc score of model trained against renn_boruta is 0.6779661016949152\n",
            "The log loss of model trained against renn_boruta is 0.3321876747675549\n",
            "Time duration of model trained against renn_boruta is 1.0244712829589844\n",
            "Time duration of model test against renn_boruta is 0.2404489517211914\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_l1 is 0.7206764198087077\n",
            "The confusion matrix of model trained against renn_l1 is [[3910    0]\n",
            " [  33   21]]\n",
            "The accuracy of model trained against renn_l1 is 0.9916750756811302\n",
            "The precision score of model trained against renn_l1 is 1.0\n",
            "The recall score of model trained against renn_l1 is 0.3888888888888889\n",
            "The auc score of model trained against renn_l1 is 0.6944444444444444\n",
            "The log loss of model trained against renn_l1 is 0.28753269955400007\n",
            "Time duration of model trained against renn_l1 is 1.484659194946289\n",
            "Time duration of model test against renn_l1 is 0.25626087188720703\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against renn_tr is 0.6703171257965779\n",
            "The confusion matrix of model trained against renn_tr is [[3924    0]\n",
            " [  36   15]]\n",
            "The accuracy of model trained against renn_tr is 0.9909433962264151\n",
            "The precision score of model trained against renn_tr is 1.0\n",
            "The recall score of model trained against renn_tr is 0.29411764705882354\n",
            "The auc score of model trained against renn_tr is 0.6470588235294118\n",
            "The log loss of model trained against renn_tr is 0.31280401263315427\n",
            "Time duration of model trained against renn_tr is 2.72121524810791\n",
            "Time duration of model test against renn_tr is 0.47659945487976074\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against smote_boruta is 0.9221918540715213\n",
            "The confusion matrix of model trained against smote_boruta is [[3104  210]\n",
            " [ 279 2736]]\n",
            "The accuracy of model trained against smote_boruta is 0.9227366092589666\n",
            "The precision score of model trained against smote_boruta is 0.9287169042769857\n",
            "The recall score of model trained against smote_boruta is 0.9074626865671642\n",
            "The auc score of model trained against smote_boruta is 0.9220475774416992\n",
            "The log loss of model trained against smote_boruta is 2.668609507437458\n",
            "Time duration of model trained against smote_boruta is 5.471795558929443\n",
            "Time duration of model test against smote_boruta is 1.2293100357055664\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against smote_l1 is 0.8811728554591265\n",
            "The confusion matrix of model trained against smote_l1 is [[2891  347]\n",
            " [ 418 2786]]\n",
            "The accuracy of model trained against smote_l1 is 0.8812480596088171\n",
            "The precision score of model trained against smote_l1 is 0.8892435365464411\n",
            "The recall score of model trained against smote_l1 is 0.869538077403246\n",
            "The auc score of model trained against smote_l1 is 0.8811865803940256\n",
            "The log loss of model trained against smote_l1 is 4.10158978615569\n",
            "Time duration of model trained against smote_l1 is 10.10624384880066\n",
            "Time duration of model test against smote_l1 is 1.793030023574829\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against smote_tr is 0.8312017755773644\n",
            "The confusion matrix of model trained against smote_tr is [[3222  605]\n",
            " [ 682 3118]]\n",
            "The accuracy of model trained against smote_tr is 0.831257375114724\n",
            "The precision score of model trained against smote_tr is 0.8374966424926135\n",
            "The recall score of model trained against smote_tr is 0.8205263157894737\n",
            "The auc score of model trained against smote_tr is 0.831219520580914\n",
            "The log loss of model trained against smote_tr is 5.8282272160345245\n",
            "Time duration of model trained against smote_tr is 34.370131969451904\n",
            "Time duration of model test against smote_tr is 4.206855058670044\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSTmBtNGuXZy",
        "colab_type": "text"
      },
      "source": [
        "### Distance-based models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smD8APfCusG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,roc_auc_score, log_loss,roc_curve\n",
        "import time\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "n_neighbors = 3\n",
        "knn_clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqbZWupoMhyG",
        "colab_type": "code",
        "outputId": "d4fc41a5-3a74-4c79-c2de-663cc39f0a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  #train the model against 10 dataset\n",
        "  train_start_time = time.time()\n",
        "  cross_val_score(knn_clf, train_set_list[i], train_labels_list[i], scoring = ftwo_scorer, cv=10)\n",
        "  train_end_time = time.time()\n",
        "  train_duration = train_end_time - train_start_time\n",
        "  test_start_time = time.time()\n",
        "  prediction = cross_val_predict(knn_clf, test_set_list[i], test_labels_list[i], cv=10)\n",
        "  test_end_time = time.time()\n",
        "  test_duration = test_end_time - test_start_time\n",
        "\n",
        "  f2_score = fbeta_score(test_labels_list[i], prediction, average='macro', beta=2)\n",
        "  cfm = confusion_matrix(test_labels_list[i], prediction)\n",
        "  accuracy = accuracy_score(test_labels_list[i], prediction)\n",
        "  precision = precision_score(test_labels_list[i], prediction)\n",
        "  recall = recall_score(test_labels_list[i], prediction)\n",
        "  roc_auc = roc_auc_score(test_labels_list[i], prediction)\n",
        "  log_score = log_loss(test_labels_list[i], prediction)\n",
        "\n",
        "  print(\"The f2 score of model trained against \" + dataset_name_list[i] + \" is \" + str(f2_score))\n",
        "  print(\"The confusion matrix of model trained against \" + dataset_name_list[i] + \" is \" + str(cfm))\n",
        "  print(\"The accuracy of model trained against \" + dataset_name_list[i] + \" is \" + str(accuracy))\n",
        "  print(\"The precision score of model trained against \" + dataset_name_list[i] + \" is \" + str(precision))\n",
        "  print(\"The recall score of model trained against \" + dataset_name_list[i] + \" is \" + str(recall))\n",
        "  print(\"The auc score of model trained against \" + dataset_name_list[i] + \" is \" + str(roc_auc))\n",
        "  print(\"The log loss of model trained against \" + dataset_name_list[i] + \" is \" + str(log_score))\n",
        "  print(\"Time duration of model trained against \" + dataset_name_list[i] + \" is \" + str(train_duration))\n",
        "  print(\"Time duration of model test against \" + dataset_name_list[i] + \" is \" + str(test_duration))\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against original is 0.6809456129280018\n",
            "The confusion matrix of model trained against original is [[4016    3]\n",
            " [  32   15]]\n",
            "The accuracy of model trained against original is 0.9913920314805705\n",
            "The precision score of model trained against original is 0.8333333333333334\n",
            "The recall score of model trained against original is 0.3191489361702128\n",
            "The auc score of model trained against original is 0.6592012409141683\n",
            "The log loss of model trained against original is 0.2973092898706759\n",
            "Time duration of model trained against original is 13.678386211395264\n",
            "Time duration of model test against original is 0.9736738204956055\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_boruta is 0.968956446243028\n",
            "The confusion matrix of model trained against ros_boruta is [[3852  173]\n",
            " [  76 3923]]\n",
            "The accuracy of model trained against ros_boruta is 0.9689680957128615\n",
            "The precision score of model trained against ros_boruta is 0.957763671875\n",
            "The recall score of model trained against ros_boruta is 0.980995248812203\n",
            "The auc score of model trained against ros_boruta is 0.9690069411762878\n",
            "The log loss of model trained against ros_boruta is 1.0718212428574514\n",
            "Time duration of model trained against ros_boruta is 25.796083688735962\n",
            "Time duration of model test against ros_boruta is 1.764075517654419\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_l1 is 0.9710471952548965\n",
            "The confusion matrix of model trained against ros_l1 is [[3839  186]\n",
            " [  46 3953]]\n",
            "The accuracy of model trained against ros_l1 is 0.9710867397806581\n",
            "The precision score of model trained against ros_l1 is 0.9550616090843199\n",
            "The recall score of model trained against ros_l1 is 0.9884971242810703\n",
            "The auc score of model trained against ros_l1 is 0.9711429720784233\n",
            "The log loss of model trained against ros_l1 is 0.998647164598866\n",
            "Time duration of model trained against ros_l1 is 32.0123565196991\n",
            "Time duration of model test against ros_l1 is 2.120098829269409\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_tr is 0.9810320847578311\n",
            "The confusion matrix of model trained against ros_tr is [[3889  136]\n",
            " [  16 3983]]\n",
            "The accuracy of model trained against ros_tr is 0.9810568295114656\n",
            "The precision score of model trained against ros_tr is 0.9669822772517601\n",
            "The recall score of model trained against ros_tr is 0.9959989997499374\n",
            "The auc score of model trained against ros_tr is 0.9811050899370805\n",
            "The log loss of model trained against ros_tr is 0.6542874822129783\n",
            "Time duration of model trained against ros_tr is 39.388832569122314\n",
            "Time duration of model test against ros_tr is 2.5833451747894287\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_boruta is 0.8485381511736529\n",
            "The confusion matrix of model trained against renn_boruta is [[3888    4]\n",
            " [  20   39]]\n",
            "The accuracy of model trained against renn_boruta is 0.9939255884586181\n",
            "The precision score of model trained against renn_boruta is 0.9069767441860465\n",
            "The recall score of model trained against renn_boruta is 0.6610169491525424\n",
            "The auc score of model trained against renn_boruta is 0.8299945999616771\n",
            "The log loss of model trained against renn_boruta is 0.20980355147243254\n",
            "Time duration of model trained against renn_boruta is 6.357152700424194\n",
            "Time duration of model test against renn_boruta is 0.4999697208404541\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_l1 is 0.8104529917739529\n",
            "The confusion matrix of model trained against renn_l1 is [[3908    2]\n",
            " [  23   31]]\n",
            "The accuracy of model trained against renn_l1 is 0.9936932391523713\n",
            "The precision score of model trained against renn_l1 is 0.9393939393939394\n",
            "The recall score of model trained against renn_l1 is 0.5740740740740741\n",
            "The auc score of model trained against renn_l1 is 0.7867812825613336\n",
            "The log loss of model trained against renn_l1 is 0.21782820612200585\n",
            "Time duration of model trained against renn_l1 is 8.021714925765991\n",
            "Time duration of model test against renn_l1 is 0.5928916931152344\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_tr is 0.7969813017289943\n",
            "The confusion matrix of model trained against renn_tr is [[3921    3]\n",
            " [  23   28]]\n",
            "The accuracy of model trained against renn_tr is 0.9934591194968554\n",
            "The precision score of model trained against renn_tr is 0.9032258064516129\n",
            "The recall score of model trained against renn_tr is 0.5490196078431373\n",
            "The auc score of model trained against renn_tr is 0.7741275409246268\n",
            "The log loss of model trained against renn_tr is 0.22591461259370366\n",
            "Time duration of model trained against renn_tr is 9.73214864730835\n",
            "Time duration of model test against renn_tr is 0.7243187427520752\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_boruta is 0.9895301834139694\n",
            "The confusion matrix of model trained against smote_boruta is [[3283   31]\n",
            " [  35 2980]]\n",
            "The accuracy of model trained against smote_boruta is 0.9895718122926213\n",
            "The precision score of model trained against smote_boruta is 0.9897044171371637\n",
            "The recall score of model trained against smote_boruta is 0.988391376451078\n",
            "The auc score of model trained against smote_boruta is 0.9895185608869752\n",
            "The log loss of model trained against smote_boruta is 0.3601807599280214\n",
            "Time duration of model trained against smote_boruta is 15.956318378448486\n",
            "Time duration of model test against smote_boruta is 1.1465950012207031\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_l1 is 0.9818161987013381\n",
            "The confusion matrix of model trained against smote_l1 is [[3195   43]\n",
            " [  74 3130]]\n",
            "The accuracy of model trained against smote_l1 is 0.9818379385284073\n",
            "The precision score of model trained against smote_l1 is 0.9864481563189411\n",
            "The recall score of model trained against smote_l1 is 0.9769038701622972\n",
            "The auc score of model trained against smote_l1 is 0.9818120339075846\n",
            "The log loss of model trained against smote_l1 is 0.6273007173073663\n",
            "Time duration of model trained against smote_l1 is 20.479743003845215\n",
            "Time duration of model test against smote_l1 is 1.4431521892547607\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_tr is 0.9825614432862246\n",
            "The confusion matrix of model trained against smote_tr is [[3761   66]\n",
            " [  67 3733]]\n",
            "The accuracy of model trained against smote_tr is 0.9825619509636817\n",
            "The precision score of model trained against smote_tr is 0.9826270071071335\n",
            "The recall score of model trained against smote_tr is 0.9823684210526316\n",
            "The auc score of model trained against smote_tr is 0.9825612682738988\n",
            "The log loss of model trained against smote_tr is 0.6022957957196171\n",
            "Time duration of model trained against smote_tr is 35.73758268356323\n",
            "Time duration of model test against smote_tr is 2.4118967056274414\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR9TjcKn8vcl",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE-Df2mg81mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,roc_auc_score, log_loss,roc_curve\n",
        "import time\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "gnb_clf = GaussianNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt9rkbsMVdmJ",
        "colab_type": "code",
        "outputId": "597cc92f-34fe-45a1-b889-ee8154d1664a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  #train the model against 10 dataset\n",
        "  train_start_time = time.time()\n",
        "  cross_val_score(gnb_clf, train_set_list[i].toarray(), train_labels_list[i], scoring = ftwo_scorer, cv=10)\n",
        "  train_end_time = time.time()\n",
        "  train_duration = train_end_time - train_start_time\n",
        "  test_start_time = time.time()\n",
        "  prediction = cross_val_predict(gnb_clf, test_set_list[i].toarray(), test_labels_list[i], cv=10)\n",
        "  test_end_time = time.time()\n",
        "  test_duration = test_end_time - test_start_time\n",
        "\n",
        "  f2_score = fbeta_score(test_labels_list[i], prediction, average='macro', beta=2)\n",
        "  cfm = confusion_matrix(test_labels_list[i], prediction)\n",
        "  accuracy = accuracy_score(test_labels_list[i], prediction)\n",
        "  precision = precision_score(test_labels_list[i], prediction)\n",
        "  recall = recall_score(test_labels_list[i], prediction)\n",
        "  roc_auc = roc_auc_score(test_labels_list[i], prediction)\n",
        "  log_score = log_loss(test_labels_list[i], prediction)\n",
        "\n",
        "  print(\"The f2 score of model trained against \" + dataset_name_list[i] + \" is \" + str(f2_score))\n",
        "  print(\"The confusion matrix of model trained against \" + dataset_name_list[i] + \" is \" + str(cfm))\n",
        "  print(\"The accuracy of model trained against \" + dataset_name_list[i] + \" is \" + str(accuracy))\n",
        "  print(\"The precision score of model trained against \" + dataset_name_list[i] + \" is \" + str(precision))\n",
        "  print(\"The recall score of model trained against \" + dataset_name_list[i] + \" is \" + str(recall))\n",
        "  print(\"The auc score of model trained against \" + dataset_name_list[i] + \" is \" + str(roc_auc))\n",
        "  print(\"The log loss of model trained against \" + dataset_name_list[i] + \" is \" + str(log_score))\n",
        "  print(\"Time duration of model trained against \" + dataset_name_list[i] + \" is \" + str(train_duration))\n",
        "  print(\"Time duration of model test against \" + dataset_name_list[i] + \" is \" + str(test_duration))\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against original is 0.23766671705907808\n",
            "The confusion matrix of model trained against original is [[1499 2520]\n",
            " [  20   27]]\n",
            "The accuracy of model trained against original is 0.3753074274471225\n",
            "The precision score of model trained against original is 0.01060070671378092\n",
            "The recall score of model trained against original is 0.574468085106383\n",
            "The auc score of model trained against original is 0.4737232189652344\n",
            "The log loss of model trained against original is 21.576612648449885\n",
            "Time duration of model trained against original is 0.7447347640991211\n",
            "Time duration of model test against original is 0.2731916904449463\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_boruta is 0.7014121119024469\n",
            "The confusion matrix of model trained against ros_boruta is [[4007   18]\n",
            " [2201 1798]]\n",
            "The accuracy of model trained against ros_boruta is 0.7234546360917248\n",
            "The precision score of model trained against ros_boruta is 0.9900881057268722\n",
            "The recall score of model trained against ros_boruta is 0.4496124031007752\n",
            "The auc score of model trained against ros_boruta is 0.722570176705667\n",
            "The log loss of model trained against ros_boruta is 9.551540280790196\n",
            "Time duration of model trained against ros_boruta is 0.12656235694885254\n",
            "Time duration of model test against ros_boruta is 0.03346848487854004\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_l1 is 0.7865482815380613\n",
            "The confusion matrix of model trained against ros_l1 is [[3817  208]\n",
            " [1449 2550]]\n",
            "The accuracy of model trained against ros_l1 is 0.7934945164506481\n",
            "The precision score of model trained against ros_l1 is 0.9245830311820159\n",
            "The recall score of model trained against ros_l1 is 0.6376594148537135\n",
            "The auc score of model trained against ros_l1 is 0.7929911981100866\n",
            "The log loss of model trained against ros_l1 is 7.132467447985105\n",
            "Time duration of model trained against ros_l1 is 0.14183783531188965\n",
            "Time duration of model test against ros_l1 is 0.03647208213806152\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_tr is 0.6317521904610978\n",
            "The confusion matrix of model trained against ros_tr is [[3951   74]\n",
            " [2630 1369]]\n",
            "The accuracy of model trained against ros_tr is 0.6630109670987039\n",
            "The precision score of model trained against ros_tr is 0.9487179487179487\n",
            "The recall score of model trained against ros_tr is 0.342335583895974\n",
            "The auc score of model trained against ros_tr is 0.6619752453641361\n",
            "The log loss of model trained against ros_tr is 11.639196229068833\n",
            "Time duration of model trained against ros_tr is 0.350261926651001\n",
            "Time duration of model test against ros_tr is 0.0417635440826416\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_boruta is 0.8060243041711006\n",
            "The confusion matrix of model trained against renn_boruta is [[3892    0]\n",
            " [  26   33]]\n",
            "The accuracy of model trained against renn_boruta is 0.9934193874968362\n",
            "The precision score of model trained against renn_boruta is 1.0\n",
            "The recall score of model trained against renn_boruta is 0.559322033898305\n",
            "The auc score of model trained against renn_boruta is 0.7796610169491525\n",
            "The log loss of model trained against renn_boruta is 0.22728630378832737\n",
            "Time duration of model trained against renn_boruta is 0.05754566192626953\n",
            "Time duration of model test against renn_boruta is 0.017006635665893555\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_l1 is 0.5667649710554388\n",
            "The confusion matrix of model trained against renn_l1 is [[3410  500]\n",
            " [  18   36]]\n",
            "The accuracy of model trained against renn_l1 is 0.8693239152371343\n",
            "The precision score of model trained against renn_l1 is 0.06716417910447761\n",
            "The recall score of model trained against renn_l1 is 0.6666666666666666\n",
            "The auc score of model trained against renn_l1 is 0.7693947144075021\n",
            "The log loss of model trained against renn_l1 is 4.51349292918235\n",
            "Time duration of model trained against renn_l1 is 0.06441807746887207\n",
            "Time duration of model test against renn_l1 is 0.01962876319885254\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_tr is 0.4467616678051182\n",
            "The confusion matrix of model trained against renn_tr is [[2805 1119]\n",
            " [  14   37]]\n",
            "The accuracy of model trained against renn_tr is 0.7149685534591195\n",
            "The precision score of model trained against renn_tr is 0.03200692041522491\n",
            "The recall score of model trained against renn_tr is 0.7254901960784313\n",
            "The auc score of model trained against renn_tr is 0.7201610001798884\n",
            "The log loss of model trained against renn_tr is 9.844862491813382\n",
            "Time duration of model trained against renn_tr is 0.09155607223510742\n",
            "Time duration of model test against renn_tr is 0.024759531021118164\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_boruta is 0.8020823538407438\n",
            "The confusion matrix of model trained against smote_boruta is [[3304   10]\n",
            " [1144 1871]]\n",
            "The accuracy of model trained against smote_boruta is 0.8176647179649233\n",
            "The precision score of model trained against smote_boruta is 0.9946836788942052\n",
            "The recall score of model trained against smote_boruta is 0.6205638474295191\n",
            "The auc score of model trained against smote_boruta is 0.8087731729603842\n",
            "The log loss of model trained against smote_boruta is 6.297638798499167\n",
            "Time duration of model trained against smote_boruta is 0.09827303886413574\n",
            "Time duration of model test against smote_boruta is 0.02586531639099121\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_l1 is 0.8609279533087664\n",
            "The confusion matrix of model trained against smote_l1 is [[3044  194]\n",
            " [ 690 2514]]\n",
            "The accuracy of model trained against smote_l1 is 0.8627755355479665\n",
            "The precision score of model trained against smote_l1 is 0.9283604135893648\n",
            "The recall score of model trained against smote_l1 is 0.7846441947565543\n",
            "The auc score of model trained against smote_l1 is 0.8623653339440585\n",
            "The log loss of model trained against smote_l1 is 4.739589173393745\n",
            "Time duration of model trained against smote_l1 is 0.11936140060424805\n",
            "Time duration of model test against smote_l1 is 0.030360698699951172\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_tr is 0.7185329679524726\n",
            "The confusion matrix of model trained against smote_tr is [[3763   64]\n",
            " [1945 1855]]\n",
            "The accuracy of model trained against smote_tr is 0.7365936803461387\n",
            "The precision score of model trained against smote_tr is 0.9666492965085982\n",
            "The recall score of model trained against smote_tr is 0.4881578947368421\n",
            "The auc score of model trained against smote_tr is 0.7357173063963803\n",
            "The log loss of model trained against smote_tr is 9.097738685146334\n",
            "Time duration of model trained against smote_tr is 0.34119725227355957\n",
            "Time duration of model test against smote_tr is 0.04251980781555176\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ9FCJy5vUoU",
        "colab_type": "text"
      },
      "source": [
        "### Rule-based models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyR2NjlsvaIZ",
        "colab_type": "code",
        "outputId": "fe817c87-274e-4dbe-9700-dda04213d763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "!pip install skope-rules"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skope-rules\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/b0/b56fb8d186f35089a469dc788c32ac99cf0276eae567736325b179b71db0/skope-rules-1.0.0.tar.gz (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from skope-rules) (1.17.4)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from skope-rules) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from skope-rules) (1.3.2)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from skope-rules) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17.1->skope-rules) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->skope-rules) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.1->skope-rules) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.18.1->skope-rules) (1.12.0)\n",
            "Building wheels for collected packages: skope-rules\n",
            "  Building wheel for skope-rules (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for skope-rules: filename=skope_rules-1.0.0-cp36-none-any.whl size=14591 sha256=f540ab4ee95479e2745884bdff61de468c9f08c117e74a8ffd438093438c3bee\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/8d/56/464f328ff3200c785626967ee39a6b2efc455469dab615f03e\n",
            "Successfully built skope-rules\n",
            "Installing collected packages: skope-rules\n",
            "Successfully installed skope-rules-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2XG0gefvu57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skrules import SkopeRules\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,roc_auc_score, log_loss,roc_curve\n",
        "import time\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "sr_clf = SkopeRules()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C5hgGYbwl4X",
        "colab_type": "code",
        "outputId": "7e236702-9534-44f8-8bf9-021c482eecb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  #train the model against 10 dataset\n",
        "  train_start_time = time.time()\n",
        "  cross_val_score(sr_clf, train_set_list[i].toarray(), train_labels_list[i], scoring = ftwo_scorer, cv=10)\n",
        "  train_end_time = time.time()\n",
        "  train_duration = train_end_time - train_start_time\n",
        "  test_start_time = time.time()\n",
        "  prediction = cross_val_predict(sr_clf, test_set_list[i].toarray(), test_labels_list[i], cv=10)\n",
        "  test_end_time = time.time()\n",
        "  test_duration = test_end_time - test_start_time\n",
        "\n",
        "  f2_score = fbeta_score(test_labels_list[i], prediction, average='macro', beta=2)\n",
        "  cfm = confusion_matrix(test_labels_list[i], prediction)\n",
        "  accuracy = accuracy_score(test_labels_list[i], prediction)\n",
        "  precision = precision_score(test_labels_list[i], prediction)\n",
        "  recall = recall_score(test_labels_list[i], prediction)\n",
        "  roc_auc = roc_auc_score(test_labels_list[i], prediction)\n",
        "  log_score = log_loss(test_labels_list[i], prediction)\n",
        "\n",
        "  print(\"The f2 score of model trained against \" + dataset_name_list[i] + \" is \" + str(f2_score))\n",
        "  print(\"The confusion matrix of model trained against \" + dataset_name_list[i] + \" is \" + str(cfm))\n",
        "  print(\"The accuracy of model trained against \" + dataset_name_list[i] + \" is \" + str(accuracy))\n",
        "  print(\"The precision score of model trained against \" + dataset_name_list[i] + \" is \" + str(precision))\n",
        "  print(\"The recall score of model trained against \" + dataset_name_list[i] + \" is \" + str(recall))\n",
        "  print(\"The auc score of model trained against \" + dataset_name_list[i] + \" is \" + str(roc_auc))\n",
        "  print(\"The log loss of model trained against \" + dataset_name_list[i] + \" is \" + str(log_score))\n",
        "  print(\"Time duration of model trained against \" + dataset_name_list[i] + \" is \" + str(train_duration))\n",
        "  print(\"Time duration of model test against \" + dataset_name_list[i] + \" is \" + str(test_duration))\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against original is 0.8103638406138955\n",
            "The confusion matrix of model trained against original is [[4017    2]\n",
            " [  20   27]]\n",
            "The accuracy of model trained against original is 0.9945892769306444\n",
            "The precision score of model trained against original is 0.9310344827586207\n",
            "The recall score of model trained against original is 0.574468085106383\n",
            "The auc score of model trained against original is 0.7869852244392328\n",
            "The log loss of model trained against original is 0.18688014753637464\n",
            "Time duration of model trained against original is 19.818411111831665\n",
            "Time duration of model test against original is 8.3367600440979\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_boruta is 0.8788649349349813\n",
            "The confusion matrix of model trained against ros_boruta is [[3533  492]\n",
            " [ 480 3519]]\n",
            "The accuracy of model trained against ros_boruta is 0.8788634097706879\n",
            "The precision score of model trained against ros_boruta is 0.8773373223635004\n",
            "The recall score of model trained against ros_boruta is 0.8799699924981246\n",
            "The auc score of model trained against ros_boruta is 0.878866983826702\n",
            "The log loss of model trained against ros_boruta is 4.183958631329617\n",
            "Time duration of model trained against ros_boruta is 10.826387643814087\n",
            "Time duration of model test against ros_boruta is 6.106526136398315\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_l1 is 0.8498984013075745\n",
            "The confusion matrix of model trained against ros_l1 is [[3187  838]\n",
            " [ 360 3639]]\n",
            "The accuracy of model trained against ros_l1 is 0.8506979062811565\n",
            "The precision score of model trained against ros_l1 is 0.8128210855483583\n",
            "The recall score of model trained against ros_l1 is 0.9099774943735934\n",
            "The auc score of model trained against ros_l1 is 0.8508893683048091\n",
            "The log loss of model trained against ros_l1 is 5.15679513755602\n",
            "Time duration of model trained against ros_l1 is 13.308969736099243\n",
            "Time duration of model test against ros_l1 is 6.240851163864136\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_tr is 0.8501550036664044\n",
            "The confusion matrix of model trained against ros_tr is [[3189  836]\n",
            " [ 360 3639]]\n",
            "The accuracy of model trained against ros_tr is 0.8509471585244267\n",
            "The precision score of model trained against ros_tr is 0.8131843575418994\n",
            "The recall score of model trained against ros_tr is 0.9099774943735934\n",
            "The auc score of model trained against ros_tr is 0.8511378155097781\n",
            "The log loss of model trained against ros_tr is 5.148186070758328\n",
            "Time duration of model trained against ros_tr is 15.953490495681763\n",
            "Time duration of model test against ros_tr is 6.73509407043457\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_boruta is 0.8171551241366437\n",
            "The confusion matrix of model trained against renn_boruta is [[3888    4]\n",
            " [  24   35]]\n",
            "The accuracy of model trained against renn_boruta is 0.9929131865350544\n",
            "The precision score of model trained against renn_boruta is 0.8974358974358975\n",
            "The recall score of model trained against renn_boruta is 0.5932203389830508\n",
            "The auc score of model trained against renn_boruta is 0.7960962948769315\n",
            "The log loss of model trained against renn_boruta is 0.24477067513217504\n",
            "Time duration of model trained against renn_boruta is 5.55400824546814\n",
            "Time duration of model test against renn_boruta is 3.7159533500671387\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_l1 is 0.8192335206949412\n",
            "The confusion matrix of model trained against renn_l1 is [[3908    2]\n",
            " [  22   32]]\n",
            "The accuracy of model trained against renn_l1 is 0.9939455095862765\n",
            "The precision score of model trained against renn_l1 is 0.9411764705882353\n",
            "The recall score of model trained against renn_l1 is 0.5925925925925926\n",
            "The auc score of model trained against renn_l1 is 0.796040541820593\n",
            "The log loss of model trained against renn_l1 is 0.20911509401430886\n",
            "Time duration of model trained against renn_l1 is 6.031940221786499\n",
            "Time duration of model test against renn_l1 is 3.439354419708252\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_tr is 0.8251296952810672\n",
            "The confusion matrix of model trained against renn_tr is [[3915    9]\n",
            " [  19   32]]\n",
            "The accuracy of model trained against renn_tr is 0.9929559748427673\n",
            "The precision score of model trained against renn_tr is 0.7804878048780488\n",
            "The recall score of model trained against renn_tr is 0.6274509803921569\n",
            "The auc score of model trained against renn_tr is 0.8125787012052527\n",
            "The log loss of model trained against renn_tr is 0.2432938202350628\n",
            "Time duration of model trained against renn_tr is 6.8183043003082275\n",
            "Time duration of model test against renn_tr is 4.362257957458496\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_boruta is 0.9480321478345914\n",
            "The confusion matrix of model trained against smote_boruta is [[3116  198]\n",
            " [ 132 2883]]\n",
            "The accuracy of model trained against smote_boruta is 0.9478590614631064\n",
            "The precision score of model trained against smote_boruta is 0.9357351509250244\n",
            "The recall score of model trained against smote_boruta is 0.9562189054726368\n",
            "The auc score of model trained against smote_boruta is 0.9482361877996859\n",
            "The log loss of model trained against smote_boruta is 1.8009092322028297\n",
            "Time duration of model trained against smote_boruta is 10.506700992584229\n",
            "Time duration of model test against smote_boruta is 6.15563702583313\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_l1 is 0.9066055017757426\n",
            "The confusion matrix of model trained against smote_l1 is [[2848  390]\n",
            " [ 211 2993]]\n",
            "The accuracy of model trained against smote_l1 is 0.9067059919279726\n",
            "The precision score of model trained against smote_l1 is 0.8847177061779485\n",
            "The recall score of model trained against smote_l1 is 0.9341448189762797\n",
            "The auc score of model trained against smote_l1 is 0.9068500500069785\n",
            "The log loss of model trained against smote_l1 is 3.22230929157701\n",
            "Time duration of model trained against smote_l1 is 12.966847658157349\n",
            "Time duration of model test against smote_l1 is 6.26524019241333\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_tr is 0.8745707480787558\n",
            "The confusion matrix of model trained against smote_tr is [[3097  730]\n",
            " [ 219 3581]]\n",
            "The accuracy of model trained against smote_tr is 0.8755736200340895\n",
            "The precision score of model trained against smote_tr is 0.8306657388077012\n",
            "The recall score of model trained against smote_tr is 0.9423684210526316\n",
            "The auc score of model trained against smote_tr is 0.8758092431889758\n",
            "The log loss of model trained against smote_tr is 4.297611446819757\n",
            "Time duration of model trained against smote_tr is 18.269908666610718\n",
            "Time duration of model test against smote_tr is 9.2262704372406\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpazRs8rVvLS",
        "colab_type": "text"
      },
      "source": [
        "### Ensemble models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp0mF1tgWFIl",
        "colab_type": "text"
      },
      "source": [
        "####Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "382padRyV1fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,roc_auc_score, log_loss,roc_curve\n",
        "import time\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1aL88-VV1rh",
        "colab_type": "code",
        "outputId": "a67218a1-a29d-4909-eb4a-6e6eaae07edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  #train the model against 10 dataset\n",
        "  train_start_time = time.time()\n",
        "  cross_val_score(rf_clf, train_set_list[i], train_labels_list[i], scoring = ftwo_scorer, cv=10)\n",
        "  train_end_time = time.time()\n",
        "  train_duration = train_end_time - train_start_time\n",
        "  test_start_time = time.time()\n",
        "  prediction = cross_val_predict(rf_clf, test_set_list[i], test_labels_list[i], cv=10)\n",
        "  test_end_time = time.time()\n",
        "  test_duration = test_end_time - test_start_time\n",
        "\n",
        "  f2_score = fbeta_score(test_labels_list[i], prediction, average='macro', beta=2)\n",
        "  cfm = confusion_matrix(test_labels_list[i], prediction)\n",
        "  accuracy = accuracy_score(test_labels_list[i], prediction)\n",
        "  precision = precision_score(test_labels_list[i], prediction)\n",
        "  recall = recall_score(test_labels_list[i], prediction)\n",
        "  roc_auc = roc_auc_score(test_labels_list[i], prediction)\n",
        "  log_score = log_loss(test_labels_list[i], prediction)\n",
        "\n",
        "  print(\"The f2 score of model trained against \" + dataset_name_list[i] + \" is \" + str(f2_score))\n",
        "  print(\"The confusion matrix of model trained against \" + dataset_name_list[i] + \" is \" + str(cfm))\n",
        "  print(\"The accuracy of model trained against \" + dataset_name_list[i] + \" is \" + str(accuracy))\n",
        "  print(\"The precision score of model trained against \" + dataset_name_list[i] + \" is \" + str(precision))\n",
        "  print(\"The recall score of model trained against \" + dataset_name_list[i] + \" is \" + str(recall))\n",
        "  print(\"The auc score of model trained against \" + dataset_name_list[i] + \" is \" + str(roc_auc))\n",
        "  print(\"The log loss of model trained against \" + dataset_name_list[i] + \" is \" + str(log_score))\n",
        "  print(\"Time duration of model trained against \" + dataset_name_list[i] + \" is \" + str(train_duration))\n",
        "  print(\"Time duration of model test against \" + dataset_name_list[i] + \" is \" + str(test_duration))\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against original is 0.7599427953440065\n",
            "The confusion matrix of model trained against original is [[4018    1]\n",
            " [  25   22]]\n",
            "The accuracy of model trained against original is 0.9936055090998525\n",
            "The precision score of model trained against original is 0.9565217391304348\n",
            "The recall score of model trained against original is 0.46808510638297873\n",
            "The auc score of model trained against original is 0.73391814413451\n",
            "The log loss of model trained against original is 0.2208580880140462\n",
            "Time duration of model trained against original is 36.54001498222351\n",
            "Time duration of model test against original is 5.509648323059082\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_boruta is 0.976179554508792\n",
            "The confusion matrix of model trained against ros_boruta is [[3876  149]\n",
            " [  42 3957]]\n",
            "The accuracy of model trained against ros_boruta is 0.9761964107676969\n",
            "The precision score of model trained against ros_boruta is 0.9637116415002436\n",
            "The recall score of model trained against ros_boruta is 0.9894973743435859\n",
            "The auc score of model trained against ros_boruta is 0.9762393704016066\n",
            "The log loss of model trained against ros_boruta is 0.8221616938490834\n",
            "Time duration of model trained against ros_boruta is 59.13778471946716\n",
            "Time duration of model test against ros_boruta is 14.343200922012329\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_l1 is 0.9798965787424994\n",
            "The confusion matrix of model trained against ros_l1 is [[3875  150]\n",
            " [  11 3988]]\n",
            "The accuracy of model trained against ros_l1 is 0.9799351944167497\n",
            "The precision score of model trained against ros_l1 is 0.9637506041565974\n",
            "The recall score of model trained against ros_l1 is 0.997249312328082\n",
            "The auc score of model trained against ros_l1 is 0.9799911157913703\n",
            "The log loss of model trained against ros_l1 is 0.6930287810562259\n",
            "Time duration of model trained against ros_l1 is 76.53313493728638\n",
            "Time duration of model test against ros_l1 is 17.549952268600464\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_tr is 0.9912748662831834\n",
            "The confusion matrix of model trained against ros_tr is [[3955   70]\n",
            " [   0 3999]]\n",
            "The accuracy of model trained against ros_tr is 0.9912761714855434\n",
            "The precision score of model trained against ros_tr is 0.9827967559596953\n",
            "The recall score of model trained against ros_tr is 1.0\n",
            "The auc score of model trained against ros_tr is 0.9913043478260869\n",
            "The log loss of model trained against ros_tr is 0.30131733791922594\n",
            "Time duration of model trained against ros_tr is 108.00921654701233\n",
            "Time duration of model test against ros_tr is 23.631874322891235\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_boruta is 0.8421131792491612\n",
            "The confusion matrix of model trained against renn_boruta is [[3889    3]\n",
            " [  21   38]]\n",
            "The accuracy of model trained against renn_boruta is 0.9939255884586181\n",
            "The precision score of model trained against renn_boruta is 0.926829268292683\n",
            "The recall score of model trained against renn_boruta is 0.6440677966101694\n",
            "The auc score of model trained against renn_boruta is 0.8216484923441393\n",
            "The log loss of model trained against renn_boruta is 0.20980334909393844\n",
            "Time duration of model trained against renn_boruta is 21.04322075843811\n",
            "Time duration of model test against renn_boruta is 4.191785097122192\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_l1 is 0.8192335206949412\n",
            "The confusion matrix of model trained against renn_l1 is [[3908    2]\n",
            " [  22   32]]\n",
            "The accuracy of model trained against renn_l1 is 0.9939455095862765\n",
            "The precision score of model trained against renn_l1 is 0.9411764705882353\n",
            "The recall score of model trained against renn_l1 is 0.5925925925925926\n",
            "The auc score of model trained against renn_l1 is 0.796040541820593\n",
            "The log loss of model trained against renn_l1 is 0.20911509401430886\n",
            "Time duration of model trained against renn_l1 is 27.182347536087036\n",
            "Time duration of model test against renn_l1 is 4.674454689025879\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_tr is 0.8369671432678313\n",
            "The confusion matrix of model trained against renn_tr is [[3923    1]\n",
            " [  19   32]]\n",
            "The accuracy of model trained against renn_tr is 0.9949685534591195\n",
            "The precision score of model trained against renn_tr is 0.9696969696969697\n",
            "The recall score of model trained against renn_tr is 0.6274509803921569\n",
            "The auc score of model trained against renn_tr is 0.8135980691970979\n",
            "The log loss of model trained against renn_tr is 0.1737802081750057\n",
            "Time duration of model trained against renn_tr is 34.244542598724365\n",
            "Time duration of model test against renn_tr is 5.272899389266968\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_boruta is 0.9890960355516127\n",
            "The confusion matrix of model trained against smote_boruta is [[3277   37]\n",
            " [  32 2983]]\n",
            "The accuracy of model trained against smote_boruta is 0.9890978037604677\n",
            "The precision score of model trained against smote_boruta is 0.9877483443708609\n",
            "The recall score of model trained against smote_boruta is 0.9893864013266999\n",
            "The auc score of model trained against smote_boruta is 0.989110822872161\n",
            "The log loss of model trained against smote_boruta is 0.3765531926613621\n",
            "Time duration of model trained against smote_boruta is 34.77880930900574\n",
            "Time duration of model test against smote_boruta is 8.053107738494873\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_l1 is 0.985866061012983\n",
            "The confusion matrix of model trained against smote_l1 is [[3199   39]\n",
            " [  52 3152]]\n",
            "The accuracy of model trained against smote_l1 is 0.9858739521887613\n",
            "The precision score of model trained against smote_l1 is 0.9877781259793168\n",
            "The recall score of model trained against smote_l1 is 0.9837702871410736\n",
            "The auc score of model trained against smote_l1 is 0.9858629076224207\n",
            "The log loss of model trained against smote_l1 is 0.48790124747541996\n",
            "Time duration of model trained against smote_l1 is 52.55081605911255\n",
            "Time duration of model test against smote_l1 is 11.399844884872437\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_tr is 0.9925261713409137\n",
            "The confusion matrix of model trained against smote_tr is [[3799   28]\n",
            " [  29 3771]]\n",
            "The accuracy of model trained against smote_tr is 0.9925265504130064\n",
            "The precision score of model trained against smote_tr is 0.9926296393787839\n",
            "The recall score of model trained against smote_tr is 0.9923684210526316\n",
            "The auc score of model trained against smote_tr is 0.9925259926010479\n",
            "The log loss of model trained against smote_tr is 0.25812673964048266\n",
            "Time duration of model trained against smote_tr is 82.5027768611908\n",
            "Time duration of model test against smote_tr is 18.63945508003235\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NETM_zpze1IP",
        "colab_type": "text"
      },
      "source": [
        "#### Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPl8SHP3e8OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,roc_auc_score, log_loss,roc_curve\n",
        "import time\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "ad_clf = AdaBoostClassifier(n_estimators=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7rNpxXQV_95",
        "colab_type": "code",
        "outputId": "5a214126-d5e4-446f-ad70-919b8a518bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  #train the model against 10 dataset\n",
        "  train_start_time = time.time()\n",
        "  cross_val_score(ad_clf, train_set_list[i], train_labels_list[i], scoring = ftwo_scorer, cv=10)\n",
        "  train_end_time = time.time()\n",
        "  train_duration = train_end_time - train_start_time\n",
        "  test_start_time = time.time()\n",
        "  prediction = cross_val_predict(ad_clf, test_set_list[i], test_labels_list[i], cv=10)\n",
        "  test_end_time = time.time()\n",
        "  test_duration = test_end_time - test_start_time\n",
        "\n",
        "  f2_score = fbeta_score(test_labels_list[i], prediction, average='macro', beta=2)\n",
        "  cfm = confusion_matrix(test_labels_list[i], prediction)\n",
        "  accuracy = accuracy_score(test_labels_list[i], prediction)\n",
        "  precision = precision_score(test_labels_list[i], prediction)\n",
        "  recall = recall_score(test_labels_list[i], prediction)\n",
        "  roc_auc = roc_auc_score(test_labels_list[i], prediction)\n",
        "  log_score = log_loss(test_labels_list[i], prediction)\n",
        "\n",
        "  print(\"The f2 score of model trained against \" + dataset_name_list[i] + \" is \" + str(f2_score))\n",
        "  print(\"The confusion matrix of model trained against \" + dataset_name_list[i] + \" is \" + str(cfm))\n",
        "  print(\"The accuracy of model trained against \" + dataset_name_list[i] + \" is \" + str(accuracy))\n",
        "  print(\"The precision score of model trained against \" + dataset_name_list[i] + \" is \" + str(precision))\n",
        "  print(\"The recall score of model trained against \" + dataset_name_list[i] + \" is \" + str(recall))\n",
        "  print(\"The auc score of model trained against \" + dataset_name_list[i] + \" is \" + str(roc_auc))\n",
        "  print(\"The log loss of model trained against \" + dataset_name_list[i] + \" is \" + str(log_score))\n",
        "  print(\"Time duration of model trained against \" + dataset_name_list[i] + \" is \" + str(train_duration))\n",
        "  print(\"Time duration of model test against \" + dataset_name_list[i] + \" is \" + str(test_duration))\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against original is 0.7943356991094435\n",
            "The confusion matrix of model trained against original is [[4013    6]\n",
            " [  21   26]]\n",
            "The accuracy of model trained against original is 0.9933595671421545\n",
            "The precision score of model trained against original is 0.8125\n",
            "The recall score of model trained against original is 0.5531914893617021\n",
            "The auc score of model trained against original is 0.7758492903389751\n",
            "The log loss of model trained against original is 0.22935360556989018\n",
            "Time duration of model trained against original is 19.49252223968506\n",
            "Time duration of model test against original is 5.724191665649414\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_boruta is 0.8964252476083332\n",
            "The confusion matrix of model trained against ros_boruta is [[3686  339]\n",
            " [ 491 3508]]\n",
            "The accuracy of model trained against ros_boruta is 0.8965603190428714\n",
            "The precision score of model trained against ros_boruta is 0.9118793865349623\n",
            "The recall score of model trained against ros_boruta is 0.8772193048262066\n",
            "The auc score of model trained against ros_boruta is 0.8964978511708673\n",
            "The log loss of model trained against ros_boruta is 3.5727137925354815\n",
            "Time duration of model trained against ros_boruta is 16.45207166671753\n",
            "Time duration of model test against ros_boruta is 5.066049337387085\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_l1 is 0.8854252756493926\n",
            "The confusion matrix of model trained against ros_l1 is [[3652  373]\n",
            " [ 545 3454]]\n",
            "The accuracy of model trained against ros_l1 is 0.885593220338983\n",
            "The precision score of model trained against ros_l1 is 0.9025346224196499\n",
            "The recall score of model trained against ros_l1 is 0.8637159289822456\n",
            "The auc score of model trained against ros_l1 is 0.8855225607644147\n",
            "The log loss of model trained against ros_l1 is 3.9515073504947003\n",
            "Time duration of model trained against ros_l1 is 18.24947166442871\n",
            "Time duration of model test against ros_l1 is 5.433154582977295\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_tr is 0.9003622193190122\n",
            "The confusion matrix of model trained against ros_tr is [[3718  307]\n",
            " [ 491 3508]]\n",
            "The accuracy of model trained against ros_tr is 0.9005483549351944\n",
            "The precision score of model trained against ros_tr is 0.9195281782437745\n",
            "The recall score of model trained against ros_tr is 0.8772193048262066\n",
            "The auc score of model trained against ros_tr is 0.9004730064503704\n",
            "The log loss of model trained against ros_tr is 3.4349687237724074\n",
            "Time duration of model trained against ros_tr is 22.443525552749634\n",
            "Time duration of model test against ros_tr is 6.630370855331421\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_boruta is 0.8289773823343272\n",
            "The confusion matrix of model trained against renn_boruta is [[3891    1]\n",
            " [  23   36]]\n",
            "The accuracy of model trained against renn_boruta is 0.9939255884586181\n",
            "The precision score of model trained against renn_boruta is 0.972972972972973\n",
            "The recall score of model trained against renn_boruta is 0.6101694915254238\n",
            "The auc score of model trained against renn_boruta is 0.8049562771090634\n",
            "The log loss of model trained against renn_boruta is 0.2098029443369502\n",
            "Time duration of model trained against renn_boruta is 8.109830617904663\n",
            "Time duration of model test against renn_boruta is 3.3658905029296875\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_l1 is 0.8279442911068181\n",
            "The confusion matrix of model trained against renn_l1 is [[3908    2]\n",
            " [  21   33]]\n",
            "The accuracy of model trained against renn_l1 is 0.9941977800201817\n",
            "The precision score of model trained against renn_l1 is 0.9428571428571428\n",
            "The recall score of model trained against renn_l1 is 0.6111111111111112\n",
            "The auc score of model trained against renn_l1 is 0.8052998010798523\n",
            "The log loss of model trained against renn_l1 is 0.20040198190661196\n",
            "Time duration of model trained against renn_l1 is 10.869211196899414\n",
            "Time duration of model test against renn_l1 is 3.7018868923187256\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_tr is 0.830957032364469\n",
            "The confusion matrix of model trained against renn_tr is [[3919    5]\n",
            " [  19   32]]\n",
            "The accuracy of model trained against renn_tr is 0.9939622641509434\n",
            "The precision score of model trained against renn_tr is 0.8648648648648649\n",
            "The recall score of model trained against renn_tr is 0.6274509803921569\n",
            "The auc score of model trained against renn_tr is 0.8130883852011752\n",
            "The log loss of model trained against renn_tr is 0.20853701420503423\n",
            "Time duration of model trained against renn_tr is 11.710266590118408\n",
            "Time duration of model test against renn_tr is 4.000331163406372\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_boruta is 0.9733680367125892\n",
            "The confusion matrix of model trained against smote_boruta is [[3233   81]\n",
            " [  87 2928]]\n",
            "The accuracy of model trained against smote_boruta is 0.9734555221993996\n",
            "The precision score of model trained against smote_boruta is 0.9730807577268196\n",
            "The recall score of model trained against smote_boruta is 0.9711442786069652\n",
            "The auc score of model trained against smote_boruta is 0.973351258193042\n",
            "The log loss of model trained against smote_boruta is 0.9168240167067223\n",
            "Time duration of model trained against smote_boruta is 14.636582851409912\n",
            "Time duration of model test against smote_boruta is 4.469054937362671\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_l1 is 0.9617912011900163\n",
            "The confusion matrix of model trained against smote_l1 is [[3130  108]\n",
            " [ 138 3066]]\n",
            "The accuracy of model trained against smote_l1 is 0.9618131015212666\n",
            "The precision score of model trained against smote_l1 is 0.9659735349716446\n",
            "The recall score of model trained against smote_l1 is 0.9569288389513109\n",
            "The auc score of model trained against smote_l1 is 0.9617874583885646\n",
            "The log loss of model trained against smote_l1 is 1.3189421530069072\n",
            "Time duration of model trained against smote_l1 is 16.723534107208252\n",
            "Time duration of model test against smote_l1 is 5.001053333282471\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_tr is 0.9689880444294872\n",
            "The confusion matrix of model trained against smote_tr is [[3758   69]\n",
            " [ 167 3633]]\n",
            "The accuracy of model trained against smote_tr is 0.9690572964468336\n",
            "The precision score of model trained against smote_tr is 0.9813614262560778\n",
            "The recall score of model trained against smote_tr is 0.9560526315789474\n",
            "The auc score of model trained against smote_tr is 0.9690114216164923\n",
            "The log loss of model trained against smote_tr is 1.068730352880767\n",
            "Time duration of model trained against smote_tr is 27.77298378944397\n",
            "Time duration of model test against smote_tr is 8.360839128494263\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjNmEso5CN1R",
        "colab_type": "text"
      },
      "source": [
        "#### Hybrid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY4BxhrGCTmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import neighbors\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,roc_auc_score, log_loss,roc_curve\n",
        "import time\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "n_neighbors = 3\n",
        "knn_clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
        "gnb_clf = GaussianNB()\n",
        "vt_clf = VotingClassifier(estimators=[('dt', dt_clf), ('knn', knn_clf), ('gnb', gnb_clf)], voting='hard')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89eikCAlWdvL",
        "colab_type": "code",
        "outputId": "5cbdd35d-4b6d-4ee8-bf78-385db929dc6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(10):\n",
        "  #train the model against 10 dataset\n",
        "  train_start_time = time.time()\n",
        "  cross_val_score(vt_clf, train_set_list[i].toarray(), train_labels_list[i], scoring = ftwo_scorer, cv=10)\n",
        "  train_end_time = time.time()\n",
        "  train_duration = train_end_time - train_start_time\n",
        "  test_start_time = time.time()\n",
        "  prediction = cross_val_predict(vt_clf, test_set_list[i].toarray(), test_labels_list[i], cv=10)\n",
        "  test_end_time = time.time()\n",
        "  test_duration = test_end_time - test_start_time\n",
        "\n",
        "  f2_score = fbeta_score(test_labels_list[i], prediction, average='macro', beta=2)\n",
        "  cfm = confusion_matrix(test_labels_list[i], prediction)\n",
        "  accuracy = accuracy_score(test_labels_list[i], prediction)\n",
        "  precision = precision_score(test_labels_list[i], prediction)\n",
        "  recall = recall_score(test_labels_list[i], prediction)\n",
        "  roc_auc = roc_auc_score(test_labels_list[i], prediction)\n",
        "  log_score = log_loss(test_labels_list[i], prediction)\n",
        "\n",
        "  print(\"The f2 score of model trained against \" + dataset_name_list[i] + \" is \" + str(f2_score))\n",
        "  print(\"The confusion matrix of model trained against \" + dataset_name_list[i] + \" is \" + str(cfm))\n",
        "  print(\"The accuracy of model trained against \" + dataset_name_list[i] + \" is \" + str(accuracy))\n",
        "  print(\"The precision score of model trained against \" + dataset_name_list[i] + \" is \" + str(precision))\n",
        "  print(\"The recall score of model trained against \" + dataset_name_list[i] + \" is \" + str(recall))\n",
        "  print(\"The auc score of model trained against \" + dataset_name_list[i] + \" is \" + str(roc_auc))\n",
        "  print(\"The log loss of model trained against \" + dataset_name_list[i] + \" is \" + str(log_score))\n",
        "  print(\"Time duration of model trained against \" + dataset_name_list[i] + \" is \" + str(train_duration))\n",
        "  print(\"Time duration of model test against \" + dataset_name_list[i] + \" is \" + str(test_duration))\n",
        "  print(\"--------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of model trained against original is 0.703536664503569\n",
            "The confusion matrix of model trained against original is [[3996   23]\n",
            " [  28   19]]\n",
            "The accuracy of model trained against original is 0.9874569601574028\n",
            "The precision score of model trained against original is 0.4523809523809524\n",
            "The recall score of model trained against original is 0.40425531914893614\n",
            "The auc score of model trained against original is 0.699266251263943\n",
            "The log loss of model trained against original is 0.43322577149073854\n",
            "Time duration of model trained against original is 56.28499412536621\n",
            "Time duration of model test against original is 3.7660443782806396\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_boruta is 0.9785630010866578\n",
            "The confusion matrix of model trained against ros_boruta is [[3904  121]\n",
            " [  51 3948]]\n",
            "The accuracy of model trained against ros_boruta is 0.9785643070787637\n",
            "The precision score of model trained against ros_boruta is 0.9702629638731876\n",
            "The recall score of model trained against ros_boruta is 0.9872468117029257\n",
            "The auc score of model trained against ros_boruta is 0.9785923499508417\n",
            "The log loss of model trained against ros_boruta is 0.7403746624144688\n",
            "Time duration of model trained against ros_boruta is 1.8473892211914062\n",
            "Time duration of model test against ros_boruta is 0.29613375663757324\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_l1 is 0.9820445465956926\n",
            "The confusion matrix of model trained against ros_l1 is [[3907  118]\n",
            " [  26 3973]]\n",
            "The accuracy of model trained against ros_l1 is 0.9820538384845464\n",
            "The precision score of model trained against ros_l1 is 0.971156196528966\n",
            "The recall score of model trained against ros_l1 is 0.9934983745936484\n",
            "The auc score of model trained against ros_l1 is 0.9820908022036564\n",
            "The log loss of model trained against ros_l1 is 0.6198502185149437\n",
            "Time duration of model trained against ros_l1 is 2.2263786792755127\n",
            "Time duration of model test against ros_l1 is 0.34740424156188965\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against ros_tr is 0.9925235505176613\n",
            "The confusion matrix of model trained against ros_tr is [[3965   60]\n",
            " [   0 3999]]\n",
            "The accuracy of model trained against ros_tr is 0.9925224327018943\n",
            "The precision score of model trained against ros_tr is 0.9852180339985218\n",
            "The recall score of model trained against ros_tr is 1.0\n",
            "The auc score of model trained against ros_tr is 0.9925465838509318\n",
            "The log loss of model trained against ros_tr is 0.2582720039307652\n",
            "Time duration of model trained against ros_tr is 7.99082612991333\n",
            "Time duration of model test against ros_tr is 0.7337958812713623\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_boruta is 0.8498979427127291\n",
            "The confusion matrix of model trained against renn_boruta is [[3889    3]\n",
            " [  20   39]]\n",
            "The accuracy of model trained against renn_boruta is 0.994178688939509\n",
            "The precision score of model trained against renn_boruta is 0.9285714285714286\n",
            "The recall score of model trained against renn_boruta is 0.6610169491525424\n",
            "The auc score of model trained against renn_boruta is 0.8301230686153257\n",
            "The log loss of model trained against renn_boruta is 0.20106156817900278\n",
            "Time duration of model trained against renn_boruta is 0.9794740676879883\n",
            "Time duration of model test against renn_boruta is 0.2420356273651123\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_l1 is 0.7986750930652609\n",
            "The confusion matrix of model trained against renn_l1 is [[3899   11]\n",
            " [  23   31]]\n",
            "The accuracy of model trained against renn_l1 is 0.991422805247225\n",
            "The precision score of model trained against renn_l1 is 0.7380952380952381\n",
            "The recall score of model trained against renn_l1 is 0.5740740740740741\n",
            "The auc score of model trained against renn_l1 is 0.7856303874206687\n",
            "The log loss of model trained against renn_l1 is 0.2962480305243943\n",
            "Time duration of model trained against renn_l1 is 1.1549365520477295\n",
            "Time duration of model test against renn_l1 is 0.2219691276550293\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against renn_tr is 0.8310818334519433\n",
            "The confusion matrix of model trained against renn_tr is [[3913   11]\n",
            " [  18   33]]\n",
            "The accuracy of model trained against renn_tr is 0.9927044025157232\n",
            "The precision score of model trained against renn_tr is 0.75\n",
            "The recall score of model trained against renn_tr is 0.6470588235294118\n",
            "The auc score of model trained against renn_tr is 0.8221277807759189\n",
            "The log loss of model trained against renn_tr is 0.25198322289915615\n",
            "Time duration of model trained against renn_tr is 2.7069132328033447\n",
            "Time duration of model test against renn_tr is 0.4554870128631592\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_boruta is 0.9886774955091553\n",
            "The confusion matrix of model trained against smote_boruta is [[3287   27]\n",
            " [  44 2971]]\n",
            "The accuracy of model trained against smote_boruta is 0.9887817980723653\n",
            "The precision score of model trained against smote_boruta is 0.9909939959973315\n",
            "The recall score of model trained against smote_boruta is 0.9854063018242123\n",
            "The auc score of model trained against smote_boruta is 0.9886295238752927\n",
            "The log loss of model trained against smote_boruta is 0.3874663790755695\n",
            "Time duration of model trained against smote_boruta is 1.2708847522735596\n",
            "Time duration of model test against smote_boruta is 0.25104618072509766\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_l1 is 0.9785330733743703\n",
            "The confusion matrix of model trained against smote_l1 is [[3196   42]\n",
            " [  96 3108]]\n",
            "The accuracy of model trained against smote_l1 is 0.9785780813411984\n",
            "The precision score of model trained against smote_l1 is 0.9866666666666667\n",
            "The recall score of model trained against smote_l1 is 0.9700374531835206\n",
            "The auc score of model trained against smote_l1 is 0.9785332417245584\n",
            "The log loss of model trained against smote_l1 is 0.7398920716531743\n",
            "Time duration of model trained against smote_l1 is 1.7291767597198486\n",
            "Time duration of model test against smote_l1 is 0.29144835472106934\n",
            "--------------------------------------------------------------------------\n",
            "The f2 score of model trained against smote_tr is 0.981862185525453\n",
            "The confusion matrix of model trained against smote_tr is [[3795   32]\n",
            " [ 106 3694]]\n",
            "The accuracy of model trained against smote_tr is 0.9819063852104366\n",
            "The precision score of model trained against smote_tr is 0.991411701556629\n",
            "The recall score of model trained against smote_tr is 0.9721052631578947\n",
            "The auc score of model trained against smote_tr is 0.9818718110929269\n",
            "The log loss of model trained against smote_tr is 0.6249346702000063\n",
            "Time duration of model trained against smote_tr is 8.068097352981567\n",
            "Time duration of model test against smote_tr is 0.8503475189208984\n",
            "--------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPqwC41Z_gLg",
        "colab_type": "text"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IrViZcvpR1v",
        "colab_type": "text"
      },
      "source": [
        "We conduct several experiments to evaluate the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqfQZXdDpAS9",
        "colab_type": "text"
      },
      "source": [
        "### Friedman test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1C5BPQjc-Rz",
        "colab_type": "text"
      },
      "source": [
        "F2 score of models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lna34rKHXv_i",
        "colab_type": "text"
      },
      "source": [
        "|  | DT | LE | KNN |  GNB | SR | RF | AD | VT\n",
        "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
        "OR | 0.7770 | 0.6582 | 0.6809 | 0.2377 | 0.8204 | 0.7599 | 0.7842 | 0.6986\n",
        "RB | 0.9759 | 0.8529 | 0.9690 | 0.7014 | 0.8790 | 0.9762 | 0.8964 | 0.9781\n",
        "RL | 0.9814 | 0.8273 | 0.9710 | 0.7865 | 0.8496 | 0.9799 | 0.8854 | 0.9820\n",
        "RT | 0.9838 | 0.8090 | 0.9810 | 0.6318 | 0.8495 | 0.9913 | 0.9004 | 0.9925\n",
        "EB | 0.8442 | 0.7033 | 0.8485 | 0.8060 | 0.8184 | 0.8421 | 0.8290 | 0.8499\n",
        "EL | 0.7935 | 0.7207 | 0.8105 | 0.5668 | 0.8179 | 0.8192 | 0.8279 | 0.7999\n",
        "ET | 0.8268 | 0.6703 | 0.7970 | 0.4468 | 0.8223 | 0.8370 | 0.8310 | 0.8369\n",
        "SB | 0.9864 | 0.9222 | 0.9895 | 0.8021 | 0.9482 | 0.9891 | 0.9734 | 0.9887\n",
        "SL | 0.9786 | 0.8812 | 0.9818 | 0.8609 | 0.9055 | 0.9859 | 0.9618 | 0.9790\n",
        "ST | 0.9820 | 0.8312 | 0.9826 | 0.7185 | 0.8746 | 0.9925 | 0.9690 | 0.9823\n",
        "avg | 0.8795 | 0.7447 | 0.8318 | 0.4781 | 0.8475 | 0.8762 | 0.8766 | 0.8405\n",
        "stdev | 0.1450 | 0.1224 | 0.2133 | 0.3400 | 0.0383 | 0.1645 | 0.1306 | 0.2005"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WZxVsZKdChY",
        "colab_type": "text"
      },
      "source": [
        "Ranks of F2 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BllF_qSjbBE1",
        "colab_type": "text"
      },
      "source": [
        "|   | DT | LE | KNN |  GNB | SR | RF | AD | VT \n",
        "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
        "OR | 3 | 7 | 6 | 8 | 1 | 4 | 2 | 5\n",
        "RB | 3 | 7 | 4 | 8 | 6 | 2 | 5 | 1\n",
        "RL | 2 | 7 | 4 | 8 | 6 | 3 | 5 | 1\n",
        "RT | 3 | 7 | 4 | 8 | 6 | 2 | 5 | 1\n",
        "EB | 3 | 8 | 2 | 7 | 6 | 4 | 5 | 1\n",
        "EL | 6 | 7 | 4 | 8 | 3 | 2 | 1 | 5\n",
        "ET | 4 | 7 | 6 | 8 | 5 | 1 | 3 | 2\n",
        "SB | 4 | 7 | 1 | 8 | 6 | 2 | 5 | 3\n",
        "SL | 4 | 7 | 2 | 8 | 6 | 1 | 5 | 3\n",
        "ST | 4 | 7 | 3 | 8 | 6 | 1 | 5 | 2\n",
        "avg | 3.5 | 7.0 | 4.5| 8.0 | 3.5 | 2.5 | 3.5 | 3.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpPwM_xdkgvh",
        "colab_type": "text"
      },
      "source": [
        "Based on the Friedman test, the Friedman statistic is $44.2$. The critical value for $k = 8$ and $n = 10$ at the $\\alpha = 0.05$ level is $14.1$, so we reject the null hypothesis, which means that the average ranks as a whole, shows a significant difference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgDRBmb1_mGr",
        "colab_type": "text"
      },
      "source": [
        "### Orange package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2shRkhW2m7tz",
        "colab_type": "text"
      },
      "source": [
        "We use the Orange package to apply Nemenyi test and Bonferroni–Dunn test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4OQNnks_vM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the function that calculate critical difference from Orange package\n",
        "def compute_CD(avranks, n, alpha=\"0.05\", test=\"nemenyi\"):\n",
        "    \"\"\"\n",
        "    Returns critical difference for Nemenyi or Bonferroni-Dunn test\n",
        "    according to given alpha (either alpha=\"0.05\" or alpha=\"0.1\") for average\n",
        "    ranks and number of tested datasets N. Test can be either \"nemenyi\" for\n",
        "    for Nemenyi two tailed test or \"bonferroni-dunn\" for Bonferroni-Dunn test.\n",
        "    \"\"\"\n",
        "    k = len(avranks)\n",
        "    d = {(\"nemenyi\", \"0.05\"): [0, 0, 1.959964, 2.343701, 2.569032, 2.727774,\n",
        "                               2.849705, 2.94832, 3.030879, 3.101730, 3.163684,\n",
        "                               3.218654, 3.268004, 3.312739, 3.353618, 3.39123,\n",
        "                               3.426041, 3.458425, 3.488685, 3.517073,\n",
        "                               3.543799],\n",
        "         (\"nemenyi\", \"0.1\"): [0, 0, 1.644854, 2.052293, 2.291341, 2.459516,\n",
        "                              2.588521, 2.692732, 2.779884, 2.854606, 2.919889,\n",
        "                              2.977768, 3.029694, 3.076733, 3.119693, 3.159199,\n",
        "                              3.195743, 3.229723, 3.261461, 3.291224, 3.319233],\n",
        "         (\"bonferroni-dunn\", \"0.05\"): [0, 0, 1.960, 2.241, 2.394, 2.498, 2.576,\n",
        "                                       2.638, 2.690, 2.724, 2.773],\n",
        "         (\"bonferroni-dunn\", \"0.1\"): [0, 0, 1.645, 1.960, 2.128, 2.241, 2.326,\n",
        "                                      2.394, 2.450, 2.498, 2.539]}\n",
        "    q = d[(test, alpha)]\n",
        "    cd = q[k] * (k * (k + 1) / (6.0 * n)) ** 0.5\n",
        "    return cd\n",
        "\n",
        "#function that draw Nemenyi diagram from Orange package\n",
        "def graph_ranks(avranks, names, cd=None, cdmethod=None, lowv=None, highv=None,\n",
        "                width=6, textspace=1, reverse=False, filename=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Draws a CD graph, which is used to display  the differences in methods'\n",
        "    performance. See Janez Demsar, Statistical Comparisons of Classifiers over\n",
        "    Multiple Data Sets, 7(Jan):1--30, 2006.\n",
        "\n",
        "    Needs matplotlib to work.\n",
        "\n",
        "    The image is ploted on `plt` imported using\n",
        "    `import matplotlib.pyplot as plt`.\n",
        "\n",
        "    Args:\n",
        "        avranks (list of float): average ranks of methods.\n",
        "        names (list of str): names of methods.\n",
        "        cd (float): Critical difference used for statistically significance of\n",
        "            difference between methods.\n",
        "        cdmethod (int, optional): the method that is compared with other methods\n",
        "            If omitted, show pairwise comparison of methods\n",
        "        lowv (int, optional): the lowest shown rank\n",
        "        highv (int, optional): the highest shown rank\n",
        "        width (int, optional): default width in inches (default: 6)\n",
        "        textspace (int, optional): space on figure sides (in inches) for the\n",
        "            method names (default: 1)\n",
        "        reverse (bool, optional):  if set to `True`, the lowest rank is on the\n",
        "            right (default: `False`)\n",
        "        filename (str, optional): output file name (with extension). If not\n",
        "            given, the function does not write a file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Function graph_ranks requires matplotlib.\")\n",
        "\n",
        "    width = float(width)\n",
        "    textspace = float(textspace)\n",
        "\n",
        "    def nth(l, n):\n",
        "        \"\"\"\n",
        "        Returns only nth elemnt in a list.\n",
        "        \"\"\"\n",
        "        n = lloc(l, n)\n",
        "        return [a[n] for a in l]\n",
        "\n",
        "    def lloc(l, n):\n",
        "        \"\"\"\n",
        "        List location in list of list structure.\n",
        "        Enable the use of negative locations:\n",
        "        -1 is the last element, -2 second last...\n",
        "        \"\"\"\n",
        "        if n < 0:\n",
        "            return len(l[0]) + n\n",
        "        else:\n",
        "            return n\n",
        "\n",
        "    def mxrange(lr):\n",
        "        \"\"\"\n",
        "        Multiple xranges. Can be used to traverse matrices.\n",
        "        This function is very slow due to unknown number of\n",
        "        parameters.\n",
        "\n",
        "        >>> mxrange([3,5])\n",
        "        [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
        "\n",
        "        >>> mxrange([[3,5,1],[9,0,-3]])\n",
        "        [(3, 9), (3, 6), (3, 3), (4, 9), (4, 6), (4, 3)]\n",
        "\n",
        "        \"\"\"\n",
        "        if not len(lr):\n",
        "            yield ()\n",
        "        else:\n",
        "            # it can work with single numbers\n",
        "            index = lr[0]\n",
        "            if isinstance(index, int):\n",
        "                index = [index]\n",
        "            for a in range(*index):\n",
        "                for b in mxrange(lr[1:]):\n",
        "                    yield tuple([a] + list(b))\n",
        "\n",
        "    def print_figure(fig, *args, **kwargs):\n",
        "        canvas = FigureCanvasAgg(fig)\n",
        "        canvas.print_figure(*args, **kwargs)\n",
        "\n",
        "    sums = avranks\n",
        "\n",
        "    tempsort = sorted([(a, i) for i, a in enumerate(sums)], reverse=reverse)\n",
        "    ssums = nth(tempsort, 0)\n",
        "    sortidx = nth(tempsort, 1)\n",
        "    nnames = [names[x] for x in sortidx]\n",
        "\n",
        "    if lowv is None:\n",
        "        lowv = min(1, int(math.floor(min(ssums))))\n",
        "    if highv is None:\n",
        "        highv = max(len(avranks), int(math.ceil(max(ssums))))\n",
        "\n",
        "    cline = 0.4\n",
        "\n",
        "    k = len(sums)\n",
        "\n",
        "    lines = None\n",
        "\n",
        "    linesblank = 0\n",
        "    scalewidth = width - 2 * textspace\n",
        "\n",
        "    def rankpos(rank):\n",
        "        if not reverse:\n",
        "            a = rank - lowv\n",
        "        else:\n",
        "            a = highv - rank\n",
        "        return textspace + scalewidth / (highv - lowv) * a\n",
        "\n",
        "    distanceh = 0.25\n",
        "\n",
        "    if cd and cdmethod is None:\n",
        "        # get pairs of non significant methods\n",
        "\n",
        "        def get_lines(sums, hsd):\n",
        "            # get all pairs\n",
        "            lsums = len(sums)\n",
        "            allpairs = [(i, j) for i, j in mxrange([[lsums], [lsums]]) if j > i]\n",
        "            # remove not significant\n",
        "            notSig = [(i, j) for i, j in allpairs\n",
        "                      if abs(sums[i] - sums[j]) <= hsd]\n",
        "            # keep only longest\n",
        "\n",
        "            def no_longer(ij_tuple, notSig):\n",
        "                i, j = ij_tuple\n",
        "                for i1, j1 in notSig:\n",
        "                    if (i1 <= i and j1 > j) or (i1 < i and j1 >= j):\n",
        "                        return False\n",
        "                return True\n",
        "\n",
        "            longest = [(i, j) for i, j in notSig if no_longer((i, j), notSig)]\n",
        "\n",
        "            return longest\n",
        "\n",
        "        lines = get_lines(ssums, cd)\n",
        "        linesblank = 0.2 + 0.2 + (len(lines) - 1) * 0.1\n",
        "\n",
        "        # add scale\n",
        "        distanceh = 0.25\n",
        "        cline += distanceh\n",
        "\n",
        "    # calculate height needed height of an image\n",
        "    minnotsignificant = max(2 * 0.2, linesblank)\n",
        "    height = cline + ((k + 1) / 2) * 0.2 + minnotsignificant\n",
        "\n",
        "    fig = plt.figure(figsize=(width, height))\n",
        "    fig.set_facecolor('white')\n",
        "    ax = fig.add_axes([0, 0, 1, 1])  # reverse y axis\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    hf = 1. / height  # height factor\n",
        "    wf = 1. / width\n",
        "\n",
        "    def hfl(l):\n",
        "        return [a * hf for a in l]\n",
        "\n",
        "    def wfl(l):\n",
        "        return [a * wf for a in l]\n",
        "\n",
        "\n",
        "    # Upper left corner is (0,0).\n",
        "    ax.plot([0, 1], [0, 1], c=\"w\")\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(1, 0)\n",
        "\n",
        "    def line(l, color='k', **kwargs):\n",
        "        \"\"\"\n",
        "        Input is a list of pairs of points.\n",
        "        \"\"\"\n",
        "        ax.plot(wfl(nth(l, 0)), hfl(nth(l, 1)), color=color, **kwargs)\n",
        "\n",
        "    def text(x, y, s, *args, **kwargs):\n",
        "        ax.text(wf * x, hf * y, s, *args, **kwargs)\n",
        "\n",
        "    line([(textspace, cline), (width - textspace, cline)], linewidth=0.7)\n",
        "\n",
        "    bigtick = 0.1\n",
        "    smalltick = 0.05\n",
        "\n",
        "    tick = None\n",
        "    for a in list(np.arange(lowv, highv, 0.5)) + [highv]:\n",
        "        tick = smalltick\n",
        "        if a == int(a):\n",
        "            tick = bigtick\n",
        "        line([(rankpos(a), cline - tick / 2),\n",
        "              (rankpos(a), cline)],\n",
        "             linewidth=0.7)\n",
        "\n",
        "    for a in range(lowv, highv + 1):\n",
        "        text(rankpos(a), cline - tick / 2 - 0.05, str(a),\n",
        "             ha=\"center\", va=\"bottom\")\n",
        "\n",
        "    k = len(ssums)\n",
        "\n",
        "    for i in range(math.ceil(k / 2)):\n",
        "        chei = cline + minnotsignificant + i * 0.2\n",
        "        line([(rankpos(ssums[i]), cline),\n",
        "              (rankpos(ssums[i]), chei),\n",
        "              (textspace - 0.1, chei)],\n",
        "             linewidth=0.7)\n",
        "        text(textspace - 0.2, chei, nnames[i], ha=\"right\", va=\"center\")\n",
        "\n",
        "    for i in range(math.ceil(k / 2), k):\n",
        "        chei = cline + minnotsignificant + (k - i - 1) * 0.2\n",
        "        line([(rankpos(ssums[i]), cline),\n",
        "              (rankpos(ssums[i]), chei),\n",
        "              (textspace + scalewidth + 0.1, chei)],\n",
        "             linewidth=0.7)\n",
        "        text(textspace + scalewidth + 0.2, chei, nnames[i],\n",
        "             ha=\"left\", va=\"center\")\n",
        "\n",
        "    if cd and cdmethod is None:\n",
        "        # upper scale\n",
        "        if not reverse:\n",
        "            begin, end = rankpos(lowv), rankpos(lowv + cd)\n",
        "        else:\n",
        "            begin, end = rankpos(highv), rankpos(highv - cd)\n",
        "\n",
        "        line([(begin, distanceh), (end, distanceh)], linewidth=0.7)\n",
        "        line([(begin, distanceh + bigtick / 2),\n",
        "              (begin, distanceh - bigtick / 2)],\n",
        "             linewidth=0.7)\n",
        "        line([(end, distanceh + bigtick / 2),\n",
        "              (end, distanceh - bigtick / 2)],\n",
        "             linewidth=0.7)\n",
        "        text((begin + end) / 2, distanceh - 0.05, \"CD\",\n",
        "             ha=\"center\", va=\"bottom\")\n",
        "\n",
        "        # no-significance lines\n",
        "        def draw_lines(lines, side=0.05, height=0.1):\n",
        "            start = cline + 0.2\n",
        "            for l, r in lines:\n",
        "                line([(rankpos(ssums[l]) - side, start),\n",
        "                      (rankpos(ssums[r]) + side, start)],\n",
        "                     linewidth=2.5)\n",
        "                start += height\n",
        "\n",
        "        draw_lines(lines)\n",
        "\n",
        "    elif cd:\n",
        "        begin = rankpos(avranks[cdmethod] - cd)\n",
        "        end = rankpos(avranks[cdmethod] + cd)\n",
        "        line([(begin, cline), (end, cline)],\n",
        "             linewidth=2.5)\n",
        "        line([(begin, cline + bigtick / 2),\n",
        "              (begin, cline - bigtick / 2)],\n",
        "             linewidth=2.5)\n",
        "        line([(end, cline + bigtick / 2),\n",
        "              (end, cline - bigtick / 2)],\n",
        "             linewidth=2.5)\n",
        "\n",
        "    if filename:\n",
        "        print_figure(fig, filename, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhJ_KxCz_pYE",
        "colab_type": "text"
      },
      "source": [
        "### Nemenyi test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEGcJgQhC5Cs",
        "colab_type": "code",
        "outputId": "1e299589-b8e6-4295-f2c4-d2e34c6038f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math\n",
        "\n",
        "#calculate the critical difference between four algorithms\n",
        "avgrank = [3.5,7.0,4.5,8.0,3.5,2.5,3.5,3.5]\n",
        "critical_diff = compute_CD(avgrank, n = 10)\n",
        "print(\"The critical difference between \" + str(len(avgrank)) + \" algorithms is + %f\" % critical_diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The critical difference between 8 algorithms is + 3.320162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-zBjAoRDW-Z",
        "colab_type": "code",
        "outputId": "83580c65-1f45-454e-c1b1-9516f702609e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "#draw the Nemenyi diagarm\n",
        "alg_names = [\"Decision Tree\", \"LinearSVC\", \"K-nearest Neighbours\", \"Naive Bayes\", \"SkopeRules\", \n",
        "             \"Random Forest\", \"Adaboost\", \"Voting\"]\n",
        "graph_ranks(avranks= avgrank, names = alg_names, cd = critical_diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACpCAYAAAC2wz72AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x154.8 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UyatANamDXb",
        "colab_type": "text"
      },
      "source": [
        "Nemenyi test shows that RF, DT, SR, AD and VT are significantly better than LE and GNB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCsaSE8dGekH",
        "colab_type": "text"
      },
      "source": [
        "### Bonferroni–Dunn test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tMXaREKGh2N",
        "colab_type": "code",
        "outputId": "26b6dc2f-b866-4d16-d493-e50d7b3f8b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math\n",
        "\n",
        "#calculate the critical difference between four algorithms\n",
        "avgrank = [3.5,7.0,4.5,8.0,3.5,2.5,3.5,3.5]\n",
        "b_critical_diff = compute_CD(avgrank, n = 10, test=\"bonferroni-dunn\")\n",
        "print(\"The critical difference between \" + str(len(avgrank)) + \" algorithms is + %f\" % b_critical_diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The critical difference between 8 algorithms is + 2.946747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIkjEO7AG-9C",
        "colab_type": "code",
        "outputId": "0d2e11f5-d19f-4f98-cc01-95ed7bd0acf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#draw the Nemenyi diagarm\n",
        "alg_names = [\"Decision Tree\", \"LinearSVC\", \"K-nearest Neighbours\", \"Naive Bayes\", \"SkopeRules\", \n",
        "             \"Random Forest\", \"Adaboost\", \"Voting\"]\n",
        "graph_ranks(avranks= avgrank, names = alg_names, cd = b_critical_diff, cdmethod=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACICAYAAAB6M+hlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n62aVRp66UQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x122.4 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pch4D5Q1mVJ8",
        "colab_type": "text"
      },
      "source": [
        "Bonferroni–Dunn test using RF as control algorithm, we can generate similar conclusion as in Nemenyi test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfKyI4vKdeLn",
        "colab_type": "text"
      },
      "source": [
        "### Training and testing speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJhcWvW3hmuZ",
        "colab_type": "text"
      },
      "source": [
        "The following figure illustrates that, despite poor classification performance, Naive Bayes algorithm is actually the fastest algorithm in terms of training and testing speed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWnRp0eHgSTy",
        "colab_type": "text"
      },
      "source": [
        "[Training and testing speed of models](https://drive.google.com/open?id=1JiXrvR0Kexw2UcYNFEcY0VjQmAXQa_0a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WHlh5AVibeD",
        "colab_type": "text"
      },
      "source": [
        "The following figure provides a closer view of algorithms excluding Naive Bayes. Having the best classification performance, Random forest algorithm actually requires the longest time to build a model and test unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov_LXUU2hPNd",
        "colab_type": "text"
      },
      "source": [
        "[Training and testing speed of models except Naive Bayes](https://drive.google.com/open?id=19py8B9t2itqRwiW2bHod5cUeiycQ4zht)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsc7mf2_kZWm",
        "colab_type": "text"
      },
      "source": [
        "### Memory consumption rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ouCWxz9wRe0",
        "colab_type": "text"
      },
      "source": [
        "[memory consumption rate](https://drive.google.com/open?id=138O84s-LTeF8iQMz5mMNFojMzkxfk9Xb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2PG3ZyYwF6A",
        "colab_type": "text"
      },
      "source": [
        "This figure illustrates that GNB algorithm needs the least memory to build a model. Similar as training/testing speed, RF algorithm  requires the most memory block than other seven algorithms."
      ]
    }
  ]
}
