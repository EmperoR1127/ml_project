{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RzSJA1Fa0ZLD",
        "4XBPDWNA0SK-",
        "5VGv6kw1j2f2",
        "ToG_GdIPEfsC",
        "BSTmBtNGuXZy"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmperoR1127/ml_project/blob/emperor/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_TbqKhLg9Yf",
        "colab_type": "code",
        "outputId": "dcc83eef-734d-4ec2-9417-7546d56d60f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLSkIfDHdYjk",
        "colab_type": "text"
      },
      "source": [
        "# Env setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3blYPMzdrPA",
        "colab_type": "text"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6GJppz9hBv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Project root directory\n",
        "PROJECT_ROOT_DIR = \"/content/drive/My Drive/\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"Images\", fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtfXsBeWdkzQ",
        "colab_type": "text"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOO7V1uePIVN",
        "colab_type": "code",
        "outputId": "d3e7bcff-cc7c-4206-e50b-7303366ca872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#load the dataset\n",
        "path = PROJECT_ROOT_DIR + \"Data/H-1B_Disclosure_RAW_Data.csv\"\n",
        "df = pd.read_csv(path, encoding='utf-8')\n",
        "processed_data = df.copy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlltPJJUAauj",
        "colab_type": "text"
      },
      "source": [
        "#Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSJA1Fa0ZLD",
        "colab_type": "text"
      },
      "source": [
        "###Drop correlated columns and create new columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVgedKr4jm9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data = processed_data.drop([\"CASE_NUMBER\", \"VISA_CLASS\", \n",
        "                                        \"EMPLOYER_NAME\", \"EMPLOYER_STATE\",\"EMPLOYER_POSTAL_CODE\", \n",
        "                                        \"EMPLOYER_CITY\", \"EMPLOYER_BUSINESS_DBA\", \n",
        "                                        \"EMPLOYER_COUNTRY\", \"EMPLOYER_PROVINCE\", \"EMPLOYER_ADDRESS\", \n",
        "                                        \"EMPLOYER_PHONE\", \"EMPLOYER_PHONE_EXT\", \n",
        "                                        \"AGENT_ATTORNEY_NAME\", \"AGENT_ATTORNEY_CITY\", \"AGENT_ATTORNEY_STATE\",\n",
        "                                        \"JOB_TITLE\", \"SOC_NAME\",\n",
        "                                        \"PW_SOURCE\", \"PW_SOURCE_YEAR\", \"PW_SOURCE_OTHER\", \"WAGE_RATE_OF_PAY_FROM\",\n",
        "                                        \"WAGE_RATE_OF_PAY_TO\", \"WAGE_UNIT_OF_PAY\",\n",
        "                                        \"WORKSITE_CITY\", \"WORKSITE_COUNTY\", \"WORKSITE_POSTAL_CODE\", \n",
        "                                        \"ORIGINAL_CERT_DATE\", \"PUBLIC_DISCLOSURE_LOCATION\"], axis=1)\n",
        "#format EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['CASE_SUBMITTED'] = pd.to_datetime(processed_data['CASE_SUBMITTED'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['DECISION_DATE'] = pd.to_datetime(processed_data['DECISION_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_START_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_START_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_END_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_END_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "#drop NaT rows because we can't \"guess\" the specific date\n",
        "processed_data = processed_data[processed_data.CASE_SUBMITTED != 'NaT']\n",
        "processed_data = processed_data[processed_data.DECISION_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_START_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_END_DATE != 'NaT']\n",
        "#add one column as EMP_PERIOD, and drop EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMPLOYMENT_END_DATE'] - processed_data['EMPLOYMENT_START_DATE']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD']/np.timedelta64(1,'Y')\n",
        "#train_set = train_set[train_set.EMP_PERIOD != '-']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD'].astype(float)\n",
        "#add one column as PROCESS_TIME, indicating processing time of visa application\n",
        "processed_data['PROCESS_TIME'] = processed_data['DECISION_DATE'] - processed_data['CASE_SUBMITTED']\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].map(lambda x: str(x)[:1])\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].astype(float)\n",
        "processed_data = processed_data.drop([\"EMPLOYMENT_START_DATE\", \"EMPLOYMENT_END_DATE\"], axis=1)\n",
        "processed_data = processed_data.drop([\"CASE_SUBMITTED\", \"DECISION_DATE\"], axis=1)\n",
        "\n",
        "#concatenate the first 2 digit of column SOC_CODE and NAIC_CODE\n",
        "processed_data['SOC_CODE'] = processed_data['SOC_CODE'].map(lambda x: str(x)[:2])\n",
        "processed_data['NAICS_CODE'] = processed_data['NAICS_CODE'].map(lambda x: str(x)[:2])\n",
        "#remove impurity in the column\n",
        "processed_data = processed_data[processed_data.PW_UNIT_OF_PAY != 'N']\n",
        "processed_data = processed_data[processed_data.PREVAILING_WAGE != 'N']\n",
        "#according to google, there are 2080 working hours per year\n",
        "pw_unit_column = {\"Year\":1, \"Hour\":2080, \"Month\":12, \"Week\":52, \"Bi-Weekly\":26}\n",
        "processed_data['PW_UNIT_OF_PAY'] = processed_data['PW_UNIT_OF_PAY'].replace(pw_unit_column)\n",
        "#remove ',' in the column value\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('str')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data.PREVAILING_WAGE.str.replace(',','')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('float')\n",
        "#add one column as ANNUAL_SALARY\n",
        "processed_data['ANNUAL_SALARY'] = processed_data['PREVAILING_WAGE'] * processed_data['PW_UNIT_OF_PAY']\n",
        "processed_data = processed_data.drop([\"PREVAILING_WAGE\", \"PW_UNIT_OF_PAY\"], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsKzfnI37gKd",
        "colab_type": "code",
        "outputId": "6c10d8be-de39-474a-a414-d1b72cf6d55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "processed_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20327, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XBPDWNA0SK-",
        "colab_type": "text"
      },
      "source": [
        "### Deal with noise, missing values, numerical and categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRGugNHkGECf",
        "colab_type": "code",
        "outputId": "879d48aa-61ff-4eb1-cc2d-82c1a28c6bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "original_set = processed_data.drop([\"CASE_STATUS\"], axis=1)\n",
        "original_labels = processed_data[[\"CASE_STATUS\"]].copy()\n",
        "original_set_num = original_set.drop([\"AGENT_REPRESENTING_EMPLOYER\", \"SOC_CODE\", \"NAICS_CODE\",\n",
        "                                \"FULL_TIME_POSITION\", \"PW_WAGE_LEVEL\", \"H1B_DEPENDENT\", \"WILLFUL_VIOLATOR\",\n",
        "                                \"SUPPORT_H1B\", \"LABOR_CON_AGREE\", \"WORKSITE_STATE\"], axis=1)\n",
        "original_set_cat = original_set.drop([\"TOTAL_WORKERS\",\"NEW_EMPLOYMENT\",\"CONTINUED_EMPLOYMENT\",\n",
        "                                \"CHANGE_PREVIOUS_EMPLOYMENT\", \"NEW_CONCURRENT_EMP\", \"CHANGE_EMPLOYER\",\n",
        "                                \"AMENDED_PETITION\", \"EMP_PERIOD\", \"PROCESS_TIME\",\n",
        "                                \"ANNUAL_SALARY\"], axis=1)\n",
        "#build the pipeline\n",
        "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),('cat', OneHotEncoder()),])\n",
        "full_pipeline = ColumnTransformer([(\"num\", num_pipeline, list(original_set_num)),(\"cat\", cat_pipeline, list(original_set_cat)),])\n",
        "\n",
        "#prepare the data\n",
        "original_set = full_pipeline.fit_transform(original_set)\n",
        "\n",
        "#prepare the target\n",
        "encoder = LabelEncoder()\n",
        "original_labels = encoder.fit_transform(original_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VGv6kw1j2f2",
        "colab_type": "text"
      },
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff-ed4Sp2LDQ",
        "colab_type": "text"
      },
      "source": [
        "Boruta feature selection method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yNuS8Id7ygE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Boruta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKN5c2-53z8",
        "colab_type": "code",
        "outputId": "854e540e-17c5-4358-befd-bac4217d88ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "#Boruta feature selection\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "feat_selector = BorutaPy(rf, n_estimators='auto', random_state=1)\n",
        "feat_selector.fit(original_set.toarray(), original_labels)\n",
        "boruta_set = feat_selector.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(boruta_set.shape[1])\n",
        "      + \" features after applying Boruta feature selection technique\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset with 122 features is reduced to 5 features after applying Boruta feature selection technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2sagoqX2T20",
        "colab_type": "text"
      },
      "source": [
        "L1-based and tree-based feature selection method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVoI2E6c6Tvg",
        "colab_type": "code",
        "outputId": "19629416-64e9-4c19-a6d6-528f8576d123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "#L1-based feature selection\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter = 2000).fit(original_set, original_labels)\n",
        "l_model = SelectFromModel(lsvc, prefit=True)\n",
        "l1_set = l_model.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(l1_set.shape[1])\n",
        "      + \" features after applying L1-based feature selection technique\")\n",
        "\n",
        "#tree-based feature selection\n",
        "clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = clf.fit(original_set, original_labels)\n",
        "tb_model = SelectFromModel(clf, prefit=True)\n",
        "tr_set = tb_model.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(tr_set.shape[1])\n",
        "      + \" features after applying tree-based feature selection technique\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset with 122 features is reduced to 8 features after applying L1-based feature selection technique\n",
            "Dataset with 122 features is reduced to 14 features after applying tree-based feature selection technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4TXaI2sUx8",
        "colab_type": "text"
      },
      "source": [
        "### Deal with class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byix8507s90s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "from collections import Counter\n",
        "#load the datasets\n",
        "original_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_set.gz')\n",
        "boruta_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'boruta_set.gz')\n",
        "l1_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'l1_set.gz')\n",
        "tr_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'tr_set.gz')\n",
        "#load the labels\n",
        "original_labels = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_labels.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrTUV3A8tMC4",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with oversampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmCKFngMtGM5",
        "colab_type": "code",
        "outputId": "2b22106b-0c2a-4225-b22e-88eb057eb6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#rebalance the dataset using oversampling (random oversampling)\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "ros_boruta_set, ros_boruta_labels = ros.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_boruta \" + str(sorted(Counter(ros_boruta_labels).items())))\n",
        "\n",
        "ros_l1_set, ros_l1_labels = ros.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_l1 \" + str(sorted(Counter(ros_l1_labels).items())))\n",
        "\n",
        "ros_tr_set, ros_tr_labels = ros.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_tr \" + str(sorted(Counter(ros_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of oversampling with train_set_boruta [(0, 20058), (1, 20058)]\n",
            "Class distribution of oversampling with train_set_l1 [(0, 20058), (1, 20058)]\n",
            "Class distribution of oversampling with train_set_tr [(0, 20058), (1, 20058)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Coxm_WJwpQh",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with under-sampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ypJeXqwuUY",
        "colab_type": "code",
        "outputId": "58c34e94-63e9-4719-a1ca-4e8538e9e7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
        "#rebalance the dataset using undersampling (nearest neightbours)\n",
        "renn = RepeatedEditedNearestNeighbours()\n",
        "renn_boruta_set, renn_boruta_labels = renn.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of undersampling with boruta_set \" + str(sorted(Counter(renn_boruta_labels).items())))\n",
        "\n",
        "renn_l1_set, renn_l1_labels = renn.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of undersampling with l1_set \" + str(sorted(Counter(renn_l1_labels).items())))\n",
        "\n",
        "renn_tr_set, renn_tr_labels = renn.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of undersampling with tr_set \" + str(sorted(Counter(renn_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of undersampling with boruta_set [(0, 19484), (1, 269)]\n",
            "Class distribution of undersampling with l1_set [(0, 19548), (1, 269)]\n",
            "Class distribution of undersampling with tr_set [(0, 19606), (1, 269)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x551OsAqwa1L",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with balanced sampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B59FGJ7zQNff",
        "colab_type": "code",
        "outputId": "2de52e45-eeb3-46b3-fcde-4146823e8796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "#rebalance the dataset using balanced sampling (SMOTEENN)\n",
        "smote_enn = SMOTEENN(random_state=0)\n",
        "smote_boruta_set, smote_boruta_labels = smote_enn.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with boruta_set \" + str(sorted(Counter(smote_boruta_labels).items())))\n",
        "\n",
        "smote_l1_set, smote_l1_labels = smote_enn.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with l1_set \" + str(sorted(Counter(smote_l1_labels).items())))\n",
        "\n",
        "smote_tr_set, smote_tr_labels = smote_enn.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with tr_set \" + str(sorted(Counter(smote_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of balanced sampling with boruta_set [(0, 16097), (1, 15546)]\n",
            "Class distribution of balanced sampling with l1_set [(0, 16067), (1, 16140)]\n",
            "Class distribution of balanced sampling with tr_set [(0, 19055), (1, 19077)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVWcMbSPU3A0",
        "colab_type": "text"
      },
      "source": [
        "### Split train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heKfDhlRvGy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the dataset into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#1. split original_set and original_labels\n",
        "original_set_train, original_set_test, original_labels_train, original_labels_test = train_test_split(original_set,original_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#2. split ros_boruta_set and ros_boruta_labels\n",
        "ros_boruta_set_train, ros_boruta_set_test, ros_boruta_labels_train, ros_boruta_labels_test = train_test_split(ros_boruta_set,ros_boruta_labels, test_size=0.2, random_state=42)\n",
        "#3. split ros_l1_set and ros_l1_labels\n",
        "ros_l1_set_train, ros_l1_set_test, ros_l1_labels_train, ros_l1_labels_test = train_test_split(ros_l1_set,ros_l1_labels, test_size=0.2, random_state=42)\n",
        "#4. split ros_tr_set and ros_tr_labels\n",
        "ros_tr_set_train, ros_tr_set_test, ros_tr_labels_train, ros_tr_labels_test = train_test_split(ros_tr_set,ros_tr_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#5. split renn_boruta_set and renn_boruta_labels\n",
        "renn_boruta_set_train, renn_boruta_set_test, renn_boruta_labels_train, renn_boruta_labels_test = train_test_split(renn_boruta_set,renn_boruta_labels, test_size=0.2, random_state=42)\n",
        "#6. split renn_l1_set and renn_l1_labels\n",
        "renn_l1_set_train, renn_l1_set_test, renn_l1_labels_train, renn_l1_labels_test = train_test_split(renn_l1_set,renn_l1_labels, test_size=0.2, random_state=42)\n",
        "#7. split renn_tr_set and renn_tr_labels\n",
        "renn_tr_set_train, renn_tr_set_test, renn_tr_labels_train, renn_tr_labels_test = train_test_split(renn_tr_set,renn_tr_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#8. split smote_boruta_set and smote_boruta_labels\n",
        "smote_boruta_set_train, smote_boruta_set_test, smote_boruta_labels_train, smote_boruta_labels_test = train_test_split(smote_boruta_set,smote_boruta_labels, test_size=0.2, random_state=42)\n",
        "#9. split smote_l1_set and smote_l1_labels\n",
        "smote_l1_set_train, smote_l1_set_test, smote_l1_labels_train, smote_l1_labels_test = train_test_split(smote_l1_set,smote_l1_labels, test_size=0.2, random_state=42)\n",
        "#10. split smote_tr_set and smote_tr_labels\n",
        "smote_tr_set_train, smote_tr_set_test, smote_tr_labels_train, smote_tr_labels_test = train_test_split(smote_tr_set,smote_tr_labels, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtzr6EtWU9cr",
        "colab_type": "text"
      },
      "source": [
        "### Dump the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srUNJLqWvLfH",
        "colab_type": "code",
        "outputId": "d0421856-f6d4-47a8-cc32-331391a055cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#store original dataset\n",
        "joblib.dump(original_set_train, PROJECT_ROOT_DIR + 'Data/' + 'original_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_set_test, PROJECT_ROOT_DIR + 'Data/' + 'original_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'original_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'original_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_boruta dataset\n",
        "joblib.dump(ros_boruta_set_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_set_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_l1 dataset\n",
        "joblib.dump(ros_l1_set_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_set_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_tr dataset\n",
        "joblib.dump(ros_tr_set_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_set_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_boruta dataset\n",
        "joblib.dump(renn_boruta_set_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_set_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_l1 dataset\n",
        "joblib.dump(renn_l1_set_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_set_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_tr dataset\n",
        "joblib.dump(renn_tr_set_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_set_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_boruta dataset\n",
        "joblib.dump(smote_boruta_set_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_set_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_l1 dataset\n",
        "joblib.dump(smote_l1_set_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_set_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_tr dataset\n",
        "joblib.dump(smote_tr_set_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_set_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_labels_test' + '.gz', compress=('gzip', 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Data/smote_tr_labels_test.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JafooTz4zkTT",
        "colab_type": "text"
      },
      "source": [
        "# Train the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUEtbpP5Uxcg",
        "colab_type": "text"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gur5v8QEtPAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "#load the 10 datasets\n",
        "#1. original dataset\n",
        "original_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_set_train' + '.gz')\n",
        "original_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_set_test' + '.gz')\n",
        "original_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_labels_train' + '.gz')\n",
        "original_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_labels_test' + '.gz')\n",
        "\n",
        "#2. ros_boruta dataset\n",
        "ros_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_set_train' + '.gz')\n",
        "ros_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_set_test' + '.gz')\n",
        "ros_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_labels_train' + '.gz')\n",
        "ros_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_labels_test' + '.gz')\n",
        "\n",
        "#3. ros_l1 dataset\n",
        "ros_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_set_train' + '.gz')\n",
        "ros_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_set_test' + '.gz')\n",
        "ros_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_labels_train' + '.gz')\n",
        "ros_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_labels_test' + '.gz')\n",
        "\n",
        "#4. ros_tr dataset\n",
        "ros_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_set_train' + '.gz')\n",
        "ros_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_set_test' + '.gz')\n",
        "ros_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_labels_train' + '.gz')\n",
        "ros_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_labels_test' + '.gz')\n",
        "\n",
        "#5. renn_boruta dataset\n",
        "renn_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_set_train' + '.gz')\n",
        "renn_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_set_test' + '.gz')\n",
        "renn_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_labels_train' + '.gz')\n",
        "renn_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_labels_test' + '.gz')\n",
        "\n",
        "#6. renn_l1 dataset\n",
        "renn_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_set_train' + '.gz')\n",
        "renn_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_set_test' + '.gz')\n",
        "renn_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_labels_train' + '.gz')\n",
        "renn_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_labels_test' + '.gz')\n",
        "\n",
        "#7. renn_tr dataset\n",
        "renn_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_set_train' + '.gz')\n",
        "renn_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_set_test' + '.gz')\n",
        "renn_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_labels_train' + '.gz')\n",
        "renn_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_labels_test' + '.gz')\n",
        "\n",
        "#8. smote_boruta dataset\n",
        "smote_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_set_train' + '.gz')\n",
        "smote_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_set_test' + '.gz')\n",
        "smote_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_labels_train' + '.gz')\n",
        "smote_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_labels_test' + '.gz')\n",
        "\n",
        "#9. smote_l1 dataset\n",
        "smote_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_set_train' + '.gz')\n",
        "smote_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_set_test' + '.gz')\n",
        "smote_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_labels_train' + '.gz')\n",
        "smote_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_labels_test' + '.gz')\n",
        "\n",
        "#10. smote_tr dataset\n",
        "smote_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_set_train' + '.gz')\n",
        "smote_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_set_test' + '.gz')\n",
        "smote_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_labels_train' + '.gz')\n",
        "smote_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_labels_test' + '.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u5G1rJAwPjE",
        "colab_type": "text"
      },
      "source": [
        "### Tree models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nPcrLv7pvUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "dt_clf = DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHXeiJ_pyC1E",
        "colab_type": "code",
        "outputId": "5e70bf58-90e8-44e9-b592-20ced8cb01b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(rf_clf, original_set_train, original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_original_set_prediction = cross_val_predict(dt_clf, original_set_test, original_labels_test, cv=10)\n",
        "dt_f2_original_set = fbeta_score(original_labels_test, dt_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against original dataset is \" + str(dt_f2_original_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of decision tree model trained against original dataset is 0.77953991347736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0WwJJ7vp5TG",
        "colab_type": "code",
        "outputId": "74c1b781-7e4b-4444-e0d0-8253d0a9b717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(dt_clf, ros_boruta_set_train, ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_ros_boruta_set_prediction = cross_val_predict(dt_clf, ros_boruta_set_test, ros_boruta_labels_test, cv=10)\n",
        "dt_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, dt_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against ros_boruta dataset is \" + str(dt_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(dt_clf, ros_l1_set_train, ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_ros_l1_set_prediction = cross_val_predict(dt_clf, ros_l1_set_test, ros_l1_labels_test, cv=10)\n",
        "dt_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, dt_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against ros_l1 dataset is \" + str(dt_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(dt_clf, ros_tr_set_train, ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_ros_tr_set_prediction = cross_val_predict(dt_clf, ros_tr_set_test, ros_tr_labels_test, cv=10)\n",
        "dt_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, dt_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against ros_tr dataset is \" + str(dt_f2_ros_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of decision tree model trained against ros_boruta dataset is 0.976179554508792\n",
            "The f2 score of decision tree model trained against ros_l1 dataset is 0.9815265128347616\n",
            "The f2 score of decision tree model trained against ros_tr dataset is 0.9838922912787686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfNmV_pwplNQ",
        "colab_type": "code",
        "outputId": "3cef2de6-d883-4cba-9f0e-698ca6aa3253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(dt_clf, renn_boruta_set_train, renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_renn_boruta_set_prediction = cross_val_predict(dt_clf, renn_boruta_set_test, renn_boruta_labels_test, cv=10)\n",
        "dt_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, dt_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against renn_boruta dataset is \" + str(dt_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(dt_clf, renn_l1_set_train, renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_renn_l1_set_prediction = cross_val_predict(dt_clf, renn_l1_set_test, renn_l1_labels_test, cv=10)\n",
        "dt_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, dt_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against renn_l1 dataset is \" + str(dt_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(dt_clf, renn_tr_set_train, renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_renn_tr_set_prediction = cross_val_predict(dt_clf, renn_tr_set_test, renn_tr_labels_test, cv=10)\n",
        "dt_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, dt_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against renn_tr dataset is \" + str(dt_f2_renn_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of decision tree model trained against renn_boruta dataset is 0.8441970686534626\n",
            "The f2 score of decision tree model trained against renn_l1 dataset is 0.7922872018632714\n",
            "The f2 score of decision tree model trained against renn_tr dataset is 0.8383439490445859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV_vXjIx4Ml2",
        "colab_type": "code",
        "outputId": "028f18fb-bd21-4ea4-faac-cb1c4cd45b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(dt_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_smote_boruta_set_prediction = cross_val_predict(dt_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "dt_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, dt_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against smote_boruta dataset is \" + str(dt_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(dt_clf, smote_l1_set_train, smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_smote_l1_set_prediction = cross_val_predict(dt_clf, smote_l1_set_test, smote_l1_labels_test, cv=10)\n",
        "dt_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, dt_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against smote_l1 dataset is \" + str(dt_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(dt_clf, smote_tr_set_train, smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_smote_tr_set_prediction = cross_val_predict(dt_clf, smote_tr_set_test, smote_tr_labels_test, cv=10)\n",
        "dt_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, dt_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against smote_tr dataset is \" + str(dt_f2_smote_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of decision tree model trained against smote_boruta dataset is 0.986408562401845\n",
            "The f2 score of decision tree model trained against smote_l1 dataset is 0.978409041272007\n",
            "The f2 score of decision tree model trained against smote_tr dataset is 0.9824316909102746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToG_GdIPEfsC",
        "colab_type": "text"
      },
      "source": [
        "### Linear models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n4TSUe_Et2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "le_clf = LinearSVC(random_state=0, tol=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXX6jWU_4kGq",
        "colab_type": "code",
        "outputId": "2b21f1c1-58ac-487b-c639-232e49b9b619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(le_clf, original_set_train, original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_original_set_prediction = cross_val_predict(le_clf, original_set_test, original_labels_test, cv=10)\n",
        "le_f2_original_set = fbeta_score(original_labels_test, le_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against original dataset is \" + str(le_f2_original_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against original dataset is 0.6581709251324499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey4MTSqW45F1",
        "colab_type": "code",
        "outputId": "efdd72ed-a4be-4700-f1d3-94eb27f14223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(le_clf, ros_boruta_set_train, ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_ros_boruta_set_prediction = cross_val_predict(le_clf, ros_boruta_set_test, ros_boruta_labels_test, cv=10)\n",
        "le_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, le_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against ros_boruta dataset is \" + str(le_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(le_clf, ros_l1_set_train, ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_ros_l1_set_prediction = cross_val_predict(le_clf, ros_l1_set_test, ros_l1_labels_test, cv=10)\n",
        "le_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, le_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against ros_l1 dataset is \" + str(le_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(le_clf, ros_tr_set_train, ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_ros_tr_set_prediction = cross_val_predict(le_clf, ros_tr_set_test, ros_tr_labels_test, cv=10)\n",
        "le_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, le_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against ros_tr dataset is \" + str(le_f2_ros_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against ros_boruta dataset is 0.852887885442009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against ros_l1 dataset is 0.8272712983803792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against ros_tr dataset is 0.8090063433867388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xWbc7X85ktw",
        "colab_type": "code",
        "outputId": "e0b29e7b-7f95-4fde-dbc5-5fcf2ea64588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(le_clf, renn_boruta_set_train, renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_renn_boruta_set_prediction = cross_val_predict(le_clf, renn_boruta_set_test, renn_boruta_labels_test, cv=10)\n",
        "le_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, le_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against renn_boruta dataset is \" + str(le_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(le_clf, renn_l1_set_train, renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_renn_l1_set_prediction = cross_val_predict(le_clf, renn_l1_set_test, renn_l1_labels_test, cv=10)\n",
        "le_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, le_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against renn_l1 dataset is \" + str(le_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(le_clf, renn_tr_set_train, renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_renn_tr_set_prediction = cross_val_predict(le_clf, renn_tr_set_test, renn_tr_labels_test, cv=10)\n",
        "le_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, le_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against renn_tr dataset is \" + str(le_f2_renn_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against renn_boruta dataset is 0.7033056967231599\n",
            "The f2 score of linear model trained against renn_l1 dataset is 0.7206764198087077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against renn_tr dataset is 0.6703171257965779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2UrZ8h251F3",
        "colab_type": "code",
        "outputId": "c6081db8-56c5-4e08-f6d2-fb7eaf3dbcf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(le_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_smote_boruta_set_prediction = cross_val_predict(le_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "le_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, le_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against smote_boruta dataset is \" + str(le_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(le_clf, smote_l1_set_train, smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_smote_l1_set_prediction = cross_val_predict(le_clf, smote_l1_set_test, smote_l1_labels_test, cv=10)\n",
        "le_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, le_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against smote_l1 dataset is \" + str(le_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(le_clf, smote_tr_set_train, smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_smote_tr_set_prediction = cross_val_predict(le_clf, smote_tr_set_test, smote_tr_labels_test, cv=10)\n",
        "le_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, le_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against smote_tr dataset is \" + str(le_f2_smote_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against smote_boruta dataset is 0.9221918540715213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against smote_l1 dataset is 0.8811728554591265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against smote_tr dataset is 0.8312017755773644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSTmBtNGuXZy",
        "colab_type": "text"
      },
      "source": [
        "### Distance-based models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smD8APfCusG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "n_neighbors = 3\n",
        "knn_clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EYrUDJd6bro",
        "colab_type": "code",
        "outputId": "8926dc5c-110f-4725-962f-0f8d26838ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(knn_clf, original_set_train, original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_original_set_prediction = cross_val_predict(knn_clf, original_set_test, original_labels_test, cv=10)\n",
        "knn_f2_original_set = fbeta_score(original_labels_test, knn_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against original dataset is \" + str(knn_f2_original_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of k-nearest neighbors model trained against original dataset is 0.6809456129280018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFw-8Yhg6tPV",
        "colab_type": "code",
        "outputId": "0ba2e0bb-7d5c-4bc9-ca71-fdfd0ccd1bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(knn_clf, ros_boruta_set_train, ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_ros_boruta_set_prediction = cross_val_predict(knn_clf, ros_boruta_set_test, ros_boruta_labels_test, cv=10)\n",
        "knn_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, knn_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against ros_boruta dataset is \" + str(knn_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(knn_clf, ros_l1_set_train, ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_ros_l1_set_prediction = cross_val_predict(knn_clf, ros_l1_set_test, ros_l1_labels_test, cv=10)\n",
        "knn_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, knn_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against ros_l1 dataset is \" + str(knn_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(knn_clf, ros_tr_set_train, ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_ros_tr_set_prediction = cross_val_predict(knn_clf, ros_tr_set_test, ros_tr_labels_test, cv=10)\n",
        "knn_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, knn_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against ros_tr dataset is \" + str(knn_f2_ros_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of k-nearest neighbors model trained against ros_boruta dataset is 0.968956446243028\n",
            "The f2 score of k-nearest neighbors model trained against ros_l1 dataset is 0.9710471952548965\n",
            "The f2 score of k-nearest neighbors model trained against ros_tr dataset is 0.9810320847578311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt7fyg6266_t",
        "colab_type": "code",
        "outputId": "f3bb6be6-ab8e-4665-85d1-630312c690db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(knn_clf, renn_boruta_set_train, renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_renn_boruta_set_prediction = cross_val_predict(knn_clf, renn_boruta_set_test, renn_boruta_labels_test, cv=10)\n",
        "knn_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, knn_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against renn_boruta dataset is \" + str(knn_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(knn_clf, renn_l1_set_train, renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_renn_l1_set_prediction = cross_val_predict(knn_clf, renn_l1_set_test, renn_l1_labels_test, cv=10)\n",
        "knn_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, knn_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against renn_l1 dataset is \" + str(knn_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(knn_clf, renn_tr_set_train, renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_renn_tr_set_prediction = cross_val_predict(knn_clf, renn_tr_set_test, renn_tr_labels_test, cv=10)\n",
        "knn_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, knn_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against renn_tr dataset is \" + str(knn_f2_renn_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of k-nearest neighbors model trained against renn_boruta dataset is 0.8485381511736529\n",
            "The f2 score of k-nearest neighbors model trained against renn_l1 dataset is 0.8104529917739529\n",
            "The f2 score of k-nearest neighbors model trained against renn_tr dataset is 0.7969813017289943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIGdfANS7HGk",
        "colab_type": "code",
        "outputId": "2b81923e-9aef-4823-b5f5-0e6b15c8f8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(knn_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_smote_boruta_set_prediction = cross_val_predict(knn_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "knn_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, knn_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against smote_boruta dataset is \" + str(knn_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(knn_clf, smote_l1_set_train, smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_smote_l1_set_prediction = cross_val_predict(knn_clf, smote_l1_set_test, smote_l1_labels_test, cv=10)\n",
        "knn_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, knn_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against smote_l1 dataset is \" + str(knn_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(knn_clf, smote_tr_set_train, smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_smote_tr_set_prediction = cross_val_predict(knn_clf, smote_tr_set_test, smote_tr_labels_test, cv=10)\n",
        "knn_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, knn_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against smote_tr dataset is \" + str(knn_f2_smote_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of k-nearest neighbors model trained against smote_boruta dataset is 0.9895301834139694\n",
            "The f2 score of k-nearest neighbors model trained against smote_l1 dataset is 0.9818161987013381\n",
            "The f2 score of k-nearest neighbors model trained against smote_tr dataset is 0.9825614432862246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "272bd008-c951-4702-ece4-537de084e2fe",
        "id": "R2CSInFb6XdK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import datetime\n",
        "import tracemalloc\n",
        "print(\"Training begin at: \" + str(datetime.datetime.now()))\n",
        "tracemalloc.start()\n",
        "cross_val_score(knn_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "snapshot = tracemalloc.take_snapshot()\n",
        "print(\"Training end at: \" + str(datetime.datetime.now()))\n",
        "print(\"Predicting begin at: \" + str(datetime.datetime.now()))\n",
        "knn_smote_boruta_set_prediction = cross_val_predict(knn_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "print(\"Predicting end at: \" + str(datetime.datetime.now()))\n",
        "\n",
        "top_stats = snapshot.statistics('lineno')\n",
        "total_size = 0\n",
        "for stat in top_stats:\n",
        "    total_size = total_size + stat.size\n",
        "print(\"Training memory consumption is \" + str(total_size / (1024 * 1024)) + \"MB\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training begin at: 2019-11-20 22:32:54.077642\n",
            "Training end at: 2019-11-20 22:33:08.427120\n",
            "Predicting begin at: 2019-11-20 22:33:08.427740\n",
            "Predicting end at: 2019-11-20 22:33:09.497922\n",
            "Training memory consumption is 120.6889295578003MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFSL9Clq8VEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR9TjcKn8vcl",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE-Df2mg81mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "gnb_clf = GaussianNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yJbwgAwPtVM",
        "colab_type": "code",
        "outputId": "0939909d-1fab-4885-b57c-1be052609dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(gnb_clf, original_set_train.toarray(), original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_original_set_prediction = cross_val_predict(gnb_clf, original_set_test.toarray(), original_labels_test, cv=10)\n",
        "gnb_f2_original_set = fbeta_score(original_labels_test, gnb_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against original dataset is \" + str(gnb_f2_original_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of Naive Bayes model trained against original dataset is 0.23766671705907808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ika4wcE9SliH",
        "colab_type": "code",
        "outputId": "89ff03e9-5aa0-4429-cdc6-959d16e7ae48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(gnb_clf, ros_boruta_set_train.toarray(), ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_ros_boruta_set_prediction = cross_val_predict(gnb_clf, ros_boruta_set_test.toarray(), ros_boruta_labels_test, cv=10)\n",
        "gnb_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, gnb_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against ros_boruta dataset is \" + str(gnb_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(gnb_clf, ros_l1_set_train.toarray(), ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_ros_l1_set_prediction = cross_val_predict(gnb_clf, ros_l1_set_test.toarray(), ros_l1_labels_test, cv=10)\n",
        "gnb_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, gnb_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against ros_l1 dataset is \" + str(gnb_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(gnb_clf, ros_tr_set_train.toarray(), ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_ros_tr_set_prediction = cross_val_predict(gnb_clf, ros_tr_set_test.toarray(), ros_tr_labels_test, cv=10)\n",
        "gnb_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, gnb_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against ros_tr dataset is \" + str(gnb_f2_ros_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of Naive Bayes model trained against ros_boruta dataset is 0.7014121119024469\n",
            "The f2 score of Naive Bayes model trained against ros_l1 dataset is 0.7865482815380613\n",
            "The f2 score of Naive Bayes model trained against ros_tr dataset is 0.6317521904610978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5byBQt1TNQX",
        "colab_type": "code",
        "outputId": "d02cf70e-363a-481c-fc3b-21439f10679f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(gnb_clf, renn_boruta_set_train.toarray(), renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_renn_boruta_set_prediction = cross_val_predict(gnb_clf, renn_boruta_set_test.toarray(), renn_boruta_labels_test, cv=10)\n",
        "gnb_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, gnb_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against renn_boruta dataset is \" + str(gnb_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(gnb_clf, renn_l1_set_train.toarray(), renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_renn_l1_set_prediction = cross_val_predict(gnb_clf, renn_l1_set_test.toarray(), renn_l1_labels_test, cv=10)\n",
        "gnb_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, gnb_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against renn_l1 dataset is \" + str(gnb_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(gnb_clf, renn_tr_set_train.toarray(), renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_renn_tr_set_prediction = cross_val_predict(gnb_clf, renn_tr_set_test.toarray(), renn_tr_labels_test, cv=10)\n",
        "gnb_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, gnb_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against renn_tr dataset is \" + str(gnb_f2_renn_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of Naive Bayes model trained against renn_boruta dataset is 0.8060243041711006\n",
            "The f2 score of Naive Bayes model trained against renn_l1 dataset is 0.5667649710554388\n",
            "The f2 score of Naive Bayes model trained against renn_tr dataset is 0.4467616678051182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5j0pg6gTjqR",
        "colab_type": "code",
        "outputId": "9ae72bdc-1ac8-4c2d-ed11-341a8e658c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(gnb_clf, smote_boruta_set_train.toarray(), smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_smote_boruta_set_prediction = cross_val_predict(gnb_clf, smote_boruta_set_test.toarray(), smote_boruta_labels_test, cv=10)\n",
        "gnb_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, gnb_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against smote_boruta dataset is \" + str(gnb_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(gnb_clf, smote_l1_set_train.toarray(), smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_smote_l1_set_prediction = cross_val_predict(gnb_clf, smote_l1_set_test.toarray(), smote_l1_labels_test, cv=10)\n",
        "gnb_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, gnb_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against smote_l1 dataset is \" + str(gnb_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(gnb_clf, smote_tr_set_train.toarray(), smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "gnb_smote_tr_set_prediction = cross_val_predict(gnb_clf, smote_tr_set_test.toarray(), smote_tr_labels_test, cv=10)\n",
        "gnb_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, gnb_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of Naive Bayes model trained against smote_tr dataset is \" + str(gnb_f2_smote_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of Naive Bayes model trained against smote_boruta dataset is 0.8020823538407438\n",
            "The f2 score of Naive Bayes model trained against smote_l1 dataset is 0.8609279533087664\n",
            "The f2 score of Naive Bayes model trained against smote_tr dataset is 0.7185329679524726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpazRs8rVvLS",
        "colab_type": "text"
      },
      "source": [
        "### Ensemble models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp0mF1tgWFIl",
        "colab_type": "text"
      },
      "source": [
        "####Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "382padRyV1fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOqiNaoPWYOM",
        "colab_type": "code",
        "outputId": "39d524bc-c16a-4bcf-9c9b-17e172371fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(rf_clf, original_set_train, original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_original_set_prediction = cross_val_predict(rf_clf, original_set_test, original_labels_test, cv=10)\n",
        "rf_f2_original_set = fbeta_score(original_labels_test, rf_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against original dataset is \" + str(rf_f2_original_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of randon forest model trained against original dataset is 0.7599427953440065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MxINss8XIM6",
        "colab_type": "code",
        "outputId": "9375659a-ee8b-4a7a-d98b-c4346dd3b139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(rf_clf, ros_boruta_set_train, ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_ros_boruta_set_prediction = cross_val_predict(rf_clf, ros_boruta_set_test, ros_boruta_labels_test, cv=10)\n",
        "rf_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, rf_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against ros_boruta dataset is \" + str(rf_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(rf_clf, ros_l1_set_train, ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_ros_l1_set_prediction = cross_val_predict(rf_clf, ros_l1_set_test, ros_l1_labels_test, cv=10)\n",
        "rf_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, rf_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against ros_l1 dataset is \" + str(rf_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(rf_clf, ros_tr_set_train, ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_ros_tr_set_prediction = cross_val_predict(rf_clf, ros_tr_set_test, ros_tr_labels_test, cv=10)\n",
        "rf_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, rf_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against ros_tr dataset is \" + str(rf_f2_ros_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of randon forest model trained against ros_boruta dataset is 0.976179554508792\n",
            "The f2 score of randon forest model trained against ros_l1 dataset is 0.9798965787424994\n",
            "The f2 score of randon forest model trained against ros_tr dataset is 0.9912748662831834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMoRwV6-ark5",
        "colab_type": "code",
        "outputId": "feb0ce40-3be2-4393-bdc5-1b9c58e36212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(rf_clf, renn_boruta_set_train, renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_renn_boruta_set_prediction = cross_val_predict(rf_clf, renn_boruta_set_test, renn_boruta_labels_test, cv=10)\n",
        "rf_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, rf_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against renn_boruta dataset is \" + str(rf_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(rf_clf, renn_l1_set_train, renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_renn_l1_set_prediction = cross_val_predict(rf_clf, renn_l1_set_test, renn_l1_labels_test, cv=10)\n",
        "rf_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, rf_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against renn_l1 dataset is \" + str(rf_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(rf_clf, renn_tr_set_train, renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_renn_tr_set_prediction = cross_val_predict(rf_clf, renn_tr_set_test, renn_tr_labels_test, cv=10)\n",
        "rf_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, rf_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against renn_tr dataset is \" + str(rf_f2_renn_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of randon forest model trained against renn_boruta dataset is 0.8421131792491612\n",
            "The f2 score of randon forest model trained against renn_l1 dataset is 0.8192335206949412\n",
            "The f2 score of randon forest model trained against renn_tr dataset is 0.8369671432678313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGSWBKzvbFgv",
        "colab_type": "code",
        "outputId": "2bc7f4b1-1a1d-46c9-f2ff-50125ecf2f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(rf_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_smote_boruta_set_prediction = cross_val_predict(rf_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "rf_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, rf_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against smote_boruta dataset is \" + str(rf_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(rf_clf, smote_l1_set_train, smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_smote_l1_set_prediction = cross_val_predict(rf_clf, smote_l1_set_test, smote_l1_labels_test, cv=10)\n",
        "rf_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, rf_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against smote_l1 dataset is \" + str(rf_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(rf_clf, smote_tr_set_train, smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "rf_smote_tr_set_prediction = cross_val_predict(rf_clf, smote_tr_set_test, smote_tr_labels_test, cv=10)\n",
        "rf_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, rf_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of randon forest model trained against smote_tr dataset is \" + str(rf_f2_smote_tr_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of randon forest model trained against smote_boruta dataset is 0.9890960355516127\n",
            "The f2 score of randon forest model trained against smote_l1 dataset is 0.985866061012983\n",
            "The f2 score of randon forest model trained against smote_tr dataset is 0.9925261713409137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NETM_zpze1IP",
        "colab_type": "text"
      },
      "source": [
        "#### Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPl8SHP3e8OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "ad_clf = AdaBoostClassifier(n_estimators=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w6zgopfASjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57b8bc62-5965-4b66-9f13-a75e71f4fffe"
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(ad_clf, original_set_train, original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_original_set_prediction = cross_val_predict(ad_clf, original_set_test, original_labels_test, cv=10)\n",
        "ad_f2_original_set = fbeta_score(original_labels_test, ad_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against original dataset is \" + str(ad_f2_original_set))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of adaboost model trained against original dataset is 0.7943356991094435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SquONItXAkhW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "087d84e8-23ff-4148-8850-4f638130e96f"
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(ad_clf, ros_boruta_set_train, ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_ros_boruta_set_prediction = cross_val_predict(ad_clf, ros_boruta_set_test, ros_boruta_labels_test, cv=10)\n",
        "ad_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, ad_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against ros_boruta dataset is \" + str(ad_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(ad_clf, ros_l1_set_train, ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_ros_l1_set_prediction = cross_val_predict(ad_clf, ros_l1_set_test, ros_l1_labels_test, cv=10)\n",
        "ad_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, ad_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against ros_l1 dataset is \" + str(ad_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(ad_clf, ros_tr_set_train, ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_ros_tr_set_prediction = cross_val_predict(ad_clf, ros_tr_set_test, ros_tr_labels_test, cv=10)\n",
        "ad_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, ad_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against ros_tr dataset is \" + str(ad_f2_ros_tr_set))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of adaboost model trained against ros_boruta dataset is 0.8964252476083332\n",
            "The f2 score of adaboost model trained against ros_l1 dataset is 0.8854252756493926\n",
            "The f2 score of adaboost model trained against ros_tr dataset is 0.9003622193190122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rcKhHOxBMWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2febc32b-10da-429a-ee4b-8d11c4706050"
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(ad_clf, renn_boruta_set_train, renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_renn_boruta_set_prediction = cross_val_predict(ad_clf, renn_boruta_set_test, renn_boruta_labels_test, cv=10)\n",
        "ad_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, ad_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against renn_boruta dataset is \" + str(ad_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(ad_clf, renn_l1_set_train, renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_renn_l1_set_prediction = cross_val_predict(ad_clf, renn_l1_set_test, renn_l1_labels_test, cv=10)\n",
        "ad_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, ad_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against renn_l1 dataset is \" + str(ad_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(ad_clf, renn_tr_set_train, renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_renn_tr_set_prediction = cross_val_predict(ad_clf, renn_tr_set_test, renn_tr_labels_test, cv=10)\n",
        "ad_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, ad_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against renn_tr dataset is \" + str(ad_f2_renn_tr_set))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of adaboost model trained against renn_boruta dataset is 0.8289773823343272\n",
            "The f2 score of adaboost model trained against renn_l1 dataset is 0.8279442911068181\n",
            "The f2 score of adaboost model trained against renn_tr dataset is 0.830957032364469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2of3R0fBarN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fea90e5e-48dd-4aee-8411-f43d00ab79b1"
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(ad_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_smote_boruta_set_prediction = cross_val_predict(ad_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "ad_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, ad_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against smote_boruta dataset is \" + str(ad_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(ad_clf, smote_l1_set_train, smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_smote_l1_set_prediction = cross_val_predict(ad_clf, smote_l1_set_test, smote_l1_labels_test, cv=10)\n",
        "ad_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, ad_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against smote_l1 dataset is \" + str(ad_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(ad_clf, smote_tr_set_train, smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_smote_tr_set_prediction = cross_val_predict(ad_clf, smote_tr_set_test, smote_tr_labels_test, cv=10)\n",
        "ad_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, ad_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of adaboost model trained against smote_tr dataset is \" + str(ad_f2_smote_tr_set))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of adaboost model trained against smote_boruta dataset is 0.9733680367125892\n",
            "The f2 score of adaboost model trained against smote_l1 dataset is 0.9617912011900163\n",
            "The f2 score of adaboost model trained against smote_tr dataset is 0.9689880444294872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjNmEso5CN1R",
        "colab_type": "text"
      },
      "source": [
        "#### Hybrid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY4BxhrGCTmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import neighbors\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "n_neighbors = 3\n",
        "knn_clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
        "gnb_clf = GaussianNB()\n",
        "vt_clf = VotingClassifier(estimators=[('dt', dt_clf), ('knn', knn_clf), ('gnb', gnb_clf)], voting='hard')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-tQO1N-DS_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c621fb6-7baa-4a39-96b5-aed417fde407"
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(vt_clf, original_set_train.toarray(), original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_original_set_prediction = cross_val_predict(vt_clf, original_set_test.toarray(), original_labels_test, cv=10)\n",
        "vt_f2_original_set = fbeta_score(original_labels_test, vt_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against original dataset is \" + str(vt_f2_original_set))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of hard voting model trained against original dataset is 0.703536664503569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_iWM1-4DpHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "63f75111-05eb-451c-f6e1-e823fa3f4d66"
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(vt_clf, ros_boruta_set_train.toarray(), ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_ros_boruta_set_prediction = cross_val_predict(vt_clf, ros_boruta_set_test.toarray(), ros_boruta_labels_test, cv=10)\n",
        "vt_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, vt_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against ros_boruta dataset is \" + str(vt_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(vt_clf, ros_l1_set_train.toarray(), ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_ros_l1_set_prediction = cross_val_predict(vt_clf, ros_l1_set_test.toarray(), ros_l1_labels_test, cv=10)\n",
        "vt_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, vt_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against ros_l1 dataset is \" + str(vt_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(ad_clf, ros_tr_set_train.toarray(), ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "ad_ros_tr_set_prediction = cross_val_predict(ad_clf, ros_tr_set_test.toarray(), ros_tr_labels_test, cv=10)\n",
        "ad_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, ad_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against ros_tr dataset is \" + str(ad_f2_ros_tr_set))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of hard voting model trained against ros_boruta dataset is 0.9781882483259291\n",
            "The f2 score of hard voting model trained against ros_l1 dataset is 0.9822946761265869\n",
            "The f2 score of hard voting model trained against ros_tr dataset is 0.9003622193190122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LjEfm_aEnxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1a97bd47-559a-461c-ce51-e428b91c19e6"
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(vt_clf, renn_boruta_set_train.toarray(), renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_renn_boruta_set_prediction = cross_val_predict(vt_clf, renn_boruta_set_test.toarray(), renn_boruta_labels_test, cv=10)\n",
        "vt_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, vt_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against renn_boruta dataset is \" + str(vt_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(vt_clf, renn_l1_set_train.toarray(), renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_renn_l1_set_prediction = cross_val_predict(vt_clf, renn_l1_set_test.toarray(), renn_l1_labels_test, cv=10)\n",
        "vt_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, vt_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against renn_l1 dataset is \" + str(vt_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(vt_clf, renn_tr_set_train.toarray(), renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_renn_tr_set_prediction = cross_val_predict(vt_clf, renn_tr_set_test.toarray(), renn_tr_labels_test, cv=10)\n",
        "vt_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, vt_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against renn_tr dataset is \" + str(vt_f2_renn_tr_set))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of hard voting model trained against renn_boruta dataset is 0.8498979427127291\n",
            "The f2 score of hard voting model trained against renn_l1 dataset is 0.7986750930652609\n",
            "The f2 score of hard voting model trained against renn_tr dataset is 0.8354611330013411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiBG3pMxGI9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2b943abe-a6dd-44ca-dca8-c3781967204e"
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(vt_clf, smote_boruta_set_train.toarray(), smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_smote_boruta_set_prediction = cross_val_predict(vt_clf, smote_boruta_set_test.toarray(), smote_boruta_labels_test, cv=10)\n",
        "vt_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, vt_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against smote_boruta dataset is \" + str(vt_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(vt_clf, smote_l1_set_train.toarray(), smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_smote_l1_set_prediction = cross_val_predict(vt_clf, smote_l1_set_test.toarray(), smote_l1_labels_test, cv=10)\n",
        "vt_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, vt_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against smote_l1 dataset is \" + str(vt_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(vt_clf, smote_tr_set_train.toarray(), smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "vt_smote_tr_set_prediction = cross_val_predict(vt_clf, smote_tr_set_test.toarray(), smote_tr_labels_test, cv=10)\n",
        "vt_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, vt_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of hard voting model trained against smote_tr dataset is \" + str(vt_f2_smote_tr_set))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of hard voting model trained against smote_boruta dataset is 0.9886774955091553\n",
            "The f2 score of hard voting model trained against smote_l1 dataset is 0.9786848461628974\n",
            "The f2 score of hard voting model trained against smote_tr dataset is 0.9822599570672526\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}