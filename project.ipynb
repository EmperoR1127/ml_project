{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmperoR1127/ml_project/blob/emperor/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_TbqKhLg9Yf",
        "colab_type": "code",
        "outputId": "1de09f69-7780-4441-fabf-867c7f180ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6GJppz9hBv5",
        "colab_type": "code",
        "outputId": "5c86eaa9-3b0e-4416-e90f-a58619fddc92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \"/content/drive/My Drive/\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"Images\", fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)\n",
        "    \n",
        "#load the dataset\n",
        "path = \"/content/drive/My Drive/Data/H-1B_Disclosure_RAW_Data.csv\"\n",
        "df = pd.read_csv(path, encoding='utf-8')\n",
        "processed_data = df.copy()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlltPJJUAauj",
        "colab_type": "text"
      },
      "source": [
        "Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVgedKr4jm9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data = processed_data.drop([\"CASE_NUMBER\", \"VISA_CLASS\", \n",
        "                                        \"EMPLOYER_NAME\", \"EMPLOYER_STATE\",\"EMPLOYER_POSTAL_CODE\", \n",
        "                                        \"EMPLOYER_CITY\", \"EMPLOYER_BUSINESS_DBA\", \n",
        "                                        \"EMPLOYER_COUNTRY\", \"EMPLOYER_PROVINCE\", \"EMPLOYER_ADDRESS\", \n",
        "                                        \"EMPLOYER_PHONE\", \"EMPLOYER_PHONE_EXT\", \n",
        "                                        \"AGENT_ATTORNEY_NAME\", \"AGENT_ATTORNEY_CITY\", \"AGENT_ATTORNEY_STATE\",\n",
        "                                        \"JOB_TITLE\", \"SOC_NAME\",\n",
        "                                        \"PW_SOURCE\", \"PW_SOURCE_YEAR\", \"PW_SOURCE_OTHER\", \"WAGE_RATE_OF_PAY_FROM\",\n",
        "                                        \"WAGE_RATE_OF_PAY_TO\", \"WAGE_UNIT_OF_PAY\",\n",
        "                                        \"WORKSITE_CITY\", \"WORKSITE_COUNTY\", \"WORKSITE_POSTAL_CODE\", \n",
        "                                        \"ORIGINAL_CERT_DATE\", \"PUBLIC_DISCLOSURE_LOCATION\"], axis=1)\n",
        "#format EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['CASE_SUBMITTED'] = pd.to_datetime(processed_data['CASE_SUBMITTED'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['DECISION_DATE'] = pd.to_datetime(processed_data['DECISION_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_START_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_START_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_END_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_END_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "#drop NaT rows because we can't \"guess\" the specific date\n",
        "processed_data = processed_data[processed_data.CASE_SUBMITTED != 'NaT']\n",
        "processed_data = processed_data[processed_data.DECISION_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_START_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_END_DATE != 'NaT']\n",
        "#add one column as EMP_PERIOD, and drop EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMPLOYMENT_END_DATE'] - processed_data['EMPLOYMENT_START_DATE']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD']/np.timedelta64(1,'Y')\n",
        "#train_set = train_set[train_set.EMP_PERIOD != '-']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD'].astype(float)\n",
        "#add one column as PROCESS_TIME, indicating processing time of visa application\n",
        "processed_data['PROCESS_TIME'] = processed_data['DECISION_DATE'] - processed_data['CASE_SUBMITTED']\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].map(lambda x: str(x)[:1])\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].astype(float)\n",
        "processed_data = processed_data.drop([\"EMPLOYMENT_START_DATE\", \"EMPLOYMENT_END_DATE\"], axis=1)\n",
        "processed_data = processed_data.drop([\"CASE_SUBMITTED\", \"DECISION_DATE\"], axis=1)\n",
        "\n",
        "#concatenate the first 2 digit of column SOC_CODE and NAIC_CODE\n",
        "processed_data['SOC_CODE'] = processed_data['SOC_CODE'].map(lambda x: str(x)[:2])\n",
        "processed_data['NAICS_CODE'] = processed_data['NAICS_CODE'].map(lambda x: str(x)[:2])\n",
        "#remove impurity in the column\n",
        "processed_data = processed_data[processed_data.PW_UNIT_OF_PAY != 'N']\n",
        "processed_data = processed_data[processed_data.PREVAILING_WAGE != 'N']\n",
        "#according to google, there are 2080 working hours per year\n",
        "pw_unit_column = {\"Year\":1, \"Hour\":2080, \"Month\":12, \"Week\":52, \"Bi-Weekly\":26}\n",
        "processed_data['PW_UNIT_OF_PAY'] = processed_data['PW_UNIT_OF_PAY'].replace(pw_unit_column)\n",
        "#remove ',' in the column value\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('str')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data.PREVAILING_WAGE.str.replace(',','')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('float')\n",
        "#add one column as ANNUAL_SALARY\n",
        "processed_data['ANNUAL_SALARY'] = processed_data['PREVAILING_WAGE'] * processed_data['PW_UNIT_OF_PAY']\n",
        "processed_data = processed_data.drop([\"PREVAILING_WAGE\", \"PW_UNIT_OF_PAY\"], axis=1)\n",
        "counts_soc = processed_data.groupby(\"SOC_CODE\")[\"SOC_CODE\"].transform(len)\n",
        "counts_naics = processed_data.groupby(\"NAICS_CODE\")[\"NAICS_CODE\"].transform(len)\n",
        "counts_worksite_state = processed_data.groupby(\"WORKSITE_STATE\")[\"WORKSITE_STATE\"].transform(len)\n",
        "mask = (counts_soc > 10000) & (counts_naics > 10000)  & (counts_worksite_state > 20000)\n",
        "processed_data = processed_data[mask]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRGugNHkGECf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "aa9e3238-6803-4878-b649-77f12db0fc13"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "train_set = processed_data.drop([\"CASE_STATUS\"], axis=1)\n",
        "train_labels = processed_data[[\"CASE_STATUS\"]].copy()\n",
        "train_set_num = train_set.drop([\"AGENT_REPRESENTING_EMPLOYER\", \"SOC_CODE\", \"NAICS_CODE\",\n",
        "                                \"FULL_TIME_POSITION\", \"PW_WAGE_LEVEL\", \"H1B_DEPENDENT\", \"WILLFUL_VIOLATOR\",\n",
        "                                \"SUPPORT_H1B\", \"LABOR_CON_AGREE\", \"WORKSITE_STATE\"], axis=1)\n",
        "train_set_cat = train_set.drop([\"TOTAL_WORKERS\",\"NEW_EMPLOYMENT\",\"CONTINUED_EMPLOYMENT\",\n",
        "                                \"CHANGE_PREVIOUS_EMPLOYMENT\", \"NEW_CONCURRENT_EMP\", \"CHANGE_EMPLOYER\",\n",
        "                                \"AMENDED_PETITION\", \"EMP_PERIOD\", \"PROCESS_TIME\",\n",
        "                                \"ANNUAL_SALARY\"], axis=1)\n",
        "#build the pipeline\n",
        "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),('cat', OneHotEncoder()),])\n",
        "full_pipeline = ColumnTransformer([(\"num\", num_pipeline, list(train_set_num)),(\"cat\", cat_pipeline, list(train_set_cat)),])\n",
        "\n",
        "#prepare the data\n",
        "train_set = full_pipeline.fit_transform(train_set)\n",
        "\n",
        "#prepare the target\n",
        "encoder = LabelEncoder()\n",
        "train_labels = encoder.fit_transform(train_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VGv6kw1j2f2",
        "colab_type": "text"
      },
      "source": [
        "Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKN5c2-53z8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66b1e523-747c-42d1-ea68-ccdb32b8fefa"
      },
      "source": [
        "#!pip install Boruta\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "#Boruta feature selection\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
        "feat_selector.fit(train_set, train_labels)\n",
        "train_set_boruta = feat_selector.transform(train_set)\n",
        "print(\"Dataset with \" + str(train_set.shape[1]) + \" features is reduced to \" + str(train_set_boruta.shape[1])\n",
        "      + \" features after applying Boruta feature selection technique\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t50\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t50\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t50\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t50\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t50\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t50\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t50\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t7\n",
            "Rejected: \t27\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t7\n",
            "Rejected: \t27\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t7\n",
            "Rejected: \t27\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t16\n",
            "Tentative: \t7\n",
            "Rejected: \t27\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t6\n",
            "Rejected: \t27\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t6\n",
            "Rejected: \t27\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t6\n",
            "Rejected: \t27\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t6\n",
            "Rejected: \t27\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t5\n",
            "Rejected: \t28\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t5\n",
            "Rejected: \t28\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t5\n",
            "Rejected: \t28\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t4\n",
            "Rejected: \t29\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t4\n",
            "Rejected: \t29\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t4\n",
            "Rejected: \t29\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t4\n",
            "Rejected: \t29\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t4\n",
            "Rejected: \t29\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t4\n",
            "Rejected: \t29\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t4\n",
            "Rejected: \t29\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t28 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t29 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t30 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t31 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t32 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t33 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t34 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t35 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t36 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t37 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t38 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t39 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t3\n",
            "Rejected: \t30\n",
            "Iteration: \t40 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t41 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t42 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t43 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t44 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t45 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t46 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t47 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t48 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t49 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t50 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t51 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t52 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t53 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t54 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t55 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t56 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t57 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t58 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t59 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t60 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t61 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t62 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t63 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t64 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t65 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t66 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t67 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t68 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t69 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t70 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t71 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t72 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t73 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t74 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t75 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t76 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t77 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t78 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t79 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t80 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t81 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t82 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t83 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t84 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t85 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t86 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t87 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t88 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t89 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t2\n",
            "Rejected: \t31\n",
            "Iteration: \t90 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t91 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t92 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t93 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t94 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t95 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t96 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t97 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t98 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "Iteration: \t99 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t1\n",
            "Rejected: \t32\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t100 / 100\n",
            "Confirmed: \t17\n",
            "Tentative: \t0\n",
            "Rejected: \t32\n",
            "Dataset with 50 features is reduced to 17 features after applying Boruta feature selection technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVoI2E6c6Tvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "b6c1f7af-3d3c-4a9c-bbc0-19fa90c18703"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "#L1-based feature selection\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter = 2000).fit(train_set, train_labels)\n",
        "l_model = SelectFromModel(lsvc, prefit=True)\n",
        "train_set_l1 = l_model.transform(train_set)\n",
        "print(\"Dataset with \" + str(train_set.shape[1]) + \" features is reduced to \" + str(train_set_l1.shape[1])\n",
        "      + \" features after applying L1-based feature selection technique\")\n",
        "\n",
        "#tree-based feature selection\n",
        "clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = clf.fit(train_set, train_labels)\n",
        "tb_model = SelectFromModel(clf, prefit=True)\n",
        "train_set_tr = tb_model.transform(train_set)\n",
        "print(\"Dataset with \" + str(train_set.shape[1]) + \" features is reduced to \" + str(train_set_tr.shape[1])\n",
        "      + \" features after applying tree-based feature selection technique\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset with 50 features is reduced to 25 features after applying L1-based feature selection technique\n",
            "Dataset with 50 features is reduced to 4 features after applying tree-based feature selection technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prRBkOssHSlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#store dataset in files using dump\n",
        "import joblib\n",
        "joblib.dump(train_set_boruta, PROJECT_ROOT_DIR + 'Data/' + 'train_set_boruta' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(train_set_l1, PROJECT_ROOT_DIR + 'Data/' + 'train_set_l1' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(train_set_tr, PROJECT_ROOT_DIR + 'Data/' + 'train_set_tr' + '.gz', compress=('gzip', 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ic72bgpsb6D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0038177-7efc-47f8-c234-67926edad84b"
      },
      "source": [
        "#store target in files using dump\n",
        "joblib.dump(train_set, PROJECT_ROOT_DIR + 'Data/' + 'train_set' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(train_labels, PROJECT_ROOT_DIR + 'Data/' + 'train_labels' + '.gz', compress=('gzip', 3))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Data/train_labels.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4TXaI2sUx8",
        "colab_type": "text"
      },
      "source": [
        "Deal with class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byix8507s90s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the datasets\n",
        "train_set_boruta = joblib.load('/content/drive/My Drive/Data/train_set_boruta.gz')\n",
        "train_set_l1 = joblib.load('/content/drive/My Drive/Data/train_set_l1.gz')\n",
        "train_set_tr = joblib.load('/content/drive/My Drive/Data/train_set_tr.gz')\n",
        "#load the labels\n",
        "train_labels = joblib.load('/content/drive/My Drive/Data/train_labels.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrTUV3A8tMC4",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with oversampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmCKFngMtGM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5c3e26bb-fde3-4512-f790-fbcc929fb98d"
      },
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#rebalance the dataset using oversampling (random oversampling)\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "ros_train_set_boruta, ros_train_labels_boruta = ros.fit_resample(train_set_boruta, train_labels)\n",
        "print(\"Class distribution of oversampling with train_set_boruta \" + str(sorted(Counter(ros_train_labels_boruta).items())))\n",
        "\n",
        "ros_train_set_l1, ros_train_labels_l1 = ros.fit_resample(train_set_l1, train_labels)\n",
        "print(\"Class distribution of oversampling with train_set_l1 \" + str(sorted(Counter(ros_train_labels_l1).items())))\n",
        "\n",
        "ros_train_set_tr, ros_train_labels_tr = ros.fit_resample(train_set_tr, train_labels)\n",
        "print(\"Class distribution of oversampling with train_set_tr \" + str(sorted(Counter(ros_train_labels_tr).items())))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of oversampling with train_set_boruta [(0, 347594), (1, 347594)]\n",
            "Class distribution of oversampling with train_set_l1 [(0, 347594), (1, 347594)]\n",
            "Class distribution of oversampling with train_set_tr [(0, 347594), (1, 347594)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc60xSJCju6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
        "#rebalance the dataset using undersampling (nearest neightbours)\n",
        "renn = RepeatedEditedNearestNeighbours()\n",
        "renn_train_set_boruta, renn_train_labels_boruta = renn.fit_resample(train_set_boruta, train_labels)\n",
        "print(\"Class distribution of undersampling with train_set_boruta \" + str(sorted(Counter(renn_train_labels_boruta).items())))\n",
        "\n",
        "renn_train_set_l1, renn_train_labels_l1 = renn.fit_resample(train_set_l1, train_labels)\n",
        "print(\"Class distribution of undersampling with train_set_l1 \" + str(sorted(Counter(renn_train_labels_l1).items())))\n",
        "\n",
        "renn_train_set_tr, renn_train_labels_tr = renn.fit_resample(train_set_tr, train_labels)\n",
        "print(\"Class distribution of undersampling with train_set_tr \" + str(sorted(Counter(renn_train_labels_tr).items())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dFLYStCtYfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "#rebalance the dataset using balanced sampling (SMOTEENN)\n",
        "smote_enn = SMOTEENN(random_state=0)\n",
        "smote_train_set_boruta, smote_train_labels_boruta = smote_enn.fit_resample(train_set_boruta, train_labels)\n",
        "print(\"Class distribution of balanced sampling with train_set_boruta \" + str(sorted(Counter(smote_train_labels_boruta).items())))\n",
        "\n",
        "smote_train_set_l1, smote_train_labels_l1 = smote_enn.fit_resample(train_set_l1, train_labels)\n",
        "print(\"Class distribution of balanced sampling with train_set_l1 \" + str(sorted(Counter(smote_train_labels_l1).items())))\n",
        "\n",
        "smote_train_set_tr, smote_train_labels_tr = smote_enn.fit_resample(train_set_tr, train_labels)\n",
        "print(\"Class distribution of balanced sampling with train_set_boruta \" + str(sorted(Counter(smote_train_labels_tr).items())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u5G1rJAwPjE",
        "colab_type": "text"
      },
      "source": [
        "Train the model using Decision Tree algorithm with 10 fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_PZdkdYkHvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "#train the model against the original dataset\n",
        "dt_or_prediction = cross_val_predict(dt_clf.fit(train_set, train_labels), \n",
        "                                           train_set, train_labels, cv=10)\n",
        "#train the model against ros_train_set_boruta, ros_train_labels_boruta\n",
        "dt_ros_boruta_prediction = cross_val_predict(dt_clf.fit(ros_train_set_boruta, ros_train_labels_boruta), \n",
        "                                                       ros_train_set_boruta, ros_train_labels_boruta, cv=10)\n",
        "#train the model against ros_train_set_l1, ros_train_labels_l1\n",
        "dt_ros_l1_prediction = cross_val_predict(dt_clf.fit(ros_train_set_l1, ros_train_labels_l1), \n",
        "                                                   ros_train_set_l1, ros_train_labels_l1, cv=10)\n",
        "#train the against ros_train_set_tr, ros_train_labels_tr\n",
        "dt_ros_tr_prediction = cross_val_predict(dt_clf.fit(ros_train_set_tr, \n",
        "                                                             ros_train_labels_tr), \n",
        "                                                  ros_train_set_tr, ros_train_labels_tr, cv=10)\n",
        "\n",
        "#calculate the presion and recall of original dataset\n",
        "dt_or_precision_score = precision_score(train_labels, dt_or_prediction)\n",
        "dt_or_recall_score = recall_score(train_labels, dt_or_prediction)\n",
        "dt_or_accuracy_score = accuracy_score(train_labels, dt_or_prediction)\n",
        "print(\"precision of decision tree model on original dataset is + %f\" % dt_or_precision_score)\n",
        "print(\"recall of decision tree model on original dataset is + %f\" % dt_or_recall_score)\n",
        "print(\"accuracy of decision tree model on original dataset is + %f\" % dt_or_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "\n",
        "#calculate the presion and recall of dt_ros_boruta_prediction\n",
        "dt_ros_boruta_precision_score = precision_score(ros_train_labels_boruta, dt_ros_boruta_prediction)\n",
        "dt_ros_boruta_recall_score = recall_score(ros_train_labels_boruta, dt_ros_boruta_prediction)\n",
        "dt_ros_boruta_accuracy_score = accuracy_score(ros_train_labels_boruta, dt_ros_boruta_prediction)\n",
        "print(\"precision of decision tree model on oversampling dataset is + %f\" % dt_ros_boruta_precision_score)\n",
        "print(\"recall of decision tree model on oversampling dataset is + %f\" % dt_ros_boruta_recall_score)\n",
        "print(\"accuracy of decision tree model on oversampling dataset is + %f\" % dt_ros_boruta_accuracy_score)\n",
        "print(\"-----------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}