{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmperoR1127/ml_project/blob/emperor/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_TbqKhLg9Yf",
        "colab_type": "code",
        "outputId": "1de09f69-7780-4441-fabf-867c7f180ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6GJppz9hBv5",
        "colab_type": "code",
        "outputId": "3c14e269-0a8d-4cd9-8fb9-e5ec54398b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \"/content/drive/My Drive/Images\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)\n",
        "    \n",
        "#load the dataset\n",
        "path = \"/content/drive/My Drive/Data/H-1B_Disclosure_RAW_Data.csv\"\n",
        "df = pd.read_csv(path, encoding='utf-8')\n",
        "processed_data = df.copy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlltPJJUAauj",
        "colab_type": "text"
      },
      "source": [
        "Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVgedKr4jm9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data = processed_data.drop([\"CASE_NUMBER\", \"VISA_CLASS\", \n",
        "                                        \"EMPLOYER_NAME\", \"EMPLOYER_STATE\",\"EMPLOYER_POSTAL_CODE\", \n",
        "                                        \"EMPLOYER_CITY\", \"EMPLOYER_BUSINESS_DBA\", \n",
        "                                        \"EMPLOYER_COUNTRY\", \"EMPLOYER_PROVINCE\", \"EMPLOYER_ADDRESS\", \n",
        "                                        \"EMPLOYER_PHONE\", \"EMPLOYER_PHONE_EXT\", \n",
        "                                        \"AGENT_ATTORNEY_NAME\", \"AGENT_ATTORNEY_CITY\", \"AGENT_ATTORNEY_STATE\",\n",
        "                                        \"JOB_TITLE\", \"SOC_NAME\",\n",
        "                                        \"PW_SOURCE\", \"PW_SOURCE_YEAR\", \"PW_SOURCE_OTHER\", \"WAGE_RATE_OF_PAY_FROM\",\n",
        "                                        \"WAGE_RATE_OF_PAY_TO\", \"WAGE_UNIT_OF_PAY\",\n",
        "                                        \"WORKSITE_CITY\", \"WORKSITE_COUNTY\", \"WORKSITE_POSTAL_CODE\", \n",
        "                                        \"ORIGINAL_CERT_DATE\", \"PUBLIC_DISCLOSURE_LOCATION\"], axis=1)\n",
        "#format EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['CASE_SUBMITTED'] = pd.to_datetime(processed_data['CASE_SUBMITTED'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['DECISION_DATE'] = pd.to_datetime(processed_data['DECISION_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_START_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_START_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_END_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_END_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "#drop NaT rows because we can't \"guess\" the specific date\n",
        "processed_data = processed_data[processed_data.CASE_SUBMITTED != 'NaT']\n",
        "processed_data = processed_data[processed_data.DECISION_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_START_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_END_DATE != 'NaT']\n",
        "#add one column as EMP_PERIOD, and drop EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMPLOYMENT_END_DATE'] - processed_data['EMPLOYMENT_START_DATE']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD']/np.timedelta64(1,'Y')\n",
        "#train_set = train_set[train_set.EMP_PERIOD != '-']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD'].astype(float)\n",
        "#add one column as PROCESS_TIME, indicating processing time of visa application\n",
        "processed_data['PROCESS_TIME'] = processed_data['DECISION_DATE'] - processed_data['CASE_SUBMITTED']\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].map(lambda x: str(x)[:1])\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].astype(float)\n",
        "processed_data = processed_data.drop([\"EMPLOYMENT_START_DATE\", \"EMPLOYMENT_END_DATE\"], axis=1)\n",
        "processed_data = processed_data.drop([\"CASE_SUBMITTED\", \"DECISION_DATE\"], axis=1)\n",
        "\n",
        "#concatenate the first 2 digit of column SOC_CODE and NAIC_CODE\n",
        "processed_data['SOC_CODE'] = processed_data['SOC_CODE'].map(lambda x: str(x)[:2])\n",
        "processed_data['NAICS_CODE'] = processed_data['NAICS_CODE'].map(lambda x: str(x)[:2])\n",
        "#remove impurity in the column\n",
        "processed_data = processed_data[processed_data.PW_UNIT_OF_PAY != 'N']\n",
        "processed_data = processed_data[processed_data.PREVAILING_WAGE != 'N']\n",
        "#according to google, there are 2080 working hours per year\n",
        "pw_unit_column = {\"Year\":1, \"Hour\":2080, \"Month\":12, \"Week\":52, \"Bi-Weekly\":26}\n",
        "processed_data['PW_UNIT_OF_PAY'] = processed_data['PW_UNIT_OF_PAY'].replace(pw_unit_column)\n",
        "#remove ',' in the column value\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('str')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data.PREVAILING_WAGE.str.replace(',','')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('float')\n",
        "#add one column as ANNUAL_SALARY\n",
        "processed_data['ANNUAL_SALARY'] = processed_data['PREVAILING_WAGE'] * processed_data['PW_UNIT_OF_PAY']\n",
        "processed_data = processed_data.drop([\"PREVAILING_WAGE\", \"PW_UNIT_OF_PAY\"], axis=1)\n",
        "counts_soc = processed_data.groupby(\"SOC_CODE\")[\"SOC_CODE\"].transform(len)\n",
        "counts_naics = processed_data.groupby(\"NAICS_CODE\")[\"NAICS_CODE\"].transform(len)\n",
        "counts_worksite_state = processed_data.groupby(\"WORKSITE_STATE\")[\"WORKSITE_STATE\"].transform(len)\n",
        "mask = (counts_soc > 10000) & (counts_naics > 10000)  & (counts_worksite_state > 20000)\n",
        "processed_data = processed_data[mask]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRGugNHkGECf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "40d25969-b206-447b-de67-96de305c4eeb"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "train_set = processed_data.drop([\"CASE_STATUS\"], axis=1)\n",
        "train_labels = processed_data[[\"CASE_STATUS\"]].copy()\n",
        "train_set_num = train_set.drop([\"AGENT_REPRESENTING_EMPLOYER\", \"SOC_CODE\", \"NAICS_CODE\",\n",
        "                                \"FULL_TIME_POSITION\", \"PW_WAGE_LEVEL\", \"H1B_DEPENDENT\", \"WILLFUL_VIOLATOR\",\n",
        "                                \"SUPPORT_H1B\", \"LABOR_CON_AGREE\", \"WORKSITE_STATE\"], axis=1)\n",
        "train_set_cat = train_set.drop([\"TOTAL_WORKERS\",\"NEW_EMPLOYMENT\",\"CONTINUED_EMPLOYMENT\",\n",
        "                                \"CHANGE_PREVIOUS_EMPLOYMENT\", \"NEW_CONCURRENT_EMP\", \"CHANGE_EMPLOYER\",\n",
        "                                \"AMENDED_PETITION\", \"EMP_PERIOD\", \"PROCESS_TIME\",\n",
        "                                \"ANNUAL_SALARY\"], axis=1)\n",
        "#build the pipeline\n",
        "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),('cat', OneHotEncoder()),])\n",
        "full_pipeline = ColumnTransformer([(\"num\", num_pipeline, list(train_set_num)),(\"cat\", cat_pipeline, list(train_set_cat)),])\n",
        "\n",
        "#prepare the data\n",
        "train_set = full_pipeline.fit_transform(train_set)\n",
        "\n",
        "#prepare the target\n",
        "encoder = LabelEncoder()\n",
        "train_labels = encoder.fit_transform(train_labels)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VGv6kw1j2f2",
        "colab_type": "text"
      },
      "source": [
        "Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKN5c2-53z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install Boruta\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "#Boruta feature selection\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "feat_selector = BorutaPy(rf, n_estimators='auto', random_state=1)\n",
        "feat_selector.fit(train_set, train_labels)\n",
        "train_set_boruta = feat_selector.transform(train_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVoI2E6c6Tvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "80b92a09-3e25-4197-b823-fdc790ee34f7"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import LinearSVC\n",
        "#L1-based feature selection\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(train_set, train_labels)\n",
        "l_model = SelectFromModel(lsvc, prefit=True)\n",
        "train_set_l1 = l_model.transform(train_set)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc60xSJCju6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60536984-623c-4874-a496-7c30e6d972e9"
      },
      "source": [
        "train_set_l1.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351638, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_PZdkdYkHvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}