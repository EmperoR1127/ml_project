{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RzSJA1Fa0ZLD",
        "4XBPDWNA0SK-",
        "5VGv6kw1j2f2",
        "ToG_GdIPEfsC",
        "BSTmBtNGuXZy"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmperoR1127/ml_project/blob/emperor/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_TbqKhLg9Yf",
        "colab_type": "code",
        "outputId": "bcd44f33-9b75-4d40-d111-2d3b879e2428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6GJppz9hBv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Project root directory\n",
        "PROJECT_ROOT_DIR = \"/content/drive/My Drive/\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"Images\", fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOO7V1uePIVN",
        "colab_type": "code",
        "outputId": "d3e7bcff-cc7c-4206-e50b-7303366ca872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#load the dataset\n",
        "path = PROJECT_ROOT_DIR + \"Data/H-1B_Disclosure_RAW_Data.csv\"\n",
        "df = pd.read_csv(path, encoding='utf-8')\n",
        "processed_data = df.copy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlltPJJUAauj",
        "colab_type": "text"
      },
      "source": [
        "#Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSJA1Fa0ZLD",
        "colab_type": "text"
      },
      "source": [
        "#####Drop correlated columns and create new columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVgedKr4jm9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_data = processed_data.drop([\"CASE_NUMBER\", \"VISA_CLASS\", \n",
        "                                        \"EMPLOYER_NAME\", \"EMPLOYER_STATE\",\"EMPLOYER_POSTAL_CODE\", \n",
        "                                        \"EMPLOYER_CITY\", \"EMPLOYER_BUSINESS_DBA\", \n",
        "                                        \"EMPLOYER_COUNTRY\", \"EMPLOYER_PROVINCE\", \"EMPLOYER_ADDRESS\", \n",
        "                                        \"EMPLOYER_PHONE\", \"EMPLOYER_PHONE_EXT\", \n",
        "                                        \"AGENT_ATTORNEY_NAME\", \"AGENT_ATTORNEY_CITY\", \"AGENT_ATTORNEY_STATE\",\n",
        "                                        \"JOB_TITLE\", \"SOC_NAME\",\n",
        "                                        \"PW_SOURCE\", \"PW_SOURCE_YEAR\", \"PW_SOURCE_OTHER\", \"WAGE_RATE_OF_PAY_FROM\",\n",
        "                                        \"WAGE_RATE_OF_PAY_TO\", \"WAGE_UNIT_OF_PAY\",\n",
        "                                        \"WORKSITE_CITY\", \"WORKSITE_COUNTY\", \"WORKSITE_POSTAL_CODE\", \n",
        "                                        \"ORIGINAL_CERT_DATE\", \"PUBLIC_DISCLOSURE_LOCATION\"], axis=1)\n",
        "#format EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['CASE_SUBMITTED'] = pd.to_datetime(processed_data['CASE_SUBMITTED'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['DECISION_DATE'] = pd.to_datetime(processed_data['DECISION_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_START_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_START_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "processed_data['EMPLOYMENT_END_DATE'] = pd.to_datetime(processed_data['EMPLOYMENT_END_DATE'],infer_datetime_format=True,errors='coerce')\n",
        "#drop NaT rows because we can't \"guess\" the specific date\n",
        "processed_data = processed_data[processed_data.CASE_SUBMITTED != 'NaT']\n",
        "processed_data = processed_data[processed_data.DECISION_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_START_DATE != 'NaT']\n",
        "processed_data = processed_data[processed_data.EMPLOYMENT_END_DATE != 'NaT']\n",
        "#add one column as EMP_PERIOD, and drop EMPLOYMENT_START_DATE and EMPLOYMENT_END_DATE\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMPLOYMENT_END_DATE'] - processed_data['EMPLOYMENT_START_DATE']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD']/np.timedelta64(1,'Y')\n",
        "#train_set = train_set[train_set.EMP_PERIOD != '-']\n",
        "processed_data['EMP_PERIOD'] = processed_data['EMP_PERIOD'].astype(float)\n",
        "#add one column as PROCESS_TIME, indicating processing time of visa application\n",
        "processed_data['PROCESS_TIME'] = processed_data['DECISION_DATE'] - processed_data['CASE_SUBMITTED']\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].map(lambda x: str(x)[:1])\n",
        "processed_data['PROCESS_TIME'] = processed_data['PROCESS_TIME'].astype(float)\n",
        "processed_data = processed_data.drop([\"EMPLOYMENT_START_DATE\", \"EMPLOYMENT_END_DATE\"], axis=1)\n",
        "processed_data = processed_data.drop([\"CASE_SUBMITTED\", \"DECISION_DATE\"], axis=1)\n",
        "\n",
        "#concatenate the first 2 digit of column SOC_CODE and NAIC_CODE\n",
        "processed_data['SOC_CODE'] = processed_data['SOC_CODE'].map(lambda x: str(x)[:2])\n",
        "processed_data['NAICS_CODE'] = processed_data['NAICS_CODE'].map(lambda x: str(x)[:2])\n",
        "#remove impurity in the column\n",
        "processed_data = processed_data[processed_data.PW_UNIT_OF_PAY != 'N']\n",
        "processed_data = processed_data[processed_data.PREVAILING_WAGE != 'N']\n",
        "#according to google, there are 2080 working hours per year\n",
        "pw_unit_column = {\"Year\":1, \"Hour\":2080, \"Month\":12, \"Week\":52, \"Bi-Weekly\":26}\n",
        "processed_data['PW_UNIT_OF_PAY'] = processed_data['PW_UNIT_OF_PAY'].replace(pw_unit_column)\n",
        "#remove ',' in the column value\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('str')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data.PREVAILING_WAGE.str.replace(',','')\n",
        "processed_data['PREVAILING_WAGE'] = processed_data['PREVAILING_WAGE'].astype('float')\n",
        "#add one column as ANNUAL_SALARY\n",
        "processed_data['ANNUAL_SALARY'] = processed_data['PREVAILING_WAGE'] * processed_data['PW_UNIT_OF_PAY']\n",
        "processed_data = processed_data.drop([\"PREVAILING_WAGE\", \"PW_UNIT_OF_PAY\"], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsKzfnI37gKd",
        "colab_type": "code",
        "outputId": "6c10d8be-de39-474a-a414-d1b72cf6d55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "processed_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20327, 21)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XBPDWNA0SK-",
        "colab_type": "text"
      },
      "source": [
        "### Deal with noise, missing values, numerical and categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRGugNHkGECf",
        "colab_type": "code",
        "outputId": "879d48aa-61ff-4eb1-cc2d-82c1a28c6bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "original_set = processed_data.drop([\"CASE_STATUS\"], axis=1)\n",
        "original_labels = processed_data[[\"CASE_STATUS\"]].copy()\n",
        "original_set_num = original_set.drop([\"AGENT_REPRESENTING_EMPLOYER\", \"SOC_CODE\", \"NAICS_CODE\",\n",
        "                                \"FULL_TIME_POSITION\", \"PW_WAGE_LEVEL\", \"H1B_DEPENDENT\", \"WILLFUL_VIOLATOR\",\n",
        "                                \"SUPPORT_H1B\", \"LABOR_CON_AGREE\", \"WORKSITE_STATE\"], axis=1)\n",
        "original_set_cat = original_set.drop([\"TOTAL_WORKERS\",\"NEW_EMPLOYMENT\",\"CONTINUED_EMPLOYMENT\",\n",
        "                                \"CHANGE_PREVIOUS_EMPLOYMENT\", \"NEW_CONCURRENT_EMP\", \"CHANGE_EMPLOYER\",\n",
        "                                \"AMENDED_PETITION\", \"EMP_PERIOD\", \"PROCESS_TIME\",\n",
        "                                \"ANNUAL_SALARY\"], axis=1)\n",
        "#build the pipeline\n",
        "num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),('cat', OneHotEncoder()),])\n",
        "full_pipeline = ColumnTransformer([(\"num\", num_pipeline, list(original_set_num)),(\"cat\", cat_pipeline, list(original_set_cat)),])\n",
        "\n",
        "#prepare the data\n",
        "original_set = full_pipeline.fit_transform(original_set)\n",
        "\n",
        "#prepare the target\n",
        "encoder = LabelEncoder()\n",
        "original_labels = encoder.fit_transform(original_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VGv6kw1j2f2",
        "colab_type": "text"
      },
      "source": [
        "### Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff-ed4Sp2LDQ",
        "colab_type": "text"
      },
      "source": [
        "Boruta feature selection method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yNuS8Id7ygE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install Boruta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuKN5c2-53z8",
        "colab_type": "code",
        "outputId": "854e540e-17c5-4358-befd-bac4217d88ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from boruta import BorutaPy\n",
        "#Boruta feature selection\n",
        "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "feat_selector = BorutaPy(rf, n_estimators='auto', random_state=1)\n",
        "feat_selector.fit(original_set.toarray(), original_labels)\n",
        "boruta_set = feat_selector.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(boruta_set.shape[1])\n",
        "      + \" features after applying Boruta feature selection technique\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset with 122 features is reduced to 5 features after applying Boruta feature selection technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2sagoqX2T20",
        "colab_type": "text"
      },
      "source": [
        "L1-based and tree-based feature selection method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVoI2E6c6Tvg",
        "colab_type": "code",
        "outputId": "19629416-64e9-4c19-a6d6-528f8576d123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "#L1-based feature selection\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter = 2000).fit(original_set, original_labels)\n",
        "l_model = SelectFromModel(lsvc, prefit=True)\n",
        "l1_set = l_model.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(l1_set.shape[1])\n",
        "      + \" features after applying L1-based feature selection technique\")\n",
        "\n",
        "#tree-based feature selection\n",
        "clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = clf.fit(original_set, original_labels)\n",
        "tb_model = SelectFromModel(clf, prefit=True)\n",
        "tr_set = tb_model.transform(original_set)\n",
        "print(\"Dataset with \" + str(original_set.shape[1]) + \" features is reduced to \" + str(tr_set.shape[1])\n",
        "      + \" features after applying tree-based feature selection technique\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dataset with 122 features is reduced to 8 features after applying L1-based feature selection technique\n",
            "Dataset with 122 features is reduced to 14 features after applying tree-based feature selection technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4TXaI2sUx8",
        "colab_type": "text"
      },
      "source": [
        "### Deal with class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byix8507s90s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "from collections import Counter\n",
        "#load the datasets\n",
        "original_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_set.gz')\n",
        "boruta_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'boruta_set.gz')\n",
        "l1_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'l1_set.gz')\n",
        "tr_set = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'tr_set.gz')\n",
        "#load the labels\n",
        "original_labels = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_labels.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrTUV3A8tMC4",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with oversampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmCKFngMtGM5",
        "colab_type": "code",
        "outputId": "2b22106b-0c2a-4225-b22e-88eb057eb6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "#rebalance the dataset using oversampling (random oversampling)\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "ros_boruta_set, ros_boruta_labels = ros.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_boruta \" + str(sorted(Counter(ros_boruta_labels).items())))\n",
        "\n",
        "ros_l1_set, ros_l1_labels = ros.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_l1 \" + str(sorted(Counter(ros_l1_labels).items())))\n",
        "\n",
        "ros_tr_set, ros_tr_labels = ros.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of oversampling with train_set_tr \" + str(sorted(Counter(ros_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of oversampling with train_set_boruta [(0, 20058), (1, 20058)]\n",
            "Class distribution of oversampling with train_set_l1 [(0, 20058), (1, 20058)]\n",
            "Class distribution of oversampling with train_set_tr [(0, 20058), (1, 20058)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Coxm_WJwpQh",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with under-sampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2ypJeXqwuUY",
        "colab_type": "code",
        "outputId": "58c34e94-63e9-4719-a1ca-4e8538e9e7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
        "#rebalance the dataset using undersampling (nearest neightbours)\n",
        "renn = RepeatedEditedNearestNeighbours()\n",
        "renn_boruta_set, renn_boruta_labels = renn.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of undersampling with boruta_set \" + str(sorted(Counter(renn_boruta_labels).items())))\n",
        "\n",
        "renn_l1_set, renn_l1_labels = renn.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of undersampling with l1_set \" + str(sorted(Counter(renn_l1_labels).items())))\n",
        "\n",
        "renn_tr_set, renn_tr_labels = renn.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of undersampling with tr_set \" + str(sorted(Counter(renn_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of undersampling with boruta_set [(0, 19484), (1, 269)]\n",
            "Class distribution of undersampling with l1_set [(0, 19548), (1, 269)]\n",
            "Class distribution of undersampling with tr_set [(0, 19606), (1, 269)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x551OsAqwa1L",
        "colab_type": "text"
      },
      "source": [
        "Rebalance dataset with balanced sampling technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B59FGJ7zQNff",
        "colab_type": "code",
        "outputId": "2de52e45-eeb3-46b3-fcde-4146823e8796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "#rebalance the dataset using balanced sampling (SMOTEENN)\n",
        "smote_enn = SMOTEENN(random_state=0)\n",
        "smote_boruta_set, smote_boruta_labels = smote_enn.fit_resample(boruta_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with boruta_set \" + str(sorted(Counter(smote_boruta_labels).items())))\n",
        "\n",
        "smote_l1_set, smote_l1_labels = smote_enn.fit_resample(l1_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with l1_set \" + str(sorted(Counter(smote_l1_labels).items())))\n",
        "\n",
        "smote_tr_set, smote_tr_labels = smote_enn.fit_resample(tr_set, original_labels)\n",
        "print(\"Class distribution of balanced sampling with tr_set \" + str(sorted(Counter(smote_tr_labels).items())))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class distribution of balanced sampling with boruta_set [(0, 16097), (1, 15546)]\n",
            "Class distribution of balanced sampling with l1_set [(0, 16067), (1, 16140)]\n",
            "Class distribution of balanced sampling with tr_set [(0, 19055), (1, 19077)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heKfDhlRvGy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the dataset into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#1. split original_set and original_labels\n",
        "original_set_train, original_set_test, original_labels_train, original_labels_test = train_test_split(original_set,original_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#2. split ros_boruta_set and ros_boruta_labels\n",
        "ros_boruta_set_train, ros_boruta_set_test, ros_boruta_labels_train, ros_boruta_labels_test = train_test_split(ros_boruta_set,ros_boruta_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#3. split ros_l1_set and ros_l1_labels\n",
        "ros_l1_set_train, ros_l1_set_test, ros_l1_labels_train, ros_l1_labels_test = train_test_split(ros_l1_set,ros_l1_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#4. split ros_tr_set and ros_tr_labels\n",
        "ros_tr_set_train, ros_tr_set_test, ros_tr_labels_train, ros_tr_labels_test = train_test_split(ros_tr_set,ros_tr_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#5. split renn_boruta_set and renn_boruta_labels\n",
        "renn_boruta_set_train, renn_boruta_set_test, renn_boruta_labels_train, renn_boruta_labels_test = train_test_split(renn_boruta_set,renn_boruta_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#6. split renn_l1_set and renn_l1_labels\n",
        "renn_l1_set_train, renn_l1_set_test, renn_l1_labels_train, renn_l1_labels_test = train_test_split(renn_l1_set,renn_l1_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#7. split renn_tr_set and renn_tr_labels\n",
        "renn_tr_set_train, renn_tr_set_test, renn_tr_labels_train, renn_tr_labels_test = train_test_split(renn_tr_set,renn_tr_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#8. split smote_boruta_set and smote_boruta_labels\n",
        "smote_boruta_set_train, smote_boruta_set_test, smote_boruta_labels_train, smote_boruta_labels_test = train_test_split(smote_boruta_set,smote_boruta_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#9. split smote_l1_set and smote_l1_labels\n",
        "smote_l1_set_train, smote_l1_set_test, smote_l1_labels_train, smote_l1_labels_test = train_test_split(smote_l1_set,smote_l1_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#10. split smote_tr_set and smote_tr_labels\n",
        "smote_tr_set_train, smote_tr_set_test, smote_tr_labels_train, smote_tr_labels_test = train_test_split(smote_tr_set,smote_tr_labels, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srUNJLqWvLfH",
        "colab_type": "code",
        "outputId": "d0421856-f6d4-47a8-cc32-331391a055cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#store original dataset\n",
        "joblib.dump(original_set_train, PROJECT_ROOT_DIR + 'Data/' + 'original_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_set_test, PROJECT_ROOT_DIR + 'Data/' + 'original_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'original_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(original_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'original_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_boruta dataset\n",
        "joblib.dump(ros_boruta_set_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_set_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_boruta_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_l1 dataset\n",
        "joblib.dump(ros_l1_set_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_set_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_l1_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store ros_tr dataset\n",
        "joblib.dump(ros_tr_set_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_set_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(ros_tr_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_boruta dataset\n",
        "joblib.dump(renn_boruta_set_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_set_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_boruta_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_l1 dataset\n",
        "joblib.dump(renn_l1_set_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_set_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_l1_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store renn_tr dataset\n",
        "joblib.dump(renn_tr_set_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_set_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(renn_tr_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_boruta dataset\n",
        "joblib.dump(smote_boruta_set_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_set_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_boruta_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_l1 dataset\n",
        "joblib.dump(smote_l1_set_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_set_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_l1_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_labels_test' + '.gz', compress=('gzip', 3))\n",
        "\n",
        "#store smote_tr dataset\n",
        "joblib.dump(smote_tr_set_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_set_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_set_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_set_test' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_labels_train, PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_labels_train' + '.gz', compress=('gzip', 3))\n",
        "joblib.dump(smote_tr_labels_test, PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_labels_test' + '.gz', compress=('gzip', 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Data/smote_tr_labels_test.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JafooTz4zkTT",
        "colab_type": "text"
      },
      "source": [
        "# Train the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gur5v8QEtPAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib\n",
        "#load the 10 datasets\n",
        "#1. original dataset\n",
        "original_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_set_train' + '.gz')\n",
        "original_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_set_test' + '.gz')\n",
        "original_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_labels_train' + '.gz')\n",
        "original_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'original_labels_test' + '.gz')\n",
        "\n",
        "#2. ros_boruta dataset\n",
        "ros_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_set_train' + '.gz')\n",
        "ros_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_set_test' + '.gz')\n",
        "ros_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_labels_train' + '.gz')\n",
        "ros_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_boruta_labels_test' + '.gz')\n",
        "\n",
        "#3. ros_l1 dataset\n",
        "ros_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_set_train' + '.gz')\n",
        "ros_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_set_test' + '.gz')\n",
        "ros_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_labels_train' + '.gz')\n",
        "ros_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_l1_labels_test' + '.gz')\n",
        "\n",
        "#4. ros_tr dataset\n",
        "ros_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_set_train' + '.gz')\n",
        "ros_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_set_test' + '.gz')\n",
        "ros_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_labels_train' + '.gz')\n",
        "ros_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'ros_tr_labels_test' + '.gz')\n",
        "\n",
        "#5. renn_boruta dataset\n",
        "renn_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_set_train' + '.gz')\n",
        "renn_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_set_test' + '.gz')\n",
        "renn_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_labels_train' + '.gz')\n",
        "renn_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_boruta_labels_test' + '.gz')\n",
        "\n",
        "#6. renn_l1 dataset\n",
        "renn_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_set_train' + '.gz')\n",
        "renn_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_set_test' + '.gz')\n",
        "renn_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_labels_train' + '.gz')\n",
        "renn_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_l1_labels_test' + '.gz')\n",
        "\n",
        "#7. renn_tr dataset\n",
        "renn_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_set_train' + '.gz')\n",
        "renn_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_set_test' + '.gz')\n",
        "renn_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_labels_train' + '.gz')\n",
        "renn_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'renn_tr_labels_test' + '.gz')\n",
        "\n",
        "#8. smote_boruta dataset\n",
        "smote_boruta_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_set_train' + '.gz')\n",
        "smote_boruta_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_set_test' + '.gz')\n",
        "smote_boruta_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_labels_train' + '.gz')\n",
        "smote_boruta_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_boruta_labels_test' + '.gz')\n",
        "\n",
        "#9. smote_l1 dataset\n",
        "smote_l1_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_set_train' + '.gz')\n",
        "smote_l1_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_set_test' + '.gz')\n",
        "smote_l1_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_labels_train' + '.gz')\n",
        "smote_l1_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_l1_labels_test' + '.gz')\n",
        "\n",
        "#10. smote_tr dataset\n",
        "smote_tr_set_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_set_train' + '.gz')\n",
        "smote_tr_set_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_set_test' + '.gz')\n",
        "smote_tr_labels_train = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_labels_train' + '.gz')\n",
        "smote_tr_labels_test = joblib.load(PROJECT_ROOT_DIR + 'Data/' + 'smote_tr_labels_test' + '.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u5G1rJAwPjE",
        "colab_type": "text"
      },
      "source": [
        "### Tree models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nPcrLv7pvUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "dt_clf = DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHXeiJ_pyC1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e70bf58-90e8-44e9-b592-20ced8cb01b5"
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(dt_clf, original_set_train, original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_original_set_prediction = cross_val_predict(dt_clf, original_set_test, original_labels_test, cv=10)\n",
        "dt_f2_original_set = fbeta_score(original_labels_test, dt_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against original dataset is \" + str(dt_f2_original_set))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of decision tree model trained against original dataset is 0.77953991347736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0WwJJ7vp5TG",
        "colab_type": "code",
        "outputId": "74c1b781-7e4b-4444-e0d0-8253d0a9b717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(dt_clf, ros_boruta_set_train, ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_ros_boruta_set_prediction = cross_val_predict(dt_clf, ros_boruta_set_test, ros_boruta_labels_test, cv=10)\n",
        "dt_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, dt_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against ros_boruta dataset is \" + str(dt_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(dt_clf, ros_l1_set_train, ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_ros_l1_set_prediction = cross_val_predict(dt_clf, ros_l1_set_test, ros_l1_labels_test, cv=10)\n",
        "dt_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, dt_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against ros_l1 dataset is \" + str(dt_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(dt_clf, ros_tr_set_train, ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_ros_tr_set_prediction = cross_val_predict(dt_clf, ros_tr_set_test, ros_tr_labels_test, cv=10)\n",
        "dt_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, dt_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against ros_tr dataset is \" + str(dt_f2_ros_tr_set))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of decision tree model trained against ros_boruta dataset is 0.976179554508792\n",
            "The f2 score of decision tree model trained against ros_l1 dataset is 0.9815265128347616\n",
            "The f2 score of decision tree model trained against ros_tr dataset is 0.9838922912787686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfNmV_pwplNQ",
        "colab_type": "code",
        "outputId": "3cef2de6-d883-4cba-9f0e-698ca6aa3253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(dt_clf, renn_boruta_set_train, renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_renn_boruta_set_prediction = cross_val_predict(dt_clf, renn_boruta_set_test, renn_boruta_labels_test, cv=10)\n",
        "dt_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, dt_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against renn_boruta dataset is \" + str(dt_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(dt_clf, renn_l1_set_train, renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_renn_l1_set_prediction = cross_val_predict(dt_clf, renn_l1_set_test, renn_l1_labels_test, cv=10)\n",
        "dt_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, dt_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against renn_l1 dataset is \" + str(dt_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(dt_clf, renn_tr_set_train, renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_renn_tr_set_prediction = cross_val_predict(dt_clf, renn_tr_set_test, renn_tr_labels_test, cv=10)\n",
        "dt_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, dt_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against renn_tr dataset is \" + str(dt_f2_renn_tr_set))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of decision tree model trained against renn_boruta dataset is 0.8441970686534626\n",
            "The f2 score of decision tree model trained against renn_l1 dataset is 0.7922872018632714\n",
            "The f2 score of decision tree model trained against renn_tr dataset is 0.8383439490445859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV_vXjIx4Ml2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "028f18fb-bd21-4ea4-faac-cb1c4cd45b8d"
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(dt_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_smote_boruta_set_prediction = cross_val_predict(dt_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "dt_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, dt_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against smote_boruta dataset is \" + str(dt_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(dt_clf, smote_l1_set_train, smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_smote_l1_set_prediction = cross_val_predict(dt_clf, smote_l1_set_test, smote_l1_labels_test, cv=10)\n",
        "dt_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, dt_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against smote_l1 dataset is \" + str(dt_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(dt_clf, smote_tr_set_train, smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "dt_smote_tr_set_prediction = cross_val_predict(dt_clf, smote_tr_set_test, smote_tr_labels_test, cv=10)\n",
        "dt_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, dt_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of decision tree model trained against smote_tr dataset is \" + str(dt_f2_smote_tr_set))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of decision tree model trained against smote_boruta dataset is 0.986408562401845\n",
            "The f2 score of decision tree model trained against smote_l1 dataset is 0.978409041272007\n",
            "The f2 score of decision tree model trained against smote_tr dataset is 0.9824316909102746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToG_GdIPEfsC",
        "colab_type": "text"
      },
      "source": [
        "### Linear models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n4TSUe_Et2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "le_clf = LinearSVC(random_state=0, tol=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXX6jWU_4kGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "2b21f1c1-58ac-487b-c639-232e49b9b619"
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(le_clf, original_set_train, original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_original_set_prediction = cross_val_predict(le_clf, original_set_test, original_labels_test, cv=10)\n",
        "le_f2_original_set = fbeta_score(original_labels_test, le_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against original dataset is \" + str(le_f2_original_set))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against original dataset is 0.6581709251324499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey4MTSqW45F1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "efdd72ed-a4be-4700-f1d3-94eb27f14223"
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(le_clf, ros_boruta_set_train, ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_ros_boruta_set_prediction = cross_val_predict(le_clf, ros_boruta_set_test, ros_boruta_labels_test, cv=10)\n",
        "le_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, le_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against ros_boruta dataset is \" + str(le_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(le_clf, ros_l1_set_train, ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_ros_l1_set_prediction = cross_val_predict(le_clf, ros_l1_set_test, ros_l1_labels_test, cv=10)\n",
        "le_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, le_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against ros_l1 dataset is \" + str(le_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(le_clf, ros_tr_set_train, ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_ros_tr_set_prediction = cross_val_predict(le_clf, ros_tr_set_test, ros_tr_labels_test, cv=10)\n",
        "le_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, le_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against ros_tr dataset is \" + str(le_f2_ros_tr_set))"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against ros_boruta dataset is 0.852887885442009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against ros_l1 dataset is 0.8272712983803792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against ros_tr dataset is 0.8090063433867388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xWbc7X85ktw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "e0b29e7b-7f95-4fde-dbc5-5fcf2ea64588"
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(le_clf, renn_boruta_set_train, renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_renn_boruta_set_prediction = cross_val_predict(le_clf, renn_boruta_set_test, renn_boruta_labels_test, cv=10)\n",
        "le_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, le_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against renn_boruta dataset is \" + str(le_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(le_clf, renn_l1_set_train, renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_renn_l1_set_prediction = cross_val_predict(le_clf, renn_l1_set_test, renn_l1_labels_test, cv=10)\n",
        "le_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, le_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against renn_l1 dataset is \" + str(le_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(le_clf, renn_tr_set_train, renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_renn_tr_set_prediction = cross_val_predict(le_clf, renn_tr_set_test, renn_tr_labels_test, cv=10)\n",
        "le_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, le_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against renn_tr dataset is \" + str(le_f2_renn_tr_set))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against renn_boruta dataset is 0.7033056967231599\n",
            "The f2 score of linear model trained against renn_l1 dataset is 0.7206764198087077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against renn_tr dataset is 0.6703171257965779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2UrZ8h251F3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "c6081db8-56c5-4e08-f6d2-fb7eaf3dbcf9"
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(le_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_smote_boruta_set_prediction = cross_val_predict(le_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "le_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, le_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against smote_boruta dataset is \" + str(le_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(le_clf, smote_l1_set_train, smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_smote_l1_set_prediction = cross_val_predict(le_clf, smote_l1_set_test, smote_l1_labels_test, cv=10)\n",
        "le_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, le_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against smote_l1 dataset is \" + str(le_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(le_clf, smote_tr_set_train, smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "le_smote_tr_set_prediction = cross_val_predict(le_clf, smote_tr_set_test, smote_tr_labels_test, cv=10)\n",
        "le_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, le_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of linear model trained against smote_tr dataset is \" + str(le_f2_smote_tr_set))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against smote_boruta dataset is 0.9221918540715213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against smote_l1 dataset is 0.8811728554591265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The f2 score of linear model trained against smote_tr dataset is 0.8312017755773644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSTmBtNGuXZy",
        "colab_type": "text"
      },
      "source": [
        "### Distance-based models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smD8APfCusG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import neighbors\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "\n",
        "#apply ftwo score to evaluate models\n",
        "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
        "n_neighbors = 3\n",
        "knn_clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EYrUDJd6bro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8926dc5c-110f-4725-962f-0f8d26838ea9"
      },
      "source": [
        "#train the model against the original dataset\n",
        "cross_val_score(knn_clf, original_set_train, original_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_original_set_prediction = cross_val_predict(knn_clf, original_set_test, original_labels_test, cv=10)\n",
        "knn_f2_original_set = fbeta_score(original_labels_test, knn_original_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against original dataset is \" + str(knn_f2_original_set))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of k-nearest neighbors model trained against original dataset is 0.6809456129280018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFw-8Yhg6tPV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0ba2e0bb-7d5c-4bc9-ca71-fdfd0ccd1bb6"
      },
      "source": [
        "#train the model against the ros_boruta dataset\n",
        "cross_val_score(knn_clf, ros_boruta_set_train, ros_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_ros_boruta_set_prediction = cross_val_predict(knn_clf, ros_boruta_set_test, ros_boruta_labels_test, cv=10)\n",
        "knn_f2_ros_boruta_set = fbeta_score(ros_boruta_labels_test, knn_ros_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against ros_boruta dataset is \" + str(knn_f2_ros_boruta_set))\n",
        "\n",
        "#train the model against the ros_l1 dataset\n",
        "cross_val_score(knn_clf, ros_l1_set_train, ros_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_ros_l1_set_prediction = cross_val_predict(knn_clf, ros_l1_set_test, ros_l1_labels_test, cv=10)\n",
        "knn_f2_ros_l1_set = fbeta_score(ros_l1_labels_test, knn_ros_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against ros_l1 dataset is \" + str(knn_f2_ros_l1_set))\n",
        "\n",
        "#train the model against the ros_tr dataset\n",
        "cross_val_score(knn_clf, ros_tr_set_train, ros_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_ros_tr_set_prediction = cross_val_predict(knn_clf, ros_tr_set_test, ros_tr_labels_test, cv=10)\n",
        "knn_f2_ros_tr_set = fbeta_score(ros_tr_labels_test, knn_ros_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against ros_tr dataset is \" + str(knn_f2_ros_tr_set))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of k-nearest neighbors model trained against ros_boruta dataset is 0.968956446243028\n",
            "The f2 score of k-nearest neighbors model trained against ros_l1 dataset is 0.9710471952548965\n",
            "The f2 score of k-nearest neighbors model trained against ros_tr dataset is 0.9810320847578311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt7fyg6266_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f3bb6be6-ab8e-4665-85d1-630312c690db"
      },
      "source": [
        "#train the model against the renn_boruta dataset\n",
        "cross_val_score(knn_clf, renn_boruta_set_train, renn_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_renn_boruta_set_prediction = cross_val_predict(knn_clf, renn_boruta_set_test, renn_boruta_labels_test, cv=10)\n",
        "knn_f2_renn_boruta_set = fbeta_score(renn_boruta_labels_test, knn_renn_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against renn_boruta dataset is \" + str(knn_f2_renn_boruta_set))\n",
        "\n",
        "#train the model against the renn_l1 dataset\n",
        "cross_val_score(knn_clf, renn_l1_set_train, renn_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_renn_l1_set_prediction = cross_val_predict(knn_clf, renn_l1_set_test, renn_l1_labels_test, cv=10)\n",
        "knn_f2_renn_l1_set = fbeta_score(renn_l1_labels_test, knn_renn_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against renn_l1 dataset is \" + str(knn_f2_renn_l1_set))\n",
        "\n",
        "#train the model against the renn_tr dataset\n",
        "cross_val_score(knn_clf, renn_tr_set_train, renn_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_renn_tr_set_prediction = cross_val_predict(knn_clf, renn_tr_set_test, renn_tr_labels_test, cv=10)\n",
        "knn_f2_renn_tr_set = fbeta_score(renn_tr_labels_test, knn_renn_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against renn_tr dataset is \" + str(knn_f2_renn_tr_set))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of k-nearest neighbors model trained against renn_boruta dataset is 0.8485381511736529\n",
            "The f2 score of k-nearest neighbors model trained against renn_l1 dataset is 0.8104529917739529\n",
            "The f2 score of k-nearest neighbors model trained against renn_tr dataset is 0.7969813017289943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIGdfANS7HGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2b81923e-9aef-4823-b5f5-0e6b15c8f8c6"
      },
      "source": [
        "#train the model against the smote_boruta dataset\n",
        "cross_val_score(knn_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_smote_boruta_set_prediction = cross_val_predict(knn_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "knn_f2_smote_boruta_set = fbeta_score(smote_boruta_labels_test, knn_smote_boruta_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against smote_boruta dataset is \" + str(knn_f2_smote_boruta_set))\n",
        "\n",
        "#train the model against the smote_l1 dataset\n",
        "cross_val_score(knn_clf, smote_l1_set_train, smote_l1_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_smote_l1_set_prediction = cross_val_predict(knn_clf, smote_l1_set_test, smote_l1_labels_test, cv=10)\n",
        "knn_f2_smote_l1_set = fbeta_score(smote_l1_labels_test, knn_smote_l1_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against smote_l1 dataset is \" + str(knn_f2_smote_l1_set))\n",
        "\n",
        "#train the model against the smote_tr dataset\n",
        "cross_val_score(knn_clf, smote_tr_set_train, smote_tr_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "knn_smote_tr_set_prediction = cross_val_predict(knn_clf, smote_tr_set_test, smote_tr_labels_test, cv=10)\n",
        "knn_f2_smote_tr_set = fbeta_score(smote_tr_labels_test, knn_smote_tr_set_prediction, average='macro', beta=2)\n",
        "print(\"The f2 score of k-nearest neighbors model trained against smote_tr dataset is \" + str(knn_f2_smote_tr_set))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The f2 score of k-nearest neighbors model trained against smote_boruta dataset is 0.9895301834139694\n",
            "The f2 score of k-nearest neighbors model trained against smote_l1 dataset is 0.9818161987013381\n",
            "The f2 score of k-nearest neighbors model trained against smote_tr dataset is 0.9825614432862246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "272bd008-c951-4702-ece4-537de084e2fe",
        "id": "R2CSInFb6XdK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import datetime\n",
        "import tracemalloc\n",
        "print(\"Training begin at: \" + str(datetime.datetime.now()))\n",
        "tracemalloc.start()\n",
        "cross_val_score(knn_clf, smote_boruta_set_train, smote_boruta_labels_train, scoring = ftwo_scorer, cv=10)\n",
        "snapshot = tracemalloc.take_snapshot()\n",
        "print(\"Training end at: \" + str(datetime.datetime.now()))\n",
        "print(\"Predicting begin at: \" + str(datetime.datetime.now()))\n",
        "knn_smote_boruta_set_prediction = cross_val_predict(knn_clf, smote_boruta_set_test, smote_boruta_labels_test, cv=10)\n",
        "print(\"Predicting end at: \" + str(datetime.datetime.now()))\n",
        "\n",
        "top_stats = snapshot.statistics('lineno')\n",
        "total_size = 0\n",
        "for stat in top_stats:\n",
        "    total_size = total_size + stat.size\n",
        "print(\"Training memory consumption is \" + str(total_size / (1024 * 1024)) + \"MB\")"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training begin at: 2019-11-20 22:32:54.077642\n",
            "Training end at: 2019-11-20 22:33:08.427120\n",
            "Predicting begin at: 2019-11-20 22:33:08.427740\n",
            "Predicting end at: 2019-11-20 22:33:09.497922\n",
            "Training memory consumption is 120.6889295578003MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFSL9Clq8VEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR9TjcKn8vcl",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE-Df2mg81mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}